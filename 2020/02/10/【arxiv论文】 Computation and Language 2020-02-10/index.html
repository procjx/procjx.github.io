<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/procjx.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/procjxfavicon32x32.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/procjxfavicon16x16.ico">
  <link rel="mask-icon" href="/images/procjx.png" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '7.4.2',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":true,"show_result":true,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    },
    sidebarPadding: 40
  };
</script>

<!-- Google Adsense -->
<!--
<script async src="//pagead2.googlesyndication.com/
pagead/js/adsbygoogle.js"></script>
<script>
(adsbygoogle = window.adsbygoogle || []).push({
google_ad_client: "pub-1179774715076800",
enable_page_level_ads: true
});
</script>
-->

<script data-ad-client="ca-pub-1179774715076800" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>


<meta name="google-site-verification" content="cEiGwg0T8Rj5msmuEcGYZTh5nnf05EhCXy0gp2Ml5BI" />
<meta name="baidu-site-verification" content="noSKHe8MJs" />

  <meta name="description" content="目录  1. A Multilingual View of Unsupervised Machine Translation [PDF] 摘要  2. BERT-of-Theseus: Compressing BERT by Progressive Module Replacing [PDF] 摘要  3. Neural Machine Translation System of Indic La">
<meta property="og:type" content="article">
<meta property="og:title" content="【arxiv论文】 Computation and Language 2020-02-10">
<meta property="og:url" content="https:&#x2F;&#x2F;procjx.github.io&#x2F;2020&#x2F;02&#x2F;10&#x2F;%E3%80%90arxiv%E8%AE%BA%E6%96%87%E3%80%91%20Computation%20and%20Language%202020-02-10&#x2F;index.html">
<meta property="og:site_name" content="PROCJX&#39;s BLOGS">
<meta property="og:description" content="目录  1. A Multilingual View of Unsupervised Machine Translation [PDF] 摘要  2. BERT-of-Theseus: Compressing BERT by Progressive Module Replacing [PDF] 摘要  3. Neural Machine Translation System of Indic La">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2020-03-04T17:09:32.448Z">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://procjx.github.io/2020/02/10/%E3%80%90arxiv%E8%AE%BA%E6%96%87%E3%80%91%20Computation%20and%20Language%202020-02-10/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>【arxiv论文】 Computation and Language 2020-02-10 | PROCJX's BLOGS</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">PROCJX's BLOGS</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <h1 class="site-subtitle" itemprop="description">WITH LOVE OF WORLD</h1>
      
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
        <li class="menu-item menu-item-resources">

    <a href="/resources/" rel="section"><i class="fa fa-fw fa-download"></i>资源</a>

  </li>
        <li class="menu-item menu-item-arxiv">

    <a href="/arxiv/" rel="section"><i class="fa fa-fw fa-file-pdf-o"></i>arxiv论文</a>

  </li>
        <li class="menu-item menu-item-deadline">

    <a href="/deadline/" rel="section"><i class="fa fa-fw fa-calendar"></i>会议截稿</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="搜索..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://procjx.github.io/2020/02/10/%E3%80%90arxiv%E8%AE%BA%E6%96%87%E3%80%91%20Computation%20and%20Language%202020-02-10/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/procjx.png">
      <meta itemprop="name" content="PROCJX">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PROCJX's BLOGS">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          【arxiv论文】 Computation and Language 2020-02-10
        </h2>

        <div class="post-meta">
        
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-02-10 10:06:09" itemprop="dateCreated datePublished" datetime="2020-02-10T10:06:09+08:00">2020-02-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-05 01:09:32" itemprop="dateModified" datetime="2020-03-05T01:09:32+08:00">2020-03-05</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/arxiv/" itemprop="url" rel="index">
                    <span itemprop="name">arxiv</span>
                  </a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/arxiv/CL/" itemprop="url" rel="index">
                    <span itemprop="name">CL</span>
                  </a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
              <span>23k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
              <span>38 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a><div style="color:red;">目录</div></h1><font size="4">
<div id="title1">
<b>1.</b> A Multilingual View of Unsupervised Machine Translation <a href="https://arxiv.org/pdf/2002.02955" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper1" style="color:#0000EE;">摘要</a><br></div>
<div id="title2">
<b>2.</b> BERT-of-Theseus: Compressing BERT by Progressive Module Replacing <a href="https://arxiv.org/pdf/2002.02925" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper2" style="color:#0000EE;">摘要</a><br></div>
<div id="title3">
<b>3.</b> Neural Machine Translation System of Indic Languages -- An Attention  based Approach <a href="https://arxiv.org/pdf/2002.02758" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper3" style="color:#0000EE;">摘要</a><br></div>
<div id="title4">
<b>4.</b> On-Device Information Extraction from SMS using Hybrid Hierarchical  Classification <a href="https://arxiv.org/pdf/2002.02755" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper4" style="color:#0000EE;">摘要</a><br></div>
<div id="title5">
<b>5.</b> Incorporating Visual Semantics into Sentence Representations within a  Grounded Space <a href="https://arxiv.org/pdf/2002.02734" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper5" style="color:#0000EE;">摘要</a><br></div>
<div id="title6">
<b>6.</b> Multimodal Matching Transformer for Live Commenting <a href="https://arxiv.org/pdf/2002.02649" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper6" style="color:#0000EE;">摘要</a><br></div>
<div id="title7">
<b>7.</b> Translating Web Search Queries into Natural Language Questions <a href="https://arxiv.org/pdf/2002.02631" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper7" style="color:#0000EE;">摘要</a><br></div>
<div id="title8">
<b>8.</b> Introducing Aspects of Creativity in Automatic Poetry Generation <a href="https://arxiv.org/pdf/2002.02511" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper8" style="color:#0000EE;">摘要</a><br></div>
<div id="title9">
<b>9.</b> Goal-Oriented Multi-Task BERT-Based Dialogue State Tracker <a href="https://arxiv.org/pdf/2002.02450" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper9" style="color:#0000EE;">摘要</a><br></div>
<div id="title10">
<b>10.</b> I love your chain mail! Making knights smile in a fantasy game world:  Open-domain goal-orientated dialogue agents <a href="https://arxiv.org/pdf/2002.02878" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper10" style="color:#0000EE;">摘要</a><br></div>
<div id="title11">
<b>11.</b> Unsupervised pretraining transfers well across languages <a href="https://arxiv.org/pdf/2002.02848" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper11" style="color:#0000EE;">摘要</a><br></div>
<div id="title12">
<b>12.</b> Depressed individuals express more distorted thinking on social media <a href="https://arxiv.org/pdf/2002.02800" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper12" style="color:#0000EE;">摘要</a><br></div>
<div id="title13">
<b>13.</b> LEAP System for SRE19 Challenge -- Improvements and Error Analysis <a href="https://arxiv.org/pdf/2002.02735" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper13" style="color:#0000EE;">摘要</a><br></div>
<div id="title14">
<b>14.</b> Transformer Transducer: A Streamable Speech Recognition Model with  Transformer Encoders and RNN-T Loss <a href="https://arxiv.org/pdf/2002.02562" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper14" style="color:#0000EE;">摘要</a><br></div>
<div id="title15">
<b>15.</b> Robust Multi-channel Speech Recognition using Frequency Aligned Network <a href="https://arxiv.org/pdf/2002.02520" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper15" style="color:#0000EE;">摘要</a><br></div>
<div id="title16">
<b>16.</b> Consistency of a Recurrent Language Model With Respect to Incomplete  Decoding <a href="https://arxiv.org/pdf/2002.02492" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper16" style="color:#0000EE;">摘要</a><br></div>
</font><a id="more"></a>


<hr>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- procjx-wenzhang2 -->
<p><ins class="adsbygoogle" style="display:block; text-align:center;" data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-1179774715076800" data-ad-slot="5367332398"></ins></p>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>


<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><div style="color:red;">摘要</div></h1><div id="paper1"> <b>1. A Multilingual View of Unsupervised Machine Translation</b>  <a href="https://arxiv.org/pdf/2002.02955" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title1" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Garcia%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xavier Garcia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Foret%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Pierre Foret</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Sellam%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Thibault Sellam</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Parikh%2C+A+P" target="_blank" rel="noopener" style="color:#0000EE;">Ankur P. Parikh</a><br>
<font size="3">
Abstract: We present a probabilistic framework for multilingual neural machine translation that encompasses supervised and unsupervised setups, focusing on unsupervised translation. In addition to studying the vanilla case where there is only monolingual data available, we propose a novel setup where one language in the (source, target) pair is not associated with any parallel data, but there may exist auxiliary parallel data that contains the other. This auxiliary data can naturally be utilized in our probabilistic framework via a novel cross-translation loss term. Empirically, we show that our approach results in higher BLEU scores over state-of-the-art unsupervised models on the WMT'14 English-French, WMT'16 English-German, and WMT'16 English-Romanian datasets in most directions. In particular, we obtain a +1.65 BLEU advantage over the best-performing unsupervised model in the Romanian-English direction. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：我们提出了多语种神经机器翻译概率框架，包括监管和监督的设置，注重监督的翻译。除了仅存在单语数据可用的研究香草情况下，我们提出了其中在（源，目标）一种语言对不与任何并行数据相关联的新的设置，但也有可能存在包含其它辅助的并行数据。该辅助数据可以自然地在我们的概率框架通过一种新颖的横翻译损耗项利用。根据经验，我们表明，我们的方法得到更高的分数BLEU在国家的最先进的无人监督的车型上WMT'14英法，WMT'16英语 - 德语和英语WMT'16  - 罗马尼亚数据集在大部分方向。特别是，我们获得了在罗马尼亚英语方向表现最好的无监督模型1.65 BLEU优势。</font>
</div>


<hr>
<div id="paper2"> <b>2. BERT-of-Theseus: Compressing BERT by Progressive Module Replacing</b>  <a href="https://arxiv.org/pdf/2002.02925" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title2" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Xu%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Canwen Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhou%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Wangchunshu Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ge%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Tao Ge</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wei%2C+F" target="_blank" rel="noopener" style="color:#0000EE;">Furu Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhou%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Ming Zhou</a><br>
<font size="3">
Abstract: In this paper, we propose a novel model compression approach to effectively compress BERT by progressive module replacing. Our approach first divides the original BERT into several modules and builds their compact substitutes. Then, we randomly replace the original modules with their substitutes to train the compact modules to mimic the behavior of the original modules. We progressively increase the probability of replacement through the training. In this way, our approach brings a deeper level of interaction between the original and compact models, and smooths the training process. Compared to the previous knowledge distillation approaches for BERT compression, our approach leverages only one loss function and one hyper-parameter, liberating human effort from hyper-parameter tuning. Our approach outperforms existing knowledge distillation approaches on GLUE benchmark, showing a new perspective of model compression. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在本文中，我们建议逐步模块更换一个新的模型的压缩方式，有效压缩BERT。我们的方法首先将原始BERT分成几个模块，并建立其紧凑的替代品。然后，我们随机与他们的替代品代替原来的模块的紧凑型模块训练到原来模块的模仿行为。我们不断通过培训提高替代的可能性。这样一来，我们的方法所带来的原始和紧凑车型之间的相互作用更深层次的，和平滑的训练过程。相较于以前的知识蒸馏方法用于BERT压缩，我们的方法利用只有一个损失函数和一个超参数，释放从高参数整定人的努力。我们的方法比现有的知识蒸馏方法胶水标杆，展示模型压缩的一个新的视角。</font>
</div>


<hr>
<div id="paper3"> <b>3. Neural Machine Translation System of Indic Languages -- An Attention  based Approach</b>  <a href="https://arxiv.org/pdf/2002.02758" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title3" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Shah%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Parth Shah</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bakrola%2C+V" target="_blank" rel="noopener" style="color:#0000EE;">Vishvajit Bakrola</a><br>
<font size="3">
Abstract: Neural machine translation (NMT) is a recent and effective technique which led to remarkable improvements in comparison of conventional machine translation techniques. Proposed neural machine translation model developed for the Gujarati language contains encoder-decoder with attention mechanism. In India, almost all the languages are originated from their ancestral language Sanskrit. They are having inevitable similarities including lexical and named entity similarity. Translating into Indic languages is always be a challenging task. In this paper, we have presented the neural machine translation system (NMT) that can efficiently translate Indic languages like Hindi and Gujarati that together covers more than 58.49 percentage of total speakers in the country. We have compared the performance of our NMT model with automatic evaluation matrices such as BLEU, perplexity and TER matrix. The comparison of our network with Google translate is also presented where it outperformed with a margin of 6 BLEU score on English-Gujarati translation. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：神经机器翻译（NMT）是最近的和有效的技术，其导致显着改善在常规机器翻译技术相比。在古吉拉特语语言开发的建议神经机器翻译模型包含编码器，解码器，注意机制。在印度，几乎所有的语言都源于他们祖先的语言梵语。他们有着必然的相似，包括词汇和命名实体的相似性。翻译成印度语始终是一项艰巨的任务。在本文中，我们提出了神经机器翻译系统（NMT），可以有效地翻译印度语像印地文和古吉拉特一起覆盖全国总扬声器超过58.49百分比。我们比较我们与自动评估NMT模型的性能矩阵如BLEU，困惑和TER矩阵。还提出了我们与谷歌翻译网络的比较在那里与6 BLEU得分上英语翻译古吉拉特语保证金跑赢。</font>
</div>


<hr>
<div id="paper4"> <b>4. On-Device Information Extraction from SMS using Hybrid Hierarchical  Classification</b>  <a href="https://arxiv.org/pdf/2002.02755" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title4" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Vatsal%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Shubham Vatsal</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Purre%2C+N" target="_blank" rel="noopener" style="color:#0000EE;">Naresh Purre</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Moharana%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sukumar Moharana</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ramena%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Gopi Ramena</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Mohanty%2C+D+P" target="_blank" rel="noopener" style="color:#0000EE;">Debi Prasanna Mohanty</a><br>
<font size="3">
Abstract: Cluttering of SMS inbox is one of the serious problems that users today face in the digital world where every online login, transaction, along with promotions generate multiple SMS. This problem not only prevents users from searching and navigating messages efficiently but often results in users missing out the relevant information associated with the corresponding SMS like offer codes, payment reminders etc. In this paper, we propose a unique architecture to organize and extract the appropriate information from SMS and further display it in an intuitive template. In the proposed architecture, we use a Hybrid Hierarchical Long Short Term Memory (LSTM)-Convolutional Neural Network (CNN) to categorize SMS into multiple classes followed by a set of entity parsers used to extract the relevant information from the classified message. The architecture using its preprocessing techniques not only takes into account the enormous variations observed in SMS data but also makes it efficient for its on-device (mobile phone) functionalities in terms of inference timing and size. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：短信收件箱的杂波环境下是严重的问题之一是用户面对今天的数字世界里，所有的在线登录，交易，以得到提拔生成多个短信。这个问题不仅防止用户搜索和浏览效率消息，但通常会导致用户错过了与像优惠代码相应的SMS相关联的相关信息，催款等。在本文中，我们提出了一个独特的体系结构来组织和提取相应的以直观的模板从SMS，并进一步显示它的信息。在所提出的架构中，我们使用了基于分层长短期记忆（LSTM）-Convolutional神经网络（CNN）归类短信到多个类，然后一组用于提取分类信息相关的信息实体解析器。使用它的预处理技术的架构不仅考虑到了SMS数据中观察到的巨大的变化，但也使得有效用于推理定时和尺寸方面及其对设备（移动电话）的功能。</font>
</div>


<hr>
<div id="paper5"> <b>5. Incorporating Visual Semantics into Sentence Representations within a  Grounded Space</b>  <a href="https://arxiv.org/pdf/2002.02734" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title5" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Bordes%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Patrick Bordes</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zablocki%2C+E" target="_blank" rel="noopener" style="color:#0000EE;">Eloi Zablocki</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Soulier%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Laure Soulier</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Piwowarski%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Benjamin Piwowarski</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Gallinari%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Patrick Gallinari</a><br>
<font size="3">
Abstract: Language grounding is an active field aiming at enriching textual representations with visual information. Generally, textual and visual elements are embedded in the same representation space, which implicitly assumes a one-to-one correspondence between modalities. This hypothesis does not hold when representing words, and becomes problematic when used to learn sentence representations --- the focus of this paper --- as a visual scene can be described by a wide variety of sentences. To overcome this limitation, we propose to transfer visual information to textual representations by learning an intermediate representation space: the grounded space. We further propose two new complementary objectives ensuring that (1) sentences associated with the same visual content are close in the grounded space and (2) similarities between related elements are preserved across modalities. We show that this model outperforms the previous state-of-the-art on classification and semantic relatedness tasks. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：语言接地是一个活跃的领域，旨在丰富文本表示视觉信息。一般地，文本和视觉元素嵌入在相同的表示空间，这隐含地假设模态之间的一对一的对应关系。代表句话的时候这个假设不成立，并且在使用时要学会一句表述---本文的重点---作为一个视觉场景可以通过各种各样的句子来描述成为问题。为了克服这种局限性，我们提出通过学习中间表示空间的视觉信息传递到文本表示：接地的空间。我们进一步提出了两种新补充的目标，确保用相同的视觉内容相关：（1）句子接近接地的空间和（2）的相关要素之间的相似跨形式保留。我们表明，这种模型优于以前的分类和语义相关任务的国家的最先进的。</font>
</div>


<hr>
<div id="paper6"> <b>6. Multimodal Matching Transformer for Live Commenting</b>  <a href="https://arxiv.org/pdf/2002.02649" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title6" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Duan%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Chaoqun Duan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Cui%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Lei Cui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ma%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Shuming Ma</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wei%2C+F" target="_blank" rel="noopener" style="color:#0000EE;">Furu Wei</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhu%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Conghui Zhu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhao%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Tiejun Zhao</a><br>
<font size="3">
Abstract: Automatic live commenting aims to provide real-time comments on videos for viewers. It encourages users engagement on online video sites, and is also a good benchmark for video-to-text generation. Recent work on this task adopts encoder-decoder models to generate comments. However, these methods do not model the interaction between videos and comments explicitly, so they tend to generate popular comments that are often irrelevant to the videos. In this work, we aim to improve the relevance between live comments and videos by modeling the cross-modal interactions among different modalities. To this end, we propose a multimodal matching transformer to capture the relationships among comments, vision, and audio. The proposed model is based on the transformer framework and can iteratively learn the attention-aware representations for each modality. We evaluate the model on a publicly available live commenting dataset. Experiments show that the multimodal matching transformer model outperforms the state-of-the-art methods. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：自动活评论旨在对影片为观众提供实时评论。它鼓励对在线视频网站的用户参与，并且也是视频到文本生成一个很好的标杆。此任务最近的工作，采用编码器，解码器模型来生成评论。然而，这些方法没有视频和评论之间的相互作用明确建模，因此他们往往会产生流行的评论说，往往无关的视频。在这项工作中，我们的目标是通过模拟不同方式之间的跨模态的相互作用，以提高现场评论和视频之间的相关性。为此，我们提出了一种多模式匹配变压器捕捉到的意见，视觉和音频之间的关系。该模型是基于变压器的框架，并可以反复学习注意力感知表示每个模式。我们评估在公开的现场评论数据集模型。实验表明，该多模态匹配变压器模型优于国家的最先进的方法。</font>
</div>


<hr>
<div id="paper7"> <b>7. Translating Web Search Queries into Natural Language Questions</b>  <a href="https://arxiv.org/pdf/2002.02631" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title7" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Kumar%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Adarsh Kumar</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Dandapat%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sandipan Dandapat</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Chordia%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sushil Chordia</a><br>
<font size="3">
Abstract: Users often query a search engine with a specific question in mind and often these queries are keywords or sub-sentential fragments. For example, if the users want to know the answer for "What's the capital of USA", they will most probably query "capital of USA" or "USA capital" or some keyword-based variation of this. For example, for the user entered query "capital of USA", the most probable question intent is "What's the capital of USA?". In this paper, we are proposing a method to generate well-formed natural language question from a given keyword-based query, which has the same question intent as the query. Conversion of keyword-based web query into a well-formed question has lots of applications, with some of them being in search engines, Community Question Answering (CQA) website and bots communication. We found a synergy between query-to-question problem with standard machine translation(MT) task. We have used both Statistical MT (SMT) and Neural MT (NMT) models to generate the questions from the query. We have observed that MT models perform well in terms of both automatic and human evaluation. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：用户经常查询与具体问题的搜索引擎在心中，往往这些查询的关键字或子句子片段。例如，如果用户想知道的答案“什么是美国的首都”，他们将最有可能的查询“美国资本”或“美国资本”或一些这方面的基于关键字的变化。例如，用户输入查询“美国资本”，最有可能的问题，目的是“什么是美国的首都呢？”。在本文中，我们提议从给定的基于关键字的查询，其中有意向的询问同样的问题，良好的自然语言问题的方法。基于关键字的网页查询转换成一个结构良好的问题有很多的应用，在搜索引擎中的一些人是社区问答（CQA）的网站和漫游通信。我们发现查询到问题的问题，标准的机器翻译（MT）的任务之间的协同作用。我们都用了统计MT（SMT）和神经MT（NMT）模型来生成从查询的问题。我们观察到，MT车型在自动和人工评估方面表现良好。</font>
</div>


<hr>
<div id="paper8"> <b>8. Introducing Aspects of Creativity in Automatic Poetry Generation</b>  <a href="https://arxiv.org/pdf/2002.02511" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title8" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Bena%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Brendan Bena</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kalita%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jugal Kalita</a><br>
<font size="3">
Abstract: Poetry Generation involves teaching systems to automatically generate text that resembles poetic work. A deep learning system can learn to generate poetry on its own by training on a corpus of poems and modeling the particular style of language. In this paper, we propose taking an approach that fine-tunes GPT-2, a pre-trained language model, to our downstream task of poetry generation. We extend prior work on poetry generation by introducing creative elements. Specifically, we generate poems that express emotion and elicit the same in readers, and poems that use the language of dreams---called dream poetry. We are able to produce poems that correctly elicit the emotions of sadness and joy 87.5 and 85 percent, respectively, of the time. We produce dreamlike poetry by training on a corpus of texts that describe dreams. Poems from this model are shown to capture elements of dream poetry with scores of no less than 3.2 on the Likert scale. We perform crowdsourced human-evaluation for all our poems. We also make use of the Coh-Metrix tool, outlining metrics we use to gauge the quality of text generated. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：诗歌生成涉及教学系统自动生成的文本类似于诗的工作。深学习系统可以学习在诗的语料库培训和建模语言的特殊风格产生对自己的诗歌。在本文中，我们建议采取的做法，微调GPT-2，预先训练的语言模型，我们的诗歌产生的下游任务。我们通过引入创意元素延长诗代前期工作。具体而言，我们产生表达情感和引发相同的读者，用梦想的语言---所谓的梦想诗诗和诗歌。我们能够产生诗歌分别是正确引起的时间悲伤和喜悦87.5％和85％，的情绪。我们通过描述梦想文本语料库培训产生梦幻般的诗意。从这个模型诗被示出为与在李克特量表的不小于3.2的分数梦想诗歌捕获元件。我们进行众包的人评价为我们所有的诗。我们还利用COH-Metrix的工具，概述我们用衡量生成的文本的质量指标。</font>
</div>


<hr>
<div id="paper9"> <b>9. Goal-Oriented Multi-Task BERT-Based Dialogue State Tracker</b>  <a href="https://arxiv.org/pdf/2002.02450" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title9" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Gulyaev%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Pavel Gulyaev</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Elistratova%2C+E" target="_blank" rel="noopener" style="color:#0000EE;">Eugenia Elistratova</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Konovalov%2C+V" target="_blank" rel="noopener" style="color:#0000EE;">Vasily Konovalov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kuratov%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yuri Kuratov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Pugachev%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Leonid Pugachev</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Burtsev%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mikhail Burtsev</a><br>
<font size="3">
Abstract: Dialogue State Tracking (DST) is a core component of virtual assistants such as Alexa or Siri. To accomplish various tasks, these assistants need to support an increasing number of services and APIs. The Schema-Guided State Tracking track of the 8th Dialogue System Technology Challenge highlighted the DST problem for unseen services. The organizers introduced the Schema-Guided Dialogue (SGD) dataset with multi-domain conversations and released a zero-shot dialogue state tracking model. In this work, we propose a GOaL-Oriented Multi-task BERT-based dialogue state tracker (GOLOMB) inspired by architectures for reading comprehension question answering systems. The model "queries" dialogue history with descriptions of slots and services as well as possible values of slots. This allows to transfer slot values in multi-domain dialogues and have a capability to scale to unseen slot types. Our model achieves a joint goal accuracy of 53.97% on the SGD dataset, outperforming the baseline model. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：对话状态跟踪（DST）是虚拟助理如Alexa或锡里的核心部件。要完成各种任务，这些助手需要支持服务和API的越来越多。第八对话系统技术挑战赛的模式制导状态跟踪轨迹突出了DST问题的看不见的服务。主办方引入了多领域的对话架构制导对话（SGD）数据集，并发布了零射门的对话状态跟踪模型。在这项工作中，我们建议架构的启发基于BERT面向目标的多任务对话状态追踪器（哥伦布）阅读理解问答系统。该模型“查询”对话的历史与插槽的说明和服务，以及插槽的可能值。这允许在多域的对话能力转移槽值并具有刻度以看不见的插槽类型。我们的模型实现了对SGD数据集的53.97％的合资目标的准确性，跑赢基准模型。</font>
</div>


<hr>
<div id="paper10"> <b>10. I love your chain mail! Making knights smile in a fantasy game world:  Open-domain goal-orientated dialogue agents</b>  <a href="https://arxiv.org/pdf/2002.02878" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title10" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Prabhumoye%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Shrimai Prabhumoye</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Margaret Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Urbanek%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jack Urbanek</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Dinan%2C+E" target="_blank" rel="noopener" style="color:#0000EE;">Emily Dinan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kiela%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Douwe Kiela</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Weston%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jason Weston</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Szlam%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Arthur Szlam</a><br>
<font size="3">
Abstract: Dialogue research tends to distinguish between chit-chat and goal-oriented tasks. While the former is arguably more naturalistic and has a wider use of language, the latter has clearer metrics and a straightforward learning signal. Humans effortlessly combine the two, for example engaging in chit-chat with the goal of exchanging information or eliciting a specific response. Here, we bridge the divide between these two domains in the setting of a rich multi-player text-based fantasy environment where agents and humans engage in both actions and dialogue. Specifically, we train a goal-oriented model with reinforcement learning against an imitation-learned ``chit-chat'' model with two approaches: the policy either learns to pick a topic or learns to pick an utterance given the top-K utterances from the chit-chat model. We show that both models outperform an inverse model baseline and can converse naturally with their dialogue partner in order to achieve goals. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：对话研究倾向于闲聊和面向目标的任务区分。前者无疑是更自然，并具有广泛应用的语言，后者有更清晰的指标和一个简单的学习用信号。人类毫不费力地将二者结合起来，例如在闲聊从事与交换信息或引发特异性反应的目标。在这里，我们弥补了丰富的基于文本的多玩家幻想环境的设置这两个领域，其中代理和人类从事这两个动作和对话之间的鸿沟。具体来说，我们训练与强化学习面向目标的模型对模仿学习的``闲聊'模型方法有两种：政策要么学会选择一个主题或学会挑给从顶部-K话语的话语在闲聊模型。我们发现，这两种模式超越逆模型基线和为了达到目标，可以与他们的对话伙伴自然交谈。</font>
</div>


<hr>
<div id="paper11"> <b>11. Unsupervised pretraining transfers well across languages</b>  <a href="https://arxiv.org/pdf/2002.02848" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title11" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/eess?searchtype=author&query=Rivi%C3%A8re%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Morgane Rivière</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Joulin%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Armand Joulin</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Mazar%C3%A9%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Pierre-Emmanuel Mazaré</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Dupoux%2C+E" target="_blank" rel="noopener" style="color:#0000EE;">Emmanuel Dupoux</a><br>
<font size="3">
Abstract: Cross-lingual and multi-lingual training of Automatic Speech Recognition (ASR) has been extensively investigated in the supervised setting. This assumes the existence of a parallel corpus of speech and orthographic transcriptions. Recently, contrastive predictive coding (CPC) algorithms have been proposed to pretrain ASR systems with unlabelled data. In this work, we investigate whether unsupervised pretraining transfers well across languages. We show that a slight modification of the CPC pretraining extracts features that transfer well to other languages, being on par or even outperforming supervised pretraining. This shows the potential of unsupervised methods for languages with few linguistic resources. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：跨语言和自动语音识别（ASR）的多语种培训的监督设置了广泛的研究。这是假设的语音和正字改编的平行语料库的存在。近日，对比预测编码（CPC）算法被提出来与未标记的数据pretrain ASR系统。在这项工作中，我们调查是否无监督的训练前转移以及跨语言。我们表明，训练前中共提取物的稍微修改的特点是传输以及其他语言，是媲美甚至超越监督训练前。这显示了与一些语言资源语言的无监督方法的潜力。</font>
</div>


<hr>
<div id="paper12"> <b>12. Depressed individuals express more distorted thinking on social media</b>  <a href="https://arxiv.org/pdf/2002.02800" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title12" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Bathina%2C+K+C" target="_blank" rel="noopener" style="color:#0000EE;">Krishna C. Bathina</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Thij%2C+M+t" target="_blank" rel="noopener" style="color:#0000EE;">Marijn ten Thij</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Lorenzo-Luaces%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Lorenzo Lorenzo-Luaces</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Rutter%2C+L+A" target="_blank" rel="noopener" style="color:#0000EE;">Lauren A. Rutter</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bollen%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Johan Bollen</a><br>
<font size="3">
Abstract: Depression is a leading cause of disability worldwide, but is often under-diagnosed and under-treated. One of the tenets of cognitive-behavioral therapy (CBT) is that individuals who are depressed exhibit distorted modes of thinking, so-called cognitive distortions, which can negatively affect their emotions and motivation. Here, we show that individuals with a self-reported diagnosis of depression on social media express higher levels of distorted thinking than a random sample. Some types of distorted thinking were found to be more than twice as prevalent in our depressed cohort, in particular Personalizing and Emotional Reasoning. This effect is specific to the distorted content of the expression and can not be explained by the presence of specific topics, sentiment, or first-person pronouns. Our results point towards the detection, and possibly mitigation, of patterns of online language that are generally deemed depressogenic. They may also provide insight into recent observations that social media usage can have a negative impact on mental health. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：抑郁症是全世界残疾的主要原因，但往往没有得到诊断和治疗不足。一个认知行为疗法（CBT）的原则之一是，谁是抑郁个体表现出扭曲的思维方式，所谓的认知扭曲，可自己的情绪和动机产生负面影响。在这里，我们表明，抑郁对社交媒体的自我报告诊断的个体表达较高水平的扭曲的思维不是随机抽样的。发现某些类型的扭曲的思维方式是在我们的沮丧人群普遍两倍以上，尤其是个性化和情感推理。这种效果是特定于表达的失真内容，并且不能由特定的主题，情绪，或第一人称代词的存在来解释。我们的研究结果指向了检测，并可能减缓，那一般都认为depressogenic在线语言模式。他们还可以提供洞察到最近的观察，社交媒体的使用会对心理健康产生负面影响。</font>
</div>


<hr>
<div id="paper13"> <b>13. LEAP System for SRE19 Challenge -- Improvements and Error Analysis</b>  <a href="https://arxiv.org/pdf/2002.02735" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title13" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/eess?searchtype=author&query=Ramoji%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Shreyas Ramoji</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Krishnan%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Prashant Krishnan</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Mysore%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Bhargavram Mysore</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Singh%2C+P" target="_blank" rel="noopener" style="color:#0000EE;">Prachi Singh</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Ganapathy%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sriram Ganapathy</a><br>
<font size="3">
Abstract: The NIST Speaker Recognition Evaluation - Conversational Telephone Speech (CTS) challenge 2019 was an open evaluation for the task of speaker verification in challenging conditions. In this paper, we provide a detailed account of the LEAP SRE system submitted to the CTS challenge focusing on the novel components in the back-end system modeling. All the systems used the time-delay neural network (TDNN) based x-vector embeddings. The x-vector system in our SRE19 submission used a large pool of training speakers (about 14k speakers). Following the x-vector extraction, we explored a neural network approach to backend score computation that was optimized for a speaker verification cost. The system combination of generative and neural PLDA models resulted in significant improvements for the SRE evaluation dataset. We also found additional gains for the SRE systems based on score normalization and calibration. Subsequent to the evaluations, we have performed a detailed analysis of the submitted systems. The analysis revealed the incremental gains obtained for different training dataset combinations as well as the modeling methods. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：NIST说话人识别评估 - 会话电话语音（CTS）挑战2019是为在艰难条件下的说话人确认的任务一个开放的评价。在本文中，我们提供了一个详细的帐户提交CTS挑战着眼于后端系统建模的新组件的LEAP SRE系统。所有的系统中使用的时间延迟神经网络（TDNN）基于X的矢量的嵌入。在我们SRE19提交的X-载体系统使用的培训扬声器（约14K扬声器）的大型游泳池。继X向量提取，我们探讨了神经网络的方法来后端分数计算这是该扬声器核查成本优化。生成和神经PLDA模型的系统组合导致的SRE评估数据集显著的改善。我们还发现基于分数标准化和校准SRE系统的额外收益。继评估，我们已经完成了提交系统的详细分析。分析揭示了不同的训练数据集组合以及建模方法获得的增量收益。</font>
</div>


<hr>
<div id="paper14"> <b>14. Transformer Transducer: A Streamable Speech Recognition Model with  Transformer Encoders and RNN-T Loss</b>  <a href="https://arxiv.org/pdf/2002.02562" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title14" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/eess?searchtype=author&query=Zhang%2C+Q" target="_blank" rel="noopener" style="color:#0000EE;">Qian Zhang</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Lu%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Han Lu</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Sak%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hasim Sak</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Tripathi%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Anshuman Tripathi</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=McDermott%2C+E" target="_blank" rel="noopener" style="color:#0000EE;">Erik McDermott</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Koo%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Stephen Koo</a>, 
<a href="https://arxiv.org/search/eess?searchtype=author&query=Kumar%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Shankar Kumar</a><br>
<font size="3">
Abstract: In this paper we present an end-to-end speech recognition model with Transformer encoders that can be used in a streaming speech recognition system. Transformer computation blocks based on self-attention are used to encode both audio and label sequences independently. The activations from both audio and label encoders are combined with a feed-forward layer to compute a probability distribution over the label space for every combination of acoustic frame position and label history. This is similar to the Recurrent Neural Network Transducer (RNN-T) model, which uses RNNs for information encoding instead of Transformer encoders. The model is trained with a monotonic RNN-T loss well-suited to frame-synchronous, streaming decoding. We present results on the LibriSpeech dataset showing that limiting the left context for self-attention in the Transformer layers makes decoding computationally tractable for streaming, with only a slight degradation in accuracy. We also show that the full attention version of our model achieves competitive performance compared to existing LibriSpeech benchmarks for attention-based models trained with cross-entropy loss. Our results also show that we can bridge the gap between full attention and limited attention versions of our model by attending to a limited number of future frames. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：本文提出了具有可在流式语音识别系统中使用的变压器编码器的终端到终端的语音识别模型。基于自我关注变压器计算块用于独立编码音频和标签序列。从音频和标签编码器的激活相结合，与前馈层，以计算在所述标签空间上的概率分布的声学帧位置和标签历史的每个组合。这是类似于回归神经网络传感器（RNN-T）模型，它使用RNNs用于编码代替变压器的编码器的信息。该模型被训练以单调RNN-T损耗非常适用于帧同步，流解码。我们上显示，限制自我关注的左上下文变压器层使得解码流媒体，只有在准确度稍有下降，易于计算的LibriSpeech数据集目前的结果。我们还表明，相对于现有的LibriSpeech基准注意力基础的模式与交叉熵损失训练的我们的模型的充分重视版本实现了有竞争力的表现。我们的研究结果还表明我们可以通过参加未来的帧数量有限弥合充分重视和关注有限的版本我们的模型之间的差距。</font>
</div>


<hr>
<div id="paper15"> <b>15. Robust Multi-channel Speech Recognition using Frequency Aligned Network</b>  <a href="https://arxiv.org/pdf/2002.02520" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title15" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Park%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Taejin Park</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kumatani%2C+K" target="_blank" rel="noopener" style="color:#0000EE;">Kenichi Kumatani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wu%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Minhua Wu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Sundaram%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Shiva Sundaram</a><br>
<font size="3">
Abstract: Conventional speech enhancement technique such as beamforming has known benefits for far-field speech recognition. Our own work in frequency-domain multi-channel acoustic modeling has shown additional improvements by training a spatial filtering layer jointly within an acoustic model. In this paper, we further develop this idea and use frequency aligned network for robust multi-channel automatic speech recognition (ASR). Unlike an affine layer in the frequency domain, the proposed frequency aligned component prevents one frequency bin influencing other frequency bins. We show that this modification not only reduces the number of parameters in the model but also significantly and improves the ASR performance. We investigate effects of frequency aligned network through ASR experiments on the real-world far-field data where users are interacting with an ASR system in uncontrolled acoustic environments. We show that our multi-channel acoustic model with a frequency aligned network shows up to 18% relative reduction in word error rate. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：传统的语音增强技术，如波束赋形已经知道好处远场语音识别。我们自己的在频域多通道声学建模工作已经由声学模型内共同培养了空间滤波层示出的额外的改进。在本文中，我们进一步发展为强大的多通道自动语音识别（ASR）这个想法，并使用频率对准网络。不像在频域中的仿射层，所提出的频率对准部件防止一个频率窗口影响其它频率仓。我们表明，这种修改不仅显著减少了参数的数量模型，而且，提高了ASR性能。我们调查通过ASR实验上，用户与失控的声学环境ASR系统交互的真实世界的远场数据的频率对准网络的影响。我们表明，在字差错率我们与频率对准网络显示多通道声学模型高达18％的相对减少。</font>
</div>


<hr>
<div id="paper16"> <b>16. Consistency of a Recurrent Language Model With Respect to Incomplete  Decoding</b>  <a href="https://arxiv.org/pdf/2002.02492" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title16" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Welleck%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Sean Welleck</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kulikov%2C+I" target="_blank" rel="noopener" style="color:#0000EE;">Ilia Kulikov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Kim%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jaedeok Kim</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Pang%2C+R+Y" target="_blank" rel="noopener" style="color:#0000EE;">Richard Yuanzhe Pang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Cho%2C+K" target="_blank" rel="noopener" style="color:#0000EE;">Kyunghyun Cho</a><br>
<font size="3">
Abstract: Despite strong performance on a variety of tasks, neural sequence models trained with maximum likelihood have been shown to exhibit issues such as length bias and degenerate repetition. We study the related issue of receiving infinite-length sequences from a recurrent language model when using common decoding algorithms. To analyze this issue, we first define inconsistency of a decoding algorithm, meaning that the algorithm can yield an infinite-length sequence that has zero probability under the model. We prove that commonly used incomplete decoding algorithms - greedy search, beam search, top-k sampling, and nucleus sampling - are inconsistent, despite the fact that recurrent language models are trained to produce sequences of finite length. Based on these insights, we propose two remedies which address inconsistency: consistent variants of top-k and nucleus sampling, and a self-terminating recurrent language model. Empirical results show that inconsistency occurs in practice, and that the proposed methods prevent inconsistency. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：尽管在各种任务的强大的性能，具有最大似然训练的神经序列模型已显示表现出的问题，如长度偏差和退化重复。我们研究使用常见的解码算法时，从经常性的语言模型接收无限长序列的相关问题。为了分析这个问题，我们首先定义的解码算法的不一致，这意味着该算法可以产生一个具有模型下零概率无限长度的序列。我们证明了常用的不完整的解码算法 - 贪婪搜索，波束搜索，前k个采样，和细胞核采样 - 不一致，尽管事实上，经常性的语言模型被训练来有限长度的生产序列。根据这些分析，我们提出了两种补救措施，地址不一致：前k和核取样，并自终止复发语言模型的一致变种。实证结果表明，发生矛盾的做法，而且所提出的方法防止不一致。</font>
</div>


<hr>
<p><font style="color:red;">注：中文为机器翻译结果！</font></p>

    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>PROCJX
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://procjx.github.io/2020/02/10/%E3%80%90arxiv%E8%AE%BA%E6%96%87%E3%80%91%20Computation%20and%20Language%202020-02-10/" title="【arxiv论文】 Computation and Language 2020-02-10">https://procjx.github.io/2020/02/10/%E3%80%90arxiv%E8%AE%BA%E6%96%87%E3%80%91%20Computation%20and%20Language%202020-02-10/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-CN" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">

        
        

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
                <a href="/2020/02/08/%E7%BB%BC%E8%BF%B0%E7%B1%BB%E8%AE%BA%E6%96%87/" rel="next" title="综述类论文">
                  <i class="fa fa-chevron-left"></i> 综述类论文
                </a>
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
                <a href="/2020/02/10/%E3%80%90arxiv%E8%AE%BA%E6%96%87%E3%80%91%20Computer%20Vision%20and%20Pattern%20Recognition%202020-02-10/" rel="prev" title="【arxiv论文】 Computer Vision and Pattern Recognition 2020-02-10">
                  【arxiv论文】 Computer Vision and Pattern Recognition 2020-02-10 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>

        
        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- procjx-wenzhang -->
<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-1179774715076800"
     data-ad-slot="9197824246"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>


      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    <div class="comments" id="gitalk-container"></div>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#目录"><span class="nav-number">1.</span> <span class="nav-text">目录</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#摘要"><span class="nav-number">2.</span> <span class="nav-text">摘要</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <img class="site-author-image" itemprop="image" alt="PROCJX"
    src="/images/procjx.png">
  <p class="site-author-name" itemprop="name">PROCJX</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">348</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">13</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">71</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/procjx" title="GitHub &amp;rarr; https:&#x2F;&#x2F;github.com&#x2F;procjx" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:procjx@gmail.com" title="E-Mail &amp;rarr; mailto:procjx@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
  </div>



      </div>


<!--
      
        <script type="text/javascript" charset="utf-8" src="/js/tagcloud.js"></script>
        <script type="text/javascript" charset="utf-8" src="/js/tagcanvas.js"></script>
        <div class="widget-wrap">
            <h3 class="widget-title">标签云</h3>
            <div id="myCanvasContainer" class="widget tagcloud">
                <canvas width="250" height="250" id="resCanvas" style="width=100%">
                    <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/AAAI/" rel="tag">AAAI</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ACL/" rel="tag">ACL</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Accepted-Papers/" rel="tag">Accepted Papers</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ArXiv/" rel="tag">ArXiv</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/BERT/" rel="tag">BERT</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CS20SI/" rel="tag">CS20SI</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CS224d/" rel="tag">CS224d</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CS231n/" rel="tag">CS231n</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CVPR/" rel="tag">CVPR</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Context/" rel="tag">Context</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Cross-Lingual/" rel="tag">Cross Lingual</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Dialog-System/" rel="tag">Dialog System</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Discourse/" rel="tag">Discourse</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Discourse-Ranking/" rel="tag">Discourse Ranking</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Discourse-Structure/" rel="tag">Discourse Structure</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Document-NMT/" rel="tag">Document NMT</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/EMNLP/" rel="tag">EMNLP</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Extractive/" rel="tag">Extractive</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ICLR/" rel="tag">ICLR</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ICML/" rel="tag">ICML</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/IJCAI/" rel="tag">IJCAI</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Inter-Sentence/" rel="tag">Inter-Sentence</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Keyphrase-Generation/" rel="tag">Keyphrase Generation</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NAACL/" rel="tag">NAACL</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NIPS/" rel="tag">NIPS</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NMT/" rel="tag">NMT</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Neural-Relation-Extraction/" rel="tag">Neural Relation Extraction</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RST/" rel="tag">RST</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Relation-Constraints/" rel="tag">Relation Constraints</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Summarization/" rel="tag">Summarization</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Translation/" rel="tag">Translation</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Word-Translation/" rel="tag">Word Translation</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/alias/" rel="tag">alias</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/git/" rel="tag">git</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pip/" rel="tag">pip</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/" rel="tag">python</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/screen/" rel="tag">screen</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/shell/" rel="tag">shell</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tgz/" rel="tag">tgz</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tts/" rel="tag">tts</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%86%92%E6%B3%A1/" rel="tag">冒泡</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F/" rel="tag">冒泡排序</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%86%99%E4%BD%9C%E5%8A%A9%E6%89%8B/" rel="tag">写作助手</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8E%8B%E7%BC%A9/" rel="tag">压缩</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6/" rel="tag">发送邮件</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%90%88%E5%B9%B6%E6%8E%92%E5%BA%8F/" rel="tag">合并排序</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%90%8E%E5%8F%B0/" rel="tag">后台</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9F%BA%E6%95%B0%E6%8E%92%E5%BA%8F/" rel="tag">基数排序</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F/" rel="tag">希尔排序</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BD%92%E5%B9%B6/" rel="tag">归并</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/" rel="tag">归并排序</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/" rel="tag">快速排序</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%89%B9%E9%87%8F/" rel="tag">批量</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%89%B9%E9%87%8F%E5%88%A0%E9%99%A4/" rel="tag">批量删除</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8E%92%E5%BA%8F/" rel="tag">排序</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8F%92%E5%85%A5/" rel="tag">插入</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F/" rel="tag">插入排序</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%99%E7%A8%8B/" rel="tag">教程</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%96%90%E6%B3%A2%E9%82%A3%E5%A5%91%E6%95%B0%E5%88%97/" rel="tag">斐波那契数列</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9D%80%E6%AD%BB%E8%BF%9B%E7%A8%8B/" rel="tag">杀死进程</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B1%89%E8%AF%BA%E5%A1%94/" rel="tag">汉诺塔</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%AE%97%E6%B3%95/" rel="tag">算法</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%A7%A3%E5%8E%8B/" rel="tag">解压</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%B0%B7%E6%AD%8C%E7%BF%BB%E8%AF%91/" rel="tag">谷歌翻译</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%BF%AD%E4%BB%A3%E5%9B%9E%E7%BF%BB/" rel="tag">迭代回翻</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%80%89%E6%8B%A9/" rel="tag">选择</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F/" rel="tag">选择排序</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%99%84%E4%BB%B6/" rel="tag">附件</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%9D%9E%E7%9B%91%E7%9D%A3/" rel="tag">非监督</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%A2%86%E5%9F%9F%E9%80%82%E5%BA%94/" rel="tag">领域适应</a><span class="tag-list-count">1</span></li></ul>
                </canvas>
            </div>
        </div>
        
-->
        
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- procjx-hengfu -->
<!--
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-1179774715076800"
     data-ad-slot="9879871597"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
-->

<!-- procjx-chuizhi -->
<!--
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-1179774715076800"
     data-ad-slot="1662238719"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
-->

<!-- procjx-zhengfangxing -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-1179774715076800"
     data-ad-slot="6699421902"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">PROCJX</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.0.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.4.2
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>












        
      </div>
    </footer>
  </div>

  
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/pisces.js"></script>
<script src="/js/next-boot.js"></script>



  
  <script>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>




  <script src="/js/local-search.js"></script>













  

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID: '2286ab64f5194d9d79ce',
      clientSecret: 'f912492bec2391664b40478f50f2f943376768d6',
      repo: 'procjx.github.io',
      owner: 'procjx',
      admin: ['procjx'],
      id: '63a531a3f5678f16f8a4fff798366555',
        language: 'zh-CN',
      distractionFreeMode: 'true'
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>
</html>
