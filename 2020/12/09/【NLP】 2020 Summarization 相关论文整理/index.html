<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/procjx.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/procjxfavicon32x32.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/procjxfavicon16x16.ico">
  <link rel="mask-icon" href="/images/procjx.png" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '7.4.2',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":true,"show_result":true,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    },
    sidebarPadding: 40
  };
</script>

<!-- Google Adsense -->
<!--
<script async src="//pagead2.googlesyndication.com/
pagead/js/adsbygoogle.js"></script>
<script>
(adsbygoogle = window.adsbygoogle || []).push({
google_ad_client: "pub-1179774715076800",
enable_page_level_ads: true
});
</script>
-->

<script data-ad-client="ca-pub-1179774715076800" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>


<meta name="google-site-verification" content="cEiGwg0T8Rj5msmuEcGYZTh5nnf05EhCXy0gp2Ml5BI" />
<meta name="baidu-site-verification" content="noSKHe8MJs" />

  <meta name="description" content="目录  1. MultiSumm: Towards a Unified Model for Multi-Lingual Abstractive Summarization, AAAI 2020 [PDF] 摘要  2. Narrative Planning Model Acquisition from Text Summaries and Descriptions, AAAI 2020 [PDF]">
<meta property="og:type" content="article">
<meta property="og:title" content="【NLP】 2020 Summarization 相关论文整理">
<meta property="og:url" content="https:&#x2F;&#x2F;procjx.github.io&#x2F;2020&#x2F;12&#x2F;09&#x2F;%E3%80%90NLP%E3%80%91%202020%20Summarization%20%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86&#x2F;index.html">
<meta property="og:site_name" content="PROCJX&#39;s BLOGS">
<meta property="og:description" content="目录  1. MultiSumm: Towards a Unified Model for Multi-Lingual Abstractive Summarization, AAAI 2020 [PDF] 摘要  2. Narrative Planning Model Acquisition from Text Summaries and Descriptions, AAAI 2020 [PDF]">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2020-12-09T13:46:56.839Z">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://procjx.github.io/2020/12/09/%E3%80%90NLP%E3%80%91%202020%20Summarization%20%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>【NLP】 2020 Summarization 相关论文整理 | PROCJX's BLOGS</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">PROCJX's BLOGS</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <h1 class="site-subtitle" itemprop="description">WITH LOVE OF WORLD</h1>
      
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
        <li class="menu-item menu-item-resources">

    <a href="/resources/" rel="section"><i class="fa fa-fw fa-download"></i>资源</a>

  </li>
        <li class="menu-item menu-item-arxiv">

    <a href="/arxiv/" rel="section"><i class="fa fa-fw fa-file-pdf-o"></i>arxiv论文</a>

  </li>
        <li class="menu-item menu-item-deadline">

    <a href="/deadline/" rel="section"><i class="fa fa-fw fa-calendar"></i>会议截稿</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="搜索..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://procjx.github.io/2020/12/09/%E3%80%90NLP%E3%80%91%202020%20Summarization%20%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/procjx.png">
      <meta itemprop="name" content="PROCJX">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PROCJX's BLOGS">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          【NLP】 2020 Summarization 相关论文整理
        </h2>

        <div class="post-meta">
        
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-12-09 21:44:47 / 修改时间：21:46:56" itemprop="dateCreated datePublished" datetime="2020-12-09T21:44:47+08:00">2020-12-09</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AC%E8%AE%BA%E6%96%87/" itemprop="url" rel="index">
                    <span itemprop="name">AC论文</span>
                  </a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AC%E8%AE%BA%E6%96%87/NLP/" itemprop="url" rel="index">
                    <span itemprop="name">NLP</span>
                  </a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
              <span>122k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
              <span>3:24</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a><div style="color:red;">目录</div></h1><font size="4">
<div id="title1">
<b>1.</b> MultiSumm: Towards a Unified Model for Multi-Lingual Abstractive Summarization, AAAI 2020 <a href="https://aaai.org/ojs/index.php/AAAI/article/view/5328/5184" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper1" style="color:#0000EE;">摘要</a><br></div>
<div id="title2">
<b>2.</b> Narrative Planning Model Acquisition from Text Summaries and Descriptions, AAAI 2020 <a href="https://aaai.org/ojs/index.php/AAAI/article/view/5534/5390" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper2" style="color:#0000EE;">摘要</a><br></div>
<div id="title3">
<b>3.</b> TemPEST: Soft Template-Based Personalized EDM Subject Generation through Collaborative Summarization, AAAI 2020 <a href="https://aaai.org/ojs/index.php/AAAI/article/view/6252/6108" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper3" style="color:#0000EE;">摘要</a><br></div>
<div id="title4">
<b>4.</b> Joint Learning of Answer Selection and Answer Summary Generation in Community Question Answering, AAAI 2020 <a href="https://aaai.org/ojs/index.php/AAAI/article/view/6266/6122" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper4" style="color:#0000EE;">摘要</a><br></div>
<div id="title5">
<b>5.</b> Document Summarization with VHTM: Variational Hierarchical Topic-Aware Mechanism, AAAI 2020 <a href="https://aaai.org/ojs/index.php/AAAI/article/view/6277/6133" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper5" style="color:#0000EE;">摘要</a><br></div>
<div id="title6">
<b>6.</b> SemSUM: Semantic Dependency Guided Neural Abstractive Summarization, AAAI 2020 <a href="https://aaai.org/ojs/index.php/AAAI/article/view/6312/6168" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper6" style="color:#0000EE;">摘要</a><br></div>
<div id="title7">
<b>7.</b> Aspect-Aware Multimodal Summarization for Chinese E-Commerce Products, AAAI 2020 <a href="https://aaai.org/ojs/index.php/AAAI/article/view/6332/6188" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper7" style="color:#0000EE;">摘要</a><br></div>
<div id="title8">
<b>8.</b> Keywords-Guided Abstractive Sentence Summarization, AAAI 2020 <a href="https://aaai.org/ojs/index.php/AAAI/article/view/6333/6189" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper8" style="color:#0000EE;">摘要</a><br></div>
<div id="title9">
<b>9.</b> Joint Parsing and Generation for Abstractive Summarization, AAAI 2020 <a href="https://aaai.org/ojs/index.php/AAAI/article/view/6419/6275" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper9" style="color:#0000EE;">摘要</a><br></div>
<div id="title10">
<b>10.</b> Controlling the Amount of Verbatim Copying in Abstractive Summarization, AAAI 2020 <a href="https://aaai.org/ojs/index.php/AAAI/article/view/6420/6276" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper10" style="color:#0000EE;">摘要</a><br></div>
<div id="title11">
<b>11.</b> Copy or Rewrite: Hybrid Summarization with Hierarchical Reinforcement Learning, AAAI 2020 <a href="https://aaai.org/ojs/index.php/AAAI/article/view/6470/6326" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper11" style="color:#0000EE;">摘要</a><br></div>
<div id="title12">
<b>12.</b> Be Relevant, Non-Redundant, and Timely: Deep Reinforcement Learning for Real-Time Event Summarization, AAAI 2020 <a href="https://aaai.org/ojs/index.php/AAAI/article/view/6483/6339" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper12" style="color:#0000EE;">摘要</a><br></div>
<div id="title13">
<b>13.</b> Weakly-Supervised Opinion Summarization by Leveraging External Information, AAAI 2020 <a href="https://aaai.org/ojs/index.php/AAAI/article/view/6512/6368" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper13" style="color:#0000EE;">摘要</a><br></div>
<div id="title14">
<b>14.</b> Multimodal Summarization with Guidance of Multimodal Reference, AAAI 2020 <a href="https://aaai.org/ojs/index.php/AAAI/article/view/6525/6381" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper14" style="color:#0000EE;">摘要</a><br></div>
<div id="title15">
<b>15.</b> Convolutional Hierarchical Attention Network for Query-Focused Video Summarization, AAAI 2020 <a href="https://aaai.org/ojs/index.php/AAAI/article/view/6929/6783" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper15" style="color:#0000EE;">摘要</a><br></div>
<div id="title16">
<b>16.</b> GRACE: Generating Summary Reports Automatically for Cognitive Assistance in Emergency Response, AAAI 2020 <a href="https://aaai.org/ojs/index.php/AAAI/article/view/7049/6903" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper16" style="color:#0000EE;">摘要</a><br></div>
<div id="title17">
<b>17.</b> Generalized Arc Consistency Algorithms for Table Constraints: A Summary of Algorithmic Ideas, AAAI 2020 <a href="https://aaai.org/ojs/index.php/AAAI/article/view/7086/6940" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper17" style="color:#0000EE;">摘要</a><br></div>
<div id="title18">
<b>18.</b> A Large-Scale Multi-Document Summarization Dataset from the Wikipedia Current Events Portal, ACL 2020 <a href="https://www.aclweb.org/anthology/2020.acl-main.120.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper18" style="color:#0000EE;">摘要</a><br></div>
<div id="title19">
<b>19.</b> Attend, Translate and Summarize: An Efficient Method for Neural Cross-Lingual Summarization, ACL 2020 <a href="https://www.aclweb.org/anthology/2020.acl-main.121.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper19" style="color:#0000EE;">摘要</a><br></div>
<div id="title20">
<b>20.</b> Examining the State-of-the-Art in News Timeline Summarization, ACL 2020 <a href="https://www.aclweb.org/anthology/2020.acl-main.122.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper20" style="color:#0000EE;">摘要</a><br></div>
<div id="title21">
<b>21.</b> SUPERT: Towards New Frontiers in Unsupervised Evaluation Metrics for Multi-Document Summarization, ACL 2020 <a href="https://www.aclweb.org/anthology/2020.acl-main.124.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper21" style="color:#0000EE;">摘要</a><br></div>
<div id="title22">
<b>22.</b> Self-Attention Guided Copy Mechanism for Abstractive Summarization, ACL 2020 <a href="https://www.aclweb.org/anthology/2020.acl-main.125.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper22" style="color:#0000EE;">摘要</a><br></div>
<div id="title23">
<b>23.</b> Attend to Medical Ontologies: Content Selection for Clinical Abstractive Summarization, ACL 2020 <a href="https://www.aclweb.org/anthology/2020.acl-main.172.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper23" style="color:#0000EE;">摘要</a><br></div>
<div id="title24">
<b>24.</b> On Faithfulness and Factuality in Abstractive Summarization, ACL 2020 <a href="https://www.aclweb.org/anthology/2020.acl-main.173.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper24" style="color:#0000EE;">摘要</a><br></div>
<div id="title25">
<b>25.</b> Screenplay Summarization Using Latent Narrative Structure, ACL 2020 <a href="https://www.aclweb.org/anthology/2020.acl-main.174.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper25" style="color:#0000EE;">摘要</a><br></div>
<div id="title26">
<b>26.</b> Unsupervised Opinion Summarization with Noising and Denoising, ACL 2020 <a href="https://www.aclweb.org/anthology/2020.acl-main.175.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper26" style="color:#0000EE;">摘要</a><br></div>
<div id="title27">
<b>27.</b> MATINF: A Jointly Labeled Large-Scale Dataset for Classification, Question Answering and Summarization, ACL 2020 <a href="https://www.aclweb.org/anthology/2020.acl-main.330.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper27" style="color:#0000EE;">摘要</a><br></div>
<div id="title28">
<b>28.</b> From Arguments to Key Points: Towards Automatic Argument Summarization, ACL 2020 <a href="https://www.aclweb.org/anthology/2020.acl-main.371.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper28" style="color:#0000EE;">摘要</a><br></div>
<div id="title29">
<b>29.</b> Facet-Aware Evaluation for Extractive Summarization, ACL 2020 <a href="https://www.aclweb.org/anthology/2020.acl-main.445.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper29" style="color:#0000EE;">摘要</a><br></div>
<div id="title30">
<b>30.</b> A Transformer-based Approach for Source Code Summarization, ACL 2020 <a href="https://www.aclweb.org/anthology/2020.acl-main.449.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper30" style="color:#0000EE;">摘要</a><br></div>
<div id="title31">
<b>31.</b> Asking and Answering Questions to Evaluate the Factual Consistency of Summaries, ACL 2020 <a href="https://www.aclweb.org/anthology/2020.acl-main.450.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper31" style="color:#0000EE;">摘要</a><br></div>
<div id="title32">
<b>32.</b> Discourse-Aware Neural Extractive Text Summarization, ACL 2020 <a href="https://www.aclweb.org/anthology/2020.acl-main.451.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper32" style="color:#0000EE;">摘要</a><br></div>
<div id="title33">
<b>33.</b> Discrete Optimization for Unsupervised Sentence Summarization with Word-Level Extraction, ACL 2020 <a href="https://www.aclweb.org/anthology/2020.acl-main.452.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper33" style="color:#0000EE;">摘要</a><br></div>
<div id="title34">
<b>34.</b> Exploring Content Selection in Summarization of Novel Chapters, ACL 2020 <a href="https://www.aclweb.org/anthology/2020.acl-main.453.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper34" style="color:#0000EE;">摘要</a><br></div>
<div id="title35">
<b>35.</b> FEQA: A Question Answering Evaluation Framework for Faithfulness Assessment in Abstractive Summarization, ACL 2020 <a href="https://www.aclweb.org/anthology/2020.acl-main.454.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper35" style="color:#0000EE;">摘要</a><br></div>
<div id="title36">
<b>36.</b> Fact-based Content Weighting for Evaluating Abstractive Summarisation, ACL 2020 <a href="https://www.aclweb.org/anthology/2020.acl-main.455.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper36" style="color:#0000EE;">摘要</a><br></div>
<div id="title37">
<b>37.</b> Knowledge Graph-Augmented Abstractive Summarization with Semantic-Driven Cloze Reward, ACL 2020 <a href="https://www.aclweb.org/anthology/2020.acl-main.457.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper37" style="color:#0000EE;">摘要</a><br></div>
<div id="title38">
<b>38.</b> Optimizing the Factual Correctness of a Summary: A Study of Summarizing Radiology Reports, ACL 2020 <a href="https://www.aclweb.org/anthology/2020.acl-main.458.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper38" style="color:#0000EE;">摘要</a><br></div>
<div id="title39">
<b>39.</b> The Summary Loop: Learning to Write Abstractive Summaries Without Examples, ACL 2020 <a href="https://www.aclweb.org/anthology/2020.acl-main.460.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper39" style="color:#0000EE;">摘要</a><br></div>
<div id="title40">
<b>40.</b> Unsupervised Opinion Summarization as Copycat-Review Generation, ACL 2020 <a href="https://www.aclweb.org/anthology/2020.acl-main.461.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper40" style="color:#0000EE;">摘要</a><br></div>
<div id="title41">
<b>41.</b> How Does NLP Benefit Legal System: A Summary of Legal Artificial Intelligence, ACL 2020 <a href="https://www.aclweb.org/anthology/2020.acl-main.466.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper41" style="color:#0000EE;">摘要</a><br></div>
<div id="title42">
<b>42.</b> OpinionDigest: A Simple Framework for Opinion Summarization, ACL 2020 <a href="https://www.aclweb.org/anthology/2020.acl-main.513.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper42" style="color:#0000EE;">摘要</a><br></div>
<div id="title43">
<b>43.</b> Composing Elementary Discourse Units in Abstractive Summarization, ACL 2020 <a href="https://www.aclweb.org/anthology/2020.acl-main.551.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper43" style="color:#0000EE;">摘要</a><br></div>
<div id="title44">
<b>44.</b> Extractive Summarization as Text Matching, ACL 2020 <a href="https://www.aclweb.org/anthology/2020.acl-main.552.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper44" style="color:#0000EE;">摘要</a><br></div>
<div id="title45">
<b>45.</b> Heterogeneous Graph Neural Networks for Extractive Document Summarization, ACL 2020 <a href="https://www.aclweb.org/anthology/2020.acl-main.553.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper45" style="color:#0000EE;">摘要</a><br></div>
<div id="title46">
<b>46.</b> Jointly Learning to Align and Summarize for Neural Cross-Lingual Summarization, ACL 2020 <a href="https://www.aclweb.org/anthology/2020.acl-main.554.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper46" style="color:#0000EE;">摘要</a><br></div>
<div id="title47">
<b>47.</b> Leveraging Graph to Improve Abstractive Multi-Document Summarization, ACL 2020 <a href="https://www.aclweb.org/anthology/2020.acl-main.555.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper47" style="color:#0000EE;">摘要</a><br></div>
<div id="title48">
<b>48.</b> Multi-Granularity Interaction Network for Extractive and Abstractive Multi-Document Summarization, ACL 2020 <a href="https://www.aclweb.org/anthology/2020.acl-main.556.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper48" style="color:#0000EE;">摘要</a><br></div>
<div id="title49">
<b>49.</b> Understanding Points of Correspondence between Sentences for Abstractive Summarization, ACL 2020 <a href="https://www.aclweb.org/anthology/2020.acl-srw.26.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper49" style="color:#0000EE;">摘要</a><br></div>
<div id="title50">
<b>50.</b> A Deep Reinforced Model for Zero-Shot Cross-Lingual Summarization with Bilingual Semantic Similarity Rewards, ACL 2020 <a href="https://www.aclweb.org/anthology/2020.ngt-1.7.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper50" style="color:#0000EE;">摘要</a><br></div>
<div id="title51">
<b>51.</b> Multi-document Summarization with Maximal Marginal Relevance-guided Reinforcement Learning, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.emnlp-main.136.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper51" style="color:#0000EE;">摘要</a><br></div>
<div id="title52">
<b>52.</b> Q-learning with Language Model for Edit-based Unsupervised Summarization, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.emnlp-main.34.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper52" style="color:#0000EE;">摘要</a><br></div>
<div id="title53">
<b>53.</b> MLSUM: The Multilingual Summarization Corpus, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.emnlp-main.647.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper53" style="color:#0000EE;">摘要</a><br></div>
<div id="title54">
<b>54.</b> Multistage Fusion with Forget Gate for Multimodal Summarization in Open-Domain Videos, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.emnlp-main.144.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper54" style="color:#0000EE;">摘要</a><br></div>
<div id="title55">
<b>55.</b> Multi-View Sequence-to-Sequence Models with Conversational Structure for Abstractive Dialogue Summarization, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.emnlp-main.336.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper55" style="color:#0000EE;">摘要</a><br></div>
<div id="title56">
<b>56.</b> Intrinsic Evaluation of Summarization Datasets, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.emnlp-main.649.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper56" style="color:#0000EE;">摘要</a><br></div>
<div id="title57">
<b>57.</b> Coarse-to-Fine Query Focused Multi-Document Summarization, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.emnlp-main.296.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper57" style="color:#0000EE;">摘要</a><br></div>
<div id="title58">
<b>58.</b> VMSMO: Learning to Generate Multimodal Summary for Video-based News Articles, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.emnlp-main.752.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper58" style="color:#0000EE;">摘要</a><br></div>
<div id="title59">
<b>59.</b> Pre-training for Abstractive Document Summarization by Reinstating Source Text, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.emnlp-main.297.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper59" style="color:#0000EE;">摘要</a><br></div>
<div id="title60">
<b>60.</b> What Have We Achieved on Text Summarization?, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.emnlp-main.33.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper60" style="color:#0000EE;">摘要</a><br></div>
<div id="title61">
<b>61.</b> Few-Shot Learning for Opinion Summarization, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.emnlp-main.337.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper61" style="color:#0000EE;">摘要</a><br></div>
<div id="title62">
<b>62.</b> Multi-hop Inference for Question-driven Summarization, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.emnlp-main.547.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper62" style="color:#0000EE;">摘要</a><br></div>
<div id="title63">
<b>63.</b> On Extractive and Abstractive Neural Document Summarization with Transformer Language Models, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.emnlp-main.748.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper63" style="color:#0000EE;">摘要</a><br></div>
<div id="title64">
<b>64.</b> Multi-Fact Correction in Abstractive Text Summarization, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.emnlp-main.749.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper64" style="color:#0000EE;">摘要</a><br></div>
<div id="title65">
<b>65.</b> Compressive Summarization with Plausibility and Salience Modeling, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.emnlp-main.507.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper65" style="color:#0000EE;">摘要</a><br></div>
<div id="title66">
<b>66.</b> Evaluating the Factual Consistency of Abstractive Text Summarization, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.emnlp-main.750.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper66" style="color:#0000EE;">摘要</a><br></div>
<div id="title67">
<b>67.</b> Quantitative Argument Summarization and beyond: Cross-Domain Key Point Analysis, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.emnlp-main.3.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper67" style="color:#0000EE;">摘要</a><br></div>
<div id="title68">
<b>68.</b> TESA: A Task in Entity Semantic Aggregation for Abstractive Summarization, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.emnlp-main.646.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper68" style="color:#0000EE;">摘要</a><br></div>
<div id="title69">
<b>69.</b> A Spectral Method for Unsupervised Multi-Document Summarization, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.emnlp-main.32.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper69" style="color:#0000EE;">摘要</a><br></div>
<div id="title70">
<b>70.</b> Unsupervised Reference-Free Summary Quality Evaluation via Contrastive Learning, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.emnlp-main.294.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper70" style="color:#0000EE;">摘要</a><br></div>
<div id="title71">
<b>71.</b> Friendly Topic Assistant for Transformer Based Abstractive Summarization, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.emnlp-main.35.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper71" style="color:#0000EE;">摘要</a><br></div>
<div id="title72">
<b>72.</b> Better Highlighting: Creating Sub-Sentence Summary Highlights, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.emnlp-main.509.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper72" style="color:#0000EE;">摘要</a><br></div>
<div id="title73">
<b>73.</b> Stepwise Extractive Summarization and Planning with Structured Transformers, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.emnlp-main.339.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper73" style="color:#0000EE;">摘要</a><br></div>
<div id="title74">
<b>74.</b> Neural Extractive Summarization with Hierarchical Attentive Heterogeneous Graph Network, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.emnlp-main.295.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper74" style="color:#0000EE;">摘要</a><br></div>
<div id="title75">
<b>75.</b> Re-evaluating Evaluation in Text Summarization, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.emnlp-main.751.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper75" style="color:#0000EE;">摘要</a><br></div>
<div id="title76">
<b>76.</b> Multi-XScience: A Large-scale Dataset for Extreme Multi-document Summarization of Scientific Articles, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.emnlp-main.648.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper76" style="color:#0000EE;">摘要</a><br></div>
<div id="title77">
<b>77.</b> Modeling Content Importance for Summarization with Pre-trained Language Models, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.emnlp-main.293.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper77" style="color:#0000EE;">摘要</a><br></div>
<div id="title78">
<b>78.</b> Factual Error Correction for Abstractive Summarization Models, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.emnlp-main.506.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper78" style="color:#0000EE;">摘要</a><br></div>
<div id="title79">
<b>79.</b> Understanding Neural Abstractive Summarization Models via Uncertainty, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.emnlp-main.508.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper79" style="color:#0000EE;">摘要</a><br></div>
<div id="title80">
<b>80.</b> Learning to Fuse Sentences with Transformers for Summarization, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.emnlp-main.338.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper80" style="color:#0000EE;">摘要</a><br></div>
<div id="title81">
<b>81.</b> Summarizing Text on Any Aspects: A Knowledge-Informed Weakly-Supervised Approach, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.emnlp-main.510.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper81" style="color:#0000EE;">摘要</a><br></div>
<div id="title82">
<b>82.</b> Summarizing Chinese Medical Answer with Graph Convolution Networks and Question-focused Dual Attention, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.2.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper82" style="color:#0000EE;">摘要</a><br></div>
<div id="title83">
<b>83.</b> A Hierarchical Network for Abstractive Meeting Summarization with Cross-Domain Pretraining, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.19.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper83" style="color:#0000EE;">摘要</a><br></div>
<div id="title84">
<b>84.</b> ZEST: Zero-shot Learning from Text Descriptions using Textual Similarity and Visual Summarization, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.50.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper84" style="color:#0000EE;">摘要</a><br></div>
<div id="title85">
<b>85.</b> Conditional Neural Generation using Sub-Aspect Functions for Extractive News Summarization, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.131.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper85" style="color:#0000EE;">摘要</a><br></div>
<div id="title86">
<b>86.</b> Unsupervised Extractive Summarization by Pre-training Hierarchical Transformers, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.161.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper86" style="color:#0000EE;">摘要</a><br></div>
<div id="title87">
<b>87.</b> TED: A Pretrained Unsupervised Summarization Model with Theme Modeling and Denoising, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.168.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper87" style="color:#0000EE;">摘要</a><br></div>
<div id="title88">
<b>88.</b> KLearn: Background Knowledge Inference from Summarization Data, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.188.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper88" style="color:#0000EE;">摘要</a><br></div>
<div id="title89">
<b>89.</b> Reducing the Frequency of Hallucinated Quantities in Abstractive Summaries, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.203.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper89" style="color:#0000EE;">摘要</a><br></div>
<div id="title90">
<b>90.</b> Abstractive Multi-Document Summarization via Joint Learning with Single-Document Summarization, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.231.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper90" style="color:#0000EE;">摘要</a><br></div>
<div id="title91">
<b>91.</b> Corpora Evaluation and System Bias detection in Multi Document Summarization, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.254.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper91" style="color:#0000EE;">摘要</a><br></div>
<div id="title92">
<b>92.</b> Towards Zero Shot Conditional Summarization with Adaptive Multi-task Fine-Tuning, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.289.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper92" style="color:#0000EE;">摘要</a><br></div>
<div id="title93">
<b>93.</b> Document Reranking for Precision Medicine with Neural Matching and Faceted Summarization, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.304.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper93" style="color:#0000EE;">摘要</a><br></div>
<div id="title94">
<b>94.</b> An Empirical Study of Cross-Dataset Evaluation for Neural Summarization Systems, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.329.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper94" style="color:#0000EE;">摘要</a><br></div>
<div id="title95">
<b>95.</b> Dr. Summarize: Global Summarization of Medical Dialogue by Exploiting Local Structures, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.335.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper95" style="color:#0000EE;">摘要</a><br></div>
<div id="title96">
<b>96.</b> WikiLingua: A New Benchmark Dataset for Multilingual Abstractive Summarization, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.360.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper96" style="color:#0000EE;">摘要</a><br></div>
<div id="title97">
<b>97.</b> SupMMD: A Sentence Importance Model for Extractive Summarisation using Maximum Mean Discrepancy, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.367.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper97" style="color:#0000EE;">摘要</a><br></div>
<div id="title98">
<b>98.</b> TLDR: Extreme Summarization of Scientific Documents, EMNLP 2020 <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.428.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper98" style="color:#0000EE;">摘要</a><br></div>
<div id="title99">
<b>99.</b> FSNet: Compression of Deep Convolutional Neural Networks by Filter Summary, ICLR 2020 <a href="https://openreview.net/pdf?id=S1xtORNFwH" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper99" style="color:#0000EE;">摘要</a><br></div>
<div id="title100">
<b>100.</b> k-SDPP: Fixed-Size Video Summarization via Sequential Determinantal Point Processes, IJCAI 2020 <a href="https://www.ijcai.org/proceedings/2020/0108.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper100" style="color:#0000EE;">摘要</a><br></div>
<div id="title101">
<b>101.</b> Neural Entity Summarization with Joint Encoding and Weak Supervision, IJCAI 2020 <a href="https://www.ijcai.org/proceedings/2020/0228.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper101" style="color:#0000EE;">摘要</a><br></div>
<div id="title102">
<b>102.</b> Neural Abstractive Summarization with Structural Attention, IJCAI 2020 <a href="https://www.ijcai.org/proceedings/2020/0514.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper102" style="color:#0000EE;">摘要</a><br></div>
<div id="title103">
<b>103.</b> A Unified Model for Financial Event Classification, Detection and Summarization, IJCAI 2020 <a href="https://www.ijcai.org/proceedings/2020/0644.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper103" style="color:#0000EE;">摘要</a><br></div>
<div id="title104">
<b>104.</b> From Standard Summarization to New Tasks and Beyond: Summarization with Manifold Information, IJCAI 2020 <a href="https://www.ijcai.org/proceedings/2020/0676.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper104" style="color:#0000EE;">摘要</a><br></div>
<div id="title105">
<b>105.</b> Point at the Triple: Generation of Text Summaries from Knowledge Base Triples (Extended Abstract), IJCAI 2020 <a href="https://www.ijcai.org/proceedings/2020/0711.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper105" style="color:#0000EE;">摘要</a><br></div>
</font><a id="more"></a>


<hr>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>                    <!-- procjx-wenzhang2 -->                     <ins class="adsbygoogle" style="display:block; text-align:center;" data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-1179774715076800" data-ad-slot="5367332398"></ins>                     <script>                         (adsbygoogle = window.adsbygoogle || []).push({});                     </script>

<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><div style="color:red;">摘要</div></h1><div id="paper1"> <b>1. MultiSumm: Towards a Unified Model for Multi-Lingual Abstractive Summarization</b>  <a href="https://aaai.org/ojs/index.php/AAAI/article/view/5328/5184" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title1" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;AAAI 2020. AAAI Technical Track: AI and the Web<br>&nbsp;&nbsp;<i>Yue Cao, Xiaojun Wan, Jin-ge Yao, Dian Yu</i><br>
<font size="3">
Automatic text summarization aims at producing a shorter version of the input text that conveys the most important information. However, multi-lingual text summarization, where the goal is to process texts in multiple languages and output summaries in the corresponding languages with a single model, has been rarely studied. In this paper, we present MultiSumm, a novel multi-lingual model for abstractive summarization. The MultiSumm model uses the following training regime: (I) multi-lingual learning that contains language model training, auto-encoder training, translation and back-translation training, and (II) joint summary generation training. We conduct experiments on summarization datasets for five rich-resource languages: English, Chinese, French, Spanish, and German, as well as two low-resource languages: Bosnian and Croatian. Experimental results show that our proposed model significantly outperforms a multi-lingual baseline model. Specifically, our model achieves comparable or even better performance than models trained separately on each language. As an additional contribution, we construct the first summarization dataset for Bosnian and Croatian, containing 177,406 and 204,748 samples, respectively.</font>
<br>
</div>


<hr>
<div id="paper2"> <b>2. Narrative Planning Model Acquisition from Text Summaries and Descriptions</b>  <a href="https://aaai.org/ojs/index.php/AAAI/article/view/5534/5390" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title2" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;AAAI 2020. AAAI Technical Track: Game Playing and Interactive Entertainment<br>&nbsp;&nbsp;<i>Thomas Hayton, Julie Porteous, João Fernando Ferreira, Alan Lindsay</i><br>
<font size="3">
AI Planning has been shown to be a useful approach for the generation of narrative in interactive entertainment systems and games. However, the creation of the underlying narrative domain models is challenging: the well documented AI planning modelling bottleneck is further compounded by the need for authors, who tend to be non-technical, to create content. We seek to support authors in this task by allowing natural language (NL) plot synopses to be used as a starting point from which planning domain models can be automatically acquired. We present a solution which analyses input NL text summaries, and builds structured representations from which a pddl model is output (fully automated or author in-the-loop). We introduce a novel sieve-based approach to pronoun resolution that demonstrates consistently high performance across domains. In the paper we focus on authoring of narrative planning models for use in interactive entertainment systems and games. We show that our approach exhibits comprehensive detection of both actions and objects in the system-extracted domain models, in combination with significant improvement in the accuracy of pronoun resolution due to the use of contextual object information. Our results and an expert user assessment show that our approach enables a reduction in authoring effort required to generate baseline narrative domain models from which variants can be built.</font>
<br>
</div>


<hr>
<div id="paper3"> <b>3. TemPEST: Soft Template-Based Personalized EDM Subject Generation through Collaborative Summarization</b>  <a href="https://aaai.org/ojs/index.php/AAAI/article/view/6252/6108" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title3" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;AAAI 2020. AAAI Technical Track: Natural Language Processing<br>&nbsp;&nbsp;<i>Yu-Hsiu Chen, Pin-Yu Chen, Hong-Han Shuai, Wen-Chih Peng</i><br>
<font size="3">
We address personalized Electronic Direct Mail (EDM) subject generation, which generates an attractive subject line for a product description according to user's preference on different contents or writing styles. Generating personalized EDM subjects has a few notable differences from generating text summaries. The subject has to be not only faithful to the description itself but also attractive to increase the click-through rate. Moreover, different users may have different preferences over the styles of topics. We propose a novel personalized EDM subject generation model named Soft Template-based Personalized EDM Subject Generator (TemPEST) to consider the aforementioned users' characteristics when generating subjects, which contains a soft template-based selective encoder network, a user rating encoder network, a summary decoder network and a rating decoder. Experimental results indicate that TemPEST is able to generate personalized topics and also effectively perform recommending rating reconstruction.</font>
<br>
</div>


<hr>
<div id="paper4"> <b>4. Joint Learning of Answer Selection and Answer Summary Generation in Community Question Answering</b>  <a href="https://aaai.org/ojs/index.php/AAAI/article/view/6266/6122" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title4" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;AAAI 2020. AAAI Technical Track: Natural Language Processing<br>&nbsp;&nbsp;<i>Yang Deng, Wai Lam, Yuexiang Xie, Daoyuan Chen, Yaliang Li, Min Yang, Ying Shen</i><br>
<font size="3">
Community question answering (CQA) gains increasing popularity in both academy and industry recently. However, the redundancy and lengthiness issues of crowdsourced answers limit the performance of answer selection and lead to reading difficulties and misunderstandings for community users. To solve these problems, we tackle the tasks of answer selection and answer summary generation in CQA with a novel joint learning model. Specifically, we design a question-driven pointer-generator network, which exploits the correlation information between question-answer pairs to aid in attending the essential information when generating answer summaries. Meanwhile, we leverage the answer summaries to alleviate noise in original lengthy answers when ranking the relevancy degrees of question-answer pairs. In addition, we construct a new large-scale CQA corpus, WikiHowQA, which contains long answers for answer selection as well as reference summaries for answer summarization. The experimental results show that the joint learning method can effectively address the answer redundancy issue in CQA and achieves state-of-the-art results on both answer selection and text summarization tasks. Furthermore, the proposed model is shown to be of great transferring ability and applicability for resource-poor CQA tasks, which lack of reference answer summaries.</font>
<br>
</div>


<hr>
<div id="paper5"> <b>5. Document Summarization with VHTM: Variational Hierarchical Topic-Aware Mechanism</b>  <a href="https://aaai.org/ojs/index.php/AAAI/article/view/6277/6133" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title5" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;AAAI 2020. AAAI Technical Track: Natural Language Processing<br>&nbsp;&nbsp;<i>Xiyan Fu, Jun Wang, Jinghan Zhang, Jinmao Wei, Zhenglu Yang</i><br>
<font size="3">
Automatic text summarization focuses on distilling summary information from texts. This research field has been considerably explored over the past decades because of its significant role in many natural language processing tasks; however, two challenging issues block its further development: (1) how to yield a summarization model embedding topic inference rather than extending with a pre-trained one and (2) how to merge the latent topics into diverse granularity levels. In this study, we propose a variational hierarchical model to holistically address both issues, dubbed VHTM. Different from the previous work assisted by a pre-trained single-grained topic model, VHTM is the first attempt to jointly accomplish summarization with topic inference via variational encoder-decoder and merge topics into multi-grained levels through topic embedding and attention. Comprehensive experiments validate the superior performance of VHTM compared with the baselines, accompanying with semantically consistent topics.</font>
<br>
</div>


<hr>
<div id="paper6"> <b>6. SemSUM: Semantic Dependency Guided Neural Abstractive Summarization</b>  <a href="https://aaai.org/ojs/index.php/AAAI/article/view/6312/6168" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title6" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;AAAI 2020. AAAI Technical Track: Natural Language Processing<br>&nbsp;&nbsp;<i>Hanqi Jin, Tianming Wang, Xiaojun Wan</i><br>
<font size="3">
In neural abstractive summarization, the generated summaries often face semantic irrelevance and content deviation from the input sentences. In this work, we incorporate semantic dependency graphs about predicate-argument structure of input sentences into neural abstractive summarization for the problem. We propose a novel semantics dependency guided summarization model (SemSUM), which can leverage the information of original input texts and the corresponding semantic dependency graphs in a complementary way to guide summarization process. We evaluate our model on the English Gigaword, DUC 2004 and MSR abstractive sentence summarization datasets. Experiments show that the proposed model improves semantic relevance and reduces content deviation, and also brings significant improvements on automatic evaluation ROUGE metrics.</font>
<br>
</div>


<hr>
<div id="paper7"> <b>7. Aspect-Aware Multimodal Summarization for Chinese E-Commerce Products</b>  <a href="https://aaai.org/ojs/index.php/AAAI/article/view/6332/6188" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title7" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;AAAI 2020. AAAI Technical Track: Natural Language Processing<br>&nbsp;&nbsp;<i>Haoran Li, Peng Yuan, Song Xu, Youzheng Wu, Xiaodong He, Bowen Zhou</i><br>
<font size="3">
We present an abstractive summarization system that produces summary for Chinese e-commerce products. This task is more challenging than general text summarization. First, the appearance of a product typically plays a significant role in customers' decisions to buy the product or not, which requires that the summarization model effectively use the visual information of the product. Furthermore, different products have remarkable features in various aspects, such as “energy efficiency” and “large capacity” for refrigerators. Meanwhile, different customers may care about different aspects. Thus, the summarizer needs to capture the most attractive aspects of a product that resonate with potential purchasers. We propose an aspect-aware multimodal summarization model that can effectively incorporate the visual information and also determine the most salient aspects of a product. We construct a large-scale Chinese e-commerce product summarization dataset that contains approximately 1.4 million manually created product summaries that are paired with detailed product information, including an image, a title, and other textual descriptions for each product. The experimental results on this dataset demonstrate that our models significantly outperform the comparative methods in terms of both the ROUGE score and manual evaluations.</font>
<br>
</div>


<hr>
<div id="paper8"> <b>8. Keywords-Guided Abstractive Sentence Summarization</b>  <a href="https://aaai.org/ojs/index.php/AAAI/article/view/6333/6189" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title8" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;AAAI 2020. AAAI Technical Track: Natural Language Processing<br>&nbsp;&nbsp;<i>Haoran Li, Junnan Zhu, Jiajun Zhang, Chengqing Zong, Xiaodong He</i><br>
<font size="3">
We study the problem of generating a summary for a given sentence. Existing researches on abstractive sentence summarization ignore that keywords in the input sentence provide significant clues for valuable content, and humans tend to write summaries covering these keywords. In this paper, we propose an abstractive sentence summarization method by applying guidance signals of keywords to both the encoder and the decoder in the sequence-to-sequence model. A multi-task learning framework is adopted to jointly learn to extract keywords and generate a summary for the input sentence. We apply keywords-guided selective encoding strategies to filter source information by investigating the interactions between the input sentence and the keywords. We extend pointer-generator network by a dual-attention and a dual-copy mechanism, which can integrate the semantics of the input sentence and the keywords, and copy words from both the input sentence and the keywords. We demonstrate that multi-task learning and keywords-oriented guidance facilitate sentence summarization task, achieving better performance than the competitive models on the English Gigaword sentence summarization dataset.</font>
<br>
</div>


<hr>
<div id="paper9"> <b>9. Joint Parsing and Generation for Abstractive Summarization</b>  <a href="https://aaai.org/ojs/index.php/AAAI/article/view/6419/6275" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title9" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;AAAI 2020. AAAI Technical Track: Natural Language Processing<br>&nbsp;&nbsp;<i>Kaiqiang Song, Logan Lebanoff, Qipeng Guo, Xipeng Qiu, Xiangyang Xue, Chen Li, Dong Yu, Fei Liu</i><br>
<font size="3">
Sentences produced by abstractive summarization systems can be ungrammatical and fail to preserve the original meanings, despite being locally fluent. In this paper we propose to remedy this problem by jointly generating a sentence and its syntactic dependency parse while performing abstraction. If generating a word can introduce an erroneous relation to the summary, the behavior must be discouraged. The proposed method thus holds promise for producing grammatical sentences and encouraging the summary to stay true-to-original. Our contributions of this work are twofold. First, we present a novel neural architecture for abstractive summarization that combines a sequential decoder with a tree-based decoder in a synchronized manner to generate a summary sentence and its syntactic parse. Secondly, we describe a novel human evaluation protocol to assess if, and to what extent, a summary remains true to its original meanings. We evaluate our method on a number of summarization datasets and demonstrate competitive results against strong baselines.</font>
<br>
</div>


<hr>
<div id="paper10"> <b>10. Controlling the Amount of Verbatim Copying in Abstractive Summarization</b>  <a href="https://aaai.org/ojs/index.php/AAAI/article/view/6420/6276" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title10" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;AAAI 2020. AAAI Technical Track: Natural Language Processing<br>&nbsp;&nbsp;<i>Kaiqiang Song, Bingqing Wang, Zhe Feng, Ren Liu, Fei Liu</i><br>
<font size="3">
An abstract must not change the meaning of the original text. A single most effective way to achieve that is to increase the amount of copying while still allowing for text abstraction. Human editors can usually exercise control over copying, resulting in summaries that are more extractive than abstractive, or vice versa. However, it remains poorly understood whether modern neural abstractive summarizers can provide the same flexibility, i.e., learning from single reference summaries to generate multiple summary hypotheses with varying degrees of copying. In this paper, we present a neural summarization model that, by learning from single human abstracts, can produce a broad spectrum of summaries ranging from purely extractive to highly generative ones. We frame the task of summarization as language modeling and exploit alternative mechanisms to generate summary hypotheses. Our method allows for control over copying during both training and decoding stages of a neural summarization model. Through extensive experiments we illustrate the significance of our proposed method on controlling the amount of verbatim copying and achieve competitive results over strong baselines. Our analysis further reveals interesting and unobvious facts.</font>
<br>
</div>


<hr>
<div id="paper11"> <b>11. Copy or Rewrite: Hybrid Summarization with Hierarchical Reinforcement Learning</b>  <a href="https://aaai.org/ojs/index.php/AAAI/article/view/6470/6326" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title11" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;AAAI 2020. AAAI Technical Track: Natural Language Processing<br>&nbsp;&nbsp;<i>Liqiang Xiao, Lu Wang, Hao He, Yaohui Jin</i><br>
<font size="3">
Jointly using the extractive and abstractive summarization methods can combine their complementary advantages, generating both informative and concise summary. Existing methods that adopt an extract-then-abstract strategy have achieved impressive results, yet they suffer from the information loss in the abstraction step because they compress all the selected sentences without distinguish. Especially when the whole sentence is summary-worthy, salient content would be lost by compression. To address this problem, we propose HySum, a hybrid framework for summarization that can flexibly switch between copying sentence and rewriting sentence according to the degree of redundancy. In this way, our approach can effectively combine the advantages of two branches of summarization, juggling informativity and conciseness. Moreover, we based on Hierarchical Reinforcement Learning, propose an end-to-end reinforcing method to bridge together the extraction module and rewriting module, which can enhance the cooperation between them. Automatic evaluation shows that our approach significantly outperforms the state-of-the-arts on the CNN/DailyMail corpus. Human evaluation also demonstrates that our generated summaries are more informative and concise than popular models.</font>
<br>
</div>


<hr>
<div id="paper12"> <b>12. Be Relevant, Non-Redundant, and Timely: Deep Reinforcement Learning for Real-Time Event Summarization</b>  <a href="https://aaai.org/ojs/index.php/AAAI/article/view/6483/6339" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title12" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;AAAI 2020. AAAI Technical Track: Natural Language Processing<br>&nbsp;&nbsp;<i>Min Yang, Chengming Li, Fei Sun, Zhou Zhao, Ying Shen, Chenglin Wu</i><br>
<font size="3">
Real-time event summarization is an essential task in natural language processing and information retrieval areas. Despite the progress of previous work, generating relevant, non-redundant, and timely event summaries remains challenging in practice. In this paper, we propose a Deep Reinforcement learning framework for real-time Event Summarization (DRES), which shows promising performance for resolving all three challenges (i.e., relevance, non-redundancy, timeliness) in a unified framework. Specifically, we (i) devise a hierarchical cross-attention network with intra- and inter-document attentions to integrate important semantic features within and between the query and input document for better text matching. In addition, relevance prediction is leveraged as an auxiliary task to strengthen the document modeling and help to extract relevant documents; (ii) propose a multi-topic dynamic memory network to capture the sequential patterns of different topics belonging to the event of interest and temporally memorize the input facts from the evolving document stream, avoiding extracting redundant information at each time step; (iii) consider both historical dependencies and future uncertainty of the document stream for generating relevant and timely summaries by exploiting the reinforcement learning technique. Experimental results on two real-world datasets have demonstrated the advantages of DRES model with significant improvement in generating relevant, non-redundant, and timely event summaries against the state-of-the-arts.</font>
<br>
</div>


<hr>
<div id="paper13"> <b>13. Weakly-Supervised Opinion Summarization by Leveraging External Information</b>  <a href="https://aaai.org/ojs/index.php/AAAI/article/view/6512/6368" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title13" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;AAAI 2020. AAAI Technical Track: Natural Language Processing<br>&nbsp;&nbsp;<i>Chao Zhao, Snigdha Chaturvedi</i><br>
<font size="3">
Opinion summarization from online product reviews is a challenging task, which involves identifying opinions related to various aspects of the product being reviewed. While previous works require additional human effort to identify relevant aspects, we instead apply domain knowledge from external sources to automatically achieve the same goal. This work proposes AspMem, a generative method that contains an array of memory cells to store aspect-related knowledge. This explicit memory can help obtain a better opinion representation and infer the aspect information more precisely. We evaluate this method on both aspect identification and opinion summarization tasks. Our experiments show that AspMem outperforms the state-of-the-art methods even though, unlike the baselines, it does not rely on human supervision which is carefully handcrafted for the given tasks.</font>
<br>
</div>


<hr>
<div id="paper14"> <b>14. Multimodal Summarization with Guidance of Multimodal Reference</b>  <a href="https://aaai.org/ojs/index.php/AAAI/article/view/6525/6381" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title14" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;AAAI 2020. AAAI Technical Track: Natural Language Processing<br>&nbsp;&nbsp;<i>Junnan Zhu, Yu Zhou, Jiajun Zhang, Haoran Li, Chengqing Zong, Changliang Li</i><br>
<font size="3">
Multimodal summarization with multimodal output (MSMO) is to generate a multimodal summary for a multimodal news report, which has been proven to effectively improve users' satisfaction. The existing MSMO methods are trained by the target of text modality, leading to the modality-bias problem that ignores the quality of model-selected image during training. To alleviate this problem, we propose a multimodal objective function with the guidance of multimodal reference to use the loss from the summary generation and the image selection. Due to the lack of multimodal reference data, we present two strategies, i.e., ROUGE-ranking and Order-ranking, to construct the multimodal reference by extending the text reference. Meanwhile, to better evaluate multimodal outputs, we propose a novel evaluation metric based on joint multimodal representation, projecting the model output and multimodal reference into a joint semantic space during evaluation. Experimental results have shown that our proposed model achieves the new state-of-the-art on both automatic and manual evaluation metrics. Besides, our proposed evaluation method can effectively improve the correlation with human judgments.</font>
<br>
</div>


<hr>
<div id="paper15"> <b>15. Convolutional Hierarchical Attention Network for Query-Focused Video Summarization</b>  <a href="https://aaai.org/ojs/index.php/AAAI/article/view/6929/6783" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title15" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;AAAI 2020. AAAI Technical Track: Vision<br>&nbsp;&nbsp;<i>Shuwen Xiao, Zhou Zhao, Zijian Zhang, Xiaohui Yan, Min Yang</i><br>
<font size="3">
Previous approaches for video summarization mainly concentrate on finding the most diverse and representative visual contents as video summary without considering the user's preference. This paper addresses the task of query-focused video summarization, which takes user's query and a long video as inputs and aims to generate a query-focused video summary. In this paper, we consider the task as a problem of computing similarity between video shots and query. To this end, we propose a method, named Convolutional Hierarchical Attention Network (CHAN), which consists of two parts: feature encoding network and query-relevance computing module. In the encoding network, we employ a convolutional network with local self-attention mechanism and query-aware global attention mechanism to learns visual information of each shot. The encoded features will be sent to query-relevance computing module to generate query-focused video summary. Extensive experiments on the benchmark dataset demonstrate the competitive performance and show the effectiveness of our approach.</font>
<br>
</div>


<hr>
<div id="paper16"> <b>16. GRACE: Generating Summary Reports Automatically for Cognitive Assistance in Emergency Response</b>  <a href="https://aaai.org/ojs/index.php/AAAI/article/view/7049/6903" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title16" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;AAAI 2020. IAAI Technical Track: Emerging Papers<br>&nbsp;&nbsp;<i>M. Arif Rahman, Sarah Masud Preum, Ronald D. Williams, Homa Alemzadeh, John A. Stankovic</i><br>
<font size="3">
EMS (emergency medical service) plays an important role in saving lives in emergency and accident situations. When first responders, including EMS providers and firefighters, arrive at an incident, they communicate with the patients (if conscious), family members and other witnesses, other first responders, and the command center. The first responders utilize a microphone and headset to support these communications. After the incident, the first responders are required to document the incident by filling out a form. Today, this is performed manually. Manual documentation of patient summary report is time-consuming, tedious, and error-prone. We have addressed these form filling problems by transcribing the audio from the scene, identifying the relevant information from all the conversations, and automatically filling out the form. Informal survey of first responders indicate that this application would be exceedingly helpful to them. Results show that we can fill out a model summary report form with an F1 score as high as 94%, 78%, 96%, and 83% when the data is noise-free audio, noisy audio, noise-free textual narratives, and noisy textual narratives, respectively.</font>
<br>
</div>


<hr>
<div id="paper17"> <b>17. Generalized Arc Consistency Algorithms for Table Constraints: A Summary of Algorithmic Ideas</b>  <a href="https://aaai.org/ojs/index.php/AAAI/article/view/7086/6940" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title17" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;AAAI 2020. Senior Member Presentation Track: Summary Talks<br>&nbsp;&nbsp;<i>Roland H. C. Yap, Wei Xia, Ruiwei Wang</i><br>
<font size="3">
Constraint Programming is a powerful paradigm to model and solve combinatorial problems. While there are many kinds of constraints, the table constraint (also called a CSP) is perhaps the most significant—being the most well-studied and has the ability to encode any other constraints defined on finite variables. Thus, designing efficient filtering algorithms on table constraints has attracted significant research efforts. In turn, there have been great improvements in efficiency over time with the evolution and development of AC and GAC algorithms. In this paper, we survey the existing filtering algorithms for table constraint focusing on historically important ideas and recent successful techniques shown to be effective.</font>
<br>
</div>


<hr>
<div id="paper18"> <b>18. A Large-Scale Multi-Document Summarization Dataset from the Wikipedia Current Events Portal</b>  <a href="https://www.aclweb.org/anthology/2020.acl-main.120.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title18" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;ACL 2020. <br>&nbsp;&nbsp;<i>Demian Gholipour Ghalandari, Chris Hokamp, Nghia The Pham, John Glover, Georgiana Ifrim</i><br>
<font size="3">
Multi-document summarization (MDS) aims to compress the content in large document collections into short summaries and has important applications in story clustering for newsfeeds, presentation of search results, and timeline generation. However, there is a lack of datasets that realistically address such use cases at a scale large enough for training supervised models for this task. This work presents a new dataset for MDS that is large both in the total number of document clusters and in the size of individual clusters. We build this dataset by leveraging the Wikipedia Current Events Portal (WCEP), which provides concise and neutral human-written summaries of news events, with links to external source articles. We also automatically extend these source articles by looking for related articles in the Common Crawl archive. We provide a quantitative analysis of the dataset and empirical results for several state-of-the-art MDS techniques.</font>
<br>
</div>


<hr>
<div id="paper19"> <b>19. Attend, Translate and Summarize: An Efficient Method for Neural Cross-Lingual Summarization</b>  <a href="https://www.aclweb.org/anthology/2020.acl-main.121.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title19" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;ACL 2020. <br>&nbsp;&nbsp;<i>Junnan Zhu, Yu Zhou, Jiajun Zhang, Chengqing Zong</i><br>
<font size="3">
Cross-lingual summarization aims at summarizing a document in one language (e.g., Chinese) into another language (e.g., English). In this paper, we propose a novel method inspired by the translation pattern in the process of obtaining a cross-lingual summary. We first attend to some words in the source text, then translate them into the target language, and summarize to get the final summary. Specifically, we first employ the encoder-decoder attention distribution to attend to the source words. Second, we present three strategies to acquire the translation probability, which helps obtain the translation candidates for each source word. Finally, each summary word is generated either from the neural distribution or from the translation candidates of source words. Experimental results on Chinese-to-English and English-to-Chinese summarization tasks have shown that our proposed method can significantly outperform the baselines, achieving comparable performance with the state-of-the-art.</font>
<br>
</div>


<hr>
<div id="paper20"> <b>20. Examining the State-of-the-Art in News Timeline Summarization</b>  <a href="https://www.aclweb.org/anthology/2020.acl-main.122.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title20" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;ACL 2020. <br>&nbsp;&nbsp;<i>Demian Gholipour Ghalandari, Georgiana Ifrim</i><br>
<font size="3">
Previous work on automatic news timeline summarization (TLS) leaves an unclear picture about how this task can generally be approached and how well it is currently solved. This is mostly due to the focus on individual subtasks, such as date selection and date summarization, and to the previous lack of appropriate evaluation metrics for the full TLS task. In this paper, we compare different TLS strategies using appropriate evaluation frameworks, and propose a simple and effective combination of methods that improves over the stateof-the-art on all tested benchmarks. For a more robust evaluation, we also present a new TLS dataset, which is larger and spans longer time periods than previous datasets.</font>
<br>
</div>


<hr>
<div id="paper21"> <b>21. SUPERT: Towards New Frontiers in Unsupervised Evaluation Metrics for Multi-Document Summarization</b>  <a href="https://www.aclweb.org/anthology/2020.acl-main.124.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title21" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;ACL 2020. <br>&nbsp;&nbsp;<i>Yang Gao, Wei Zhao, Steffen Eger</i><br>
<font size="3">
We study unsupervised multi-document summarization evaluation metrics, which require neither human-written reference summaries nor human annotations (e.g. preferences, ratings, etc.). We propose SUPERT, which rates the quality of a summary by measuring its semantic similarity with a pseudo reference summary, i.e. selected salient sentences from the source documents, using contextualized embeddings and soft token alignment techniques. Compared to the state-of-the-art unsupervised evaluation metrics, SUPERT correlates better with human ratings by 18- 39%. Furthermore, we use SUPERT as rewards to guide a neural-based reinforcement learning summarizer, yielding favorable performance compared to the state-of-the-art unsupervised summarizers. All source code is available at https://github.com/yg211/acl20-ref-free-eval.</font>
<br>
</div>


<hr>
<div id="paper22"> <b>22. Self-Attention Guided Copy Mechanism for Abstractive Summarization</b>  <a href="https://www.aclweb.org/anthology/2020.acl-main.125.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title22" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;ACL 2020. <br>&nbsp;&nbsp;<i>Song Xu, Haoran Li, Peng Yuan, Youzheng Wu, Xiaodong He, Bowen Zhou</i><br>
<font size="3">
Copy module has been widely equipped in the recent abstractive summarization models, which facilitates the decoder to extract words from the source into the summary. Generally, the encoder-decoder attention is served as the copy distribution, while how to guarantee that important words in the source are copied remains a challenge. In this work, we propose a Transformer-based model to enhance the copy mechanism. Specifically, we identify the importance of each source word based on the degree centrality with a directed graph built by the self-attention layer in the Transformer. We use the centrality of each source word to guide the copy process explicitly. Experimental results show that the self-attention graph provides useful guidance for the copy distribution. Our proposed models significantly outperform the baseline methods on the CNN/Daily Mail dataset and the Gigaword dataset.</font>
<br>
</div>


<hr>
<div id="paper23"> <b>23. Attend to Medical Ontologies: Content Selection for Clinical Abstractive Summarization</b>  <a href="https://www.aclweb.org/anthology/2020.acl-main.172.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title23" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;ACL 2020. <br>&nbsp;&nbsp;<i>Sajad Sotudeh Gharebagh, Nazli Goharian, Ross Filice</i><br>
<font size="3">
Sequence-to-sequence (seq2seq) network is a well-established model for text summarization task. It can learn to produce readable content; however, it falls short in effectively identifying key regions of the source. In this paper, we approach the content selection problem for clinical abstractive summarization by augmenting salient ontological terms into the summarizer. Our experiments on two publicly available clinical data sets (107,372 reports of MIMIC-CXR, and 3,366 reports of OpenI) show that our model statistically significantly boosts state-of-the-art results in terms of ROUGE metrics (with improvements: 2.9% RG-1, 2.5% RG-2, 1.9% RG-L), in the healthcare domain where any range of improvement impacts patients’ welfare.</font>
<br>
</div>


<hr>
<div id="paper24"> <b>24. On Faithfulness and Factuality in Abstractive Summarization</b>  <a href="https://www.aclweb.org/anthology/2020.acl-main.173.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title24" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;ACL 2020. <br>&nbsp;&nbsp;<i>Joshua Maynez, Shashi Narayan, Bernd Bohnet, Ryan McDonald</i><br>
<font size="3">
It is well known that the standard likelihood training and approximate decoding objectives in neural text generation models lead to less human-like responses for open-ended tasks such as language modeling and story generation. In this paper we have analyzed limitations of these models for abstractive document summarization and found that these models are highly prone to hallucinate content that is unfaithful to the input document. We conducted a large scale human evaluation of several neural abstractive summarization systems to better understand the types of hallucinations they produce. Our human annotators found substantial amounts of hallucinated content in all model generated summaries. However, our analysis does show that pretrained models are better summarizers not only in terms of raw metrics, i.e., ROUGE, but also in generating faithful and factual summaries as evaluated by humans. Furthermore, we show that textual entailment measures better correlate with faithfulness than standard metrics, potentially leading the way to automatic evaluation metrics as well as training and decoding criteria.</font>
<br>
</div>


<hr>
<div id="paper25"> <b>25. Screenplay Summarization Using Latent Narrative Structure</b>  <a href="https://www.aclweb.org/anthology/2020.acl-main.174.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title25" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;ACL 2020. <br>&nbsp;&nbsp;<i>Pinelopi Papalampidi, Frank Keller, Lea Frermann, Mirella Lapata</i><br>
<font size="3">
Most general-purpose extractive summarization models are trained on news articles, which are short and present all important information upfront. As a result, such models are biased on position and often perform a smart selection of sentences from the beginning of the document. When summarizing long narratives, which have complex structure and present information piecemeal, simple position heuristics are not sufficient. In this paper, we propose to explicitly incorporate the underlying structure of narratives into general unsupervised and supervised extractive summarization models. We formalize narrative structure in terms of key narrative events (turning points) and treat it as latent in order to summarize screenplays (i.e., extract an optimal sequence of scenes). Experimental results on the CSI corpus of TV screenplays, which we augment with scene-level summarization labels, show that latent turning points correlate with important aspects of a CSI episode and improve summarization performance over general extractive algorithms leading to more complete and diverse summaries.</font>
<br>
</div>


<hr>
<div id="paper26"> <b>26. Unsupervised Opinion Summarization with Noising and Denoising</b>  <a href="https://www.aclweb.org/anthology/2020.acl-main.175.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title26" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;ACL 2020. <br>&nbsp;&nbsp;<i>Reinald Kim Amplayo, Mirella Lapata</i><br>
<font size="3">
The supervised training of high-capacity models on large datasets containing hundreds of thousands of document-summary pairs is critical to the recent success of deep learning techniques for abstractive summarization. Unfortunately, in most domains (other than news) such training data is not available and cannot be easily sourced. In this paper we enable the use of supervised learning for the setting where there are only documents available (e.g., product or business reviews) without ground truth summaries. We create a synthetic dataset from a corpus of user reviews by sampling a review, pretending it is a summary, and generating noisy versions thereof which we treat as pseudo-review input. We introduce several linguistically motivated noise generation functions and a summarization model which learns to denoise the input and generate the original review. At test time, the model accepts genuine reviews and generates a summary containing salient opinions, treating those that do not reach consensus as noise. Extensive automatic and human evaluation shows that our model brings substantial improvements over both abstractive and extractive baselines.</font>
<br>
</div>


<hr>
<div id="paper27"> <b>27. MATINF: A Jointly Labeled Large-Scale Dataset for Classification, Question Answering and Summarization</b>  <a href="https://www.aclweb.org/anthology/2020.acl-main.330.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title27" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;ACL 2020. <br>&nbsp;&nbsp;<i>Canwen Xu, Jiaxin Pei, Hongtao Wu, Yiyu Liu, Chenliang Li</i><br>
<font size="3">
Recently, large-scale datasets have vastly facilitated the development in nearly all domains of Natural Language Processing. However, there is currently no cross-task dataset in NLP, which hinders the development of multi-task learning. We propose MATINF, the first jointly labeled large-scale dataset for classification, question answering and summarization. MATINF contains 1.07 million question-answer pairs with human-labeled categories and user-generated question descriptions. Based on such rich information, MATINF is applicable for three major NLP tasks, including classification, question answering, and summarization. We benchmark existing methods and a novel multi-task baseline over MATINF to inspire further research. Our comprehensive comparison and experiments over MATINF and other datasets demonstrate the merits held by MATINF.</font>
<br>
</div>


<hr>
<div id="paper28"> <b>28. From Arguments to Key Points: Towards Automatic Argument Summarization</b>  <a href="https://www.aclweb.org/anthology/2020.acl-main.371.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title28" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;ACL 2020. <br>&nbsp;&nbsp;<i>Roy Bar-Haim, Lilach Eden, Roni Friedman, Yoav Kantor, Dan Lahav, Noam Slonim</i><br>
<font size="3">
Generating a concise summary from a large collection of arguments on a given topic is an intriguing yet understudied problem. We propose to represent such summaries as a small set of talking points, termed key points, each scored according to its salience. We show, by analyzing a large dataset of crowd-contributed arguments, that a small number of key points per topic is typically sufficient for covering the vast majority of the arguments. Furthermore, we found that a domain expert can often predict these key points in advance. We study the task of argument-to-key point mapping, and introduce a novel large-scale dataset for this task. We report empirical results for an extensive set of experiments with this dataset, showing promising performance.</font>
<br>
</div>


<hr>
<div id="paper29"> <b>29. Facet-Aware Evaluation for Extractive Summarization</b>  <a href="https://www.aclweb.org/anthology/2020.acl-main.445.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title29" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;ACL 2020. <br>&nbsp;&nbsp;<i>Yuning Mao, Liyuan Liu, Qi Zhu, Xiang Ren, Jiawei Han</i><br>
<font size="3">
Commonly adopted metrics for extractive summarization focus on lexical overlap at the token level. In this paper, we present a facet-aware evaluation setup for better assessment of the information coverage in extracted summaries. Specifically, we treat each sentence in the reference summary as a facet, identify the sentences in the document that express the semantics of each facet as support sentences of the facet, and automatically evaluate extractive summarization methods by comparing the indices of extracted sentences and support sentences of all the facets in the reference summary. To facilitate this new evaluation setup, we construct an extractive version of the CNN/Daily Mail dataset and perform a thorough quantitative investigation, through which we demonstrate that facet-aware evaluation manifests better correlation with human judgment than ROUGE, enables fine-grained evaluation as well as comparative analysis, and reveals valuable insights of state-of-the-art summarization methods. Data can be found at https://github.com/morningmoni/FAR.</font>
<br>
</div>


<hr>
<div id="paper30"> <b>30. A Transformer-based Approach for Source Code Summarization</b>  <a href="https://www.aclweb.org/anthology/2020.acl-main.449.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title30" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;ACL 2020. <br>&nbsp;&nbsp;<i>Wasi Ahmad, Saikat Chakraborty, Baishakhi Ray, Kai-Wei Chang</i><br>
<font size="3">
Generating a readable summary that describes the functionality of a program is known as source code summarization. In this task, learning code representation by modeling the pairwise relationship between code tokens to capture their long-range dependencies is crucial. To learn code representation for summarization, we explore the Transformer model that uses a self-attention mechanism and has shown to be effective in capturing long-range dependencies. In this work, we show that despite the approach is simple, it outperforms the state-of-the-art techniques by a significant margin. We perform extensive analysis and ablation studies that reveal several important findings, e.g., the absolute encoding of source code tokens’ position hinders, while relative encoding significantly improves the summarization performance. We have made our code publicly available to facilitate future research.</font>
<br>
</div>


<hr>
<div id="paper31"> <b>31. Asking and Answering Questions to Evaluate the Factual Consistency of Summaries</b>  <a href="https://www.aclweb.org/anthology/2020.acl-main.450.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title31" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;ACL 2020. <br>&nbsp;&nbsp;<i>Alex Wang, Kyunghyun Cho, Mike Lewis</i><br>
<font size="3">
Practical applications of abstractive summarization models are limited by frequent factual inconsistencies with respect to their input. Existing automatic evaluation metrics for summarization are largely insensitive to such errors. We propose QAGS (pronounced “kags”), an automatic evaluation protocol that is designed to identify factual inconsistencies in a generated summary. QAGS is based on the intuition that if we ask questions about a summary and its source, we will receive similar answers if the summary is factually consistent with the source. To evaluate QAGS, we collect human judgments of factual consistency on model-generated summaries for the CNN/DailyMail (Hermann et al., 2015) and XSUM (Narayan et al., 2018) summarization datasets. QAGS has substantially higher correlations with these judgments than other automatic evaluation metrics. Also, QAGS offers a natural form of interpretability: The answers and questions generated while computing QAGS indicate which tokens of a summary are inconsistent and why. We believe QAGS is a promising tool in automatically generating usable and factually consistent text. Code for QAGS will be available at https://github.com/W4ngatang/qags.</font>
<br>
</div>


<hr>
<div id="paper32"> <b>32. Discourse-Aware Neural Extractive Text Summarization</b>  <a href="https://www.aclweb.org/anthology/2020.acl-main.451.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title32" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;ACL 2020. <br>&nbsp;&nbsp;<i>Jiacheng Xu, Zhe Gan, Yu Cheng, Jingjing Liu</i><br>
<font size="3">
Recently BERT has been adopted for document encoding in state-of-the-art text summarization models. However, sentence-based extractive models often result in redundant or uninformative phrases in the extracted summaries. Also, long-range dependencies throughout a document are not well captured by BERT, which is pre-trained on sentence pairs instead of documents. To address these issues, we present a discourse-aware neural summarization model - DiscoBert. DiscoBert extracts sub-sentential discourse units (instead of sentences) as candidates for extractive selection on a finer granularity. To capture the long-range dependencies among discourse units, structural discourse graphs are constructed based on RST trees and coreference mentions, encoded with Graph Convolutional Networks. Experiments show that the proposed model outperforms state-of-the-art methods by a significant margin on popular summarization benchmarks compared to other BERT-base models.</font>
<br>
</div>


<hr>
<div id="paper33"> <b>33. Discrete Optimization for Unsupervised Sentence Summarization with Word-Level Extraction</b>  <a href="https://www.aclweb.org/anthology/2020.acl-main.452.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title33" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;ACL 2020. <br>&nbsp;&nbsp;<i>Raphael Schumann, Lili Mou, Yao Lu, Olga Vechtomova, Katja Markert</i><br>
<font size="3">
Automatic sentence summarization produces a shorter version of a sentence, while preserving its most important information. A good summary is characterized by language fluency and high information overlap with the source sentence. We model these two aspects in an unsupervised objective function, consisting of language modeling and semantic similarity metrics. We search for a high-scoring summary by discrete optimization. Our proposed method achieves a new state-of-the art for unsupervised sentence summarization according to ROUGE scores. Additionally, we demonstrate that the commonly reported ROUGE F1 metric is sensitive to summary length. Since this is unwillingly exploited in recent work, we emphasize that future evaluation should explicitly group summarization systems by output length brackets.</font>
<br>
</div>


<hr>
<div id="paper34"> <b>34. Exploring Content Selection in Summarization of Novel Chapters</b>  <a href="https://www.aclweb.org/anthology/2020.acl-main.453.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title34" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;ACL 2020. <br>&nbsp;&nbsp;<i>Faisal Ladhak, Bryan Li, Yaser Al-Onaizan, Kathleen McKeown</i><br>
<font size="3">
We present a new summarization task, generating summaries of novel chapters using summary/chapter pairs from online study guides. This is a harder task than the news summarization task, given the chapter length as well as the extreme paraphrasing and generalization found in the summaries. We focus on extractive summarization, which requires the creation of a gold-standard set of extractive summaries. We present a new metric for aligning reference summary sentences with chapter sentences to create gold extracts and also experiment with different alignment methods. Our experiments demonstrate significant improvement over prior alignment approaches for our task as shown through automatic metrics and a crowd-sourced pyramid analysis.</font>
<br>
</div>


<hr>
<div id="paper35"> <b>35. FEQA: A Question Answering Evaluation Framework for Faithfulness Assessment in Abstractive Summarization</b>  <a href="https://www.aclweb.org/anthology/2020.acl-main.454.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title35" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;ACL 2020. <br>&nbsp;&nbsp;<i>Esin Durmus, He He, Mona Diab</i><br>
<font size="3">
Neural abstractive summarization models are prone to generate content inconsistent with the source document, i.e. unfaithful. Existing automatic metrics do not capture such mistakes effectively. We tackle the problem of evaluating faithfulness of a generated summary given its source document. We first collected human annotations of faithfulness for outputs from numerous models on two datasets. We find that current models exhibit a trade-off between abstractiveness and faithfulness: outputs with less word overlap with the source document are more likely to be unfaithful. Next, we propose an automatic question answering (QA) based metric for faithfulness, FEQA, which leverages recent advances in reading comprehension. Given question-answer pairs generated from the summary, a QA model extracts answers from the document; non-matched answers indicate unfaithful information in the summary. Among metrics based on word overlap, embedding similarity, and learned language understanding models, our QA-based metric has significantly higher correlation with human faithfulness scores, especially on highly abstractive summaries.</font>
<br>
</div>


<hr>
<div id="paper36"> <b>36. Fact-based Content Weighting for Evaluating Abstractive Summarisation</b>  <a href="https://www.aclweb.org/anthology/2020.acl-main.455.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title36" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;ACL 2020. <br>&nbsp;&nbsp;<i>Xinnuo Xu, Ondřej Dušek, Jingyi Li, Verena Rieser, Ioannis Konstas</i><br>
<font size="3">
Abstractive summarisation is notoriously hard to evaluate since standard word-overlap-based metrics are insufficient. We introduce a new evaluation metric which is based on fact-level content weighting, i.e. relating the facts of the document to the facts of the summary. We fol- low the assumption that a good summary will reflect all relevant facts, i.e. the ones present in the ground truth (human-generated refer- ence summary). We confirm this hypothe- sis by showing that our weightings are highly correlated to human perception and compare favourably to the recent manual highlight- based metric of Hardy et al. (2019).</font>
<br>
</div>


<hr>
<div id="paper37"> <b>37. Knowledge Graph-Augmented Abstractive Summarization with Semantic-Driven Cloze Reward</b>  <a href="https://www.aclweb.org/anthology/2020.acl-main.457.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title37" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;ACL 2020. <br>&nbsp;&nbsp;<i>Luyang Huang, Lingfei Wu, Lu Wang</i><br>
<font size="3">
Sequence-to-sequence models for abstractive summarization have been studied extensively, yet the generated summaries commonly suffer from fabricated content, and are often found to be near-extractive. We argue that, to address these issues, the summarizer should acquire semantic interpretation over input, e.g., via structured representation, to allow the generation of more informative summaries. In this paper, we present ASGARD, a novel framework for Abstractive Summarization with Graph-Augmentation and semantic-driven RewarD. We propose the use of dual encoders—a sequential document encoder and a graph-structured encoder—to maintain the global context and local characteristics of entities, complementing each other. We further design a reward based on a multiple choice cloze test to drive the model to better capture entity interactions. Results show that our models produce significantly higher ROUGE scores than a variant without knowledge graph as input on both New York Times and CNN/Daily Mail datasets. We also obtain better or comparable performance compared to systems that are fine-tuned from large pretrained language models. Human judges further rate our model outputs as more informative and containing fewer unfaithful errors.</font>
<br>
</div>


<hr>
<div id="paper38"> <b>38. Optimizing the Factual Correctness of a Summary: A Study of Summarizing Radiology Reports</b>  <a href="https://www.aclweb.org/anthology/2020.acl-main.458.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title38" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;ACL 2020. <br>&nbsp;&nbsp;<i>Yuhao Zhang, Derek Merck, Emily Tsai, Christopher D. Manning, Curtis Langlotz</i><br>
<font size="3">
Neural abstractive summarization models are able to generate summaries which have high overlap with human references. However, existing models are not optimized for factual correctness, a critical metric in real-world applications. In this work, we develop a general framework where we evaluate the factual correctness of a generated summary by fact-checking it automatically against its reference using an information extraction module. We further propose a training strategy which optimizes a neural summarization model with a factual correctness reward via reinforcement learning. We apply the proposed method to the summarization of radiology reports, where factual correctness is a key requirement. On two separate datasets collected from hospitals, we show via both automatic and human evaluation that the proposed approach substantially improves the factual correctness and overall quality of outputs over a competitive neural summarization system, producing radiology summaries that approach the quality of human-authored ones.</font>
<br>
</div>


<hr>
<div id="paper39"> <b>39. The Summary Loop: Learning to Write Abstractive Summaries Without Examples</b>  <a href="https://www.aclweb.org/anthology/2020.acl-main.460.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title39" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;ACL 2020. <br>&nbsp;&nbsp;<i>Philippe Laban, Andrew Hsi, John Canny, Marti A. Hearst</i><br>
<font size="3">
This work presents a new approach to unsupervised abstractive summarization based on maximizing a combination of coverage and fluency for a given length constraint. It introduces a novel method that encourages the inclusion of key terms from the original document into the summary: key terms are masked out of the original document and must be filled in by a coverage model using the current generated summary. A novel unsupervised training procedure leverages this coverage model along with a fluency model to generate and score summaries. When tested on popular news summarization datasets, the method outperforms previous unsupervised methods by more than 2 R-1 points, and approaches results of competitive supervised methods. Our model attains higher levels of abstraction with copied passages roughly two times shorter than prior work, and learns to compress and merge sentences without supervision.</font>
<br>
</div>


<hr>
<div id="paper40"> <b>40. Unsupervised Opinion Summarization as Copycat-Review Generation</b>  <a href="https://www.aclweb.org/anthology/2020.acl-main.461.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title40" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;ACL 2020. <br>&nbsp;&nbsp;<i>Arthur Bražinskas, Mirella Lapata, Ivan Titov</i><br>
<font size="3">
Opinion summarization is the task of automatically creating summaries that reflect subjective information expressed in multiple documents, such as product reviews. While the majority of previous work has focused on the extractive setting, i.e., selecting fragments from input reviews to produce a summary, we let the model generate novel sentences and hence produce abstractive summaries. Recent progress in summarization has seen the development of supervised models which rely on large quantities of document-summary pairs. Since such training data is expensive to acquire, we instead consider the unsupervised setting, in other words, we do not use any summaries in training. We define a generative model for a review collection which capitalizes on the intuition that when generating a new review given a set of other reviews of a product, we should be able to control the “amount of novelty” going into the new review or, equivalently, vary the extent to which it deviates from the input. At test time, when generating summaries, we force the novelty to be minimal, and produce a text reflecting consensus opinions. We capture this intuition by defining a hierarchical variational autoencoder model. Both individual reviews and the products they correspond to are associated with stochastic latent codes, and the review generator (“decoder”) has direct access to the text of input reviews through the pointer-generator mechanism. Experiments on Amazon and Yelp datasets, show that setting at test time the review’s latent code to its mean, allows the model to produce fluent and coherent summaries reflecting common opinions.</font>
<br>
</div>


<hr>
<div id="paper41"> <b>41. How Does NLP Benefit Legal System: A Summary of Legal Artificial Intelligence</b>  <a href="https://www.aclweb.org/anthology/2020.acl-main.466.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title41" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;ACL 2020. <br>&nbsp;&nbsp;<i>Haoxi Zhong, Chaojun Xiao, Cunchao Tu, Tianyang Zhang, Zhiyuan Liu, Maosong Sun</i><br>
<font size="3">
Legal Artificial Intelligence (LegalAI) focuses on applying the technology of artificial intelligence, especially natural language processing, to benefit tasks in the legal domain. In recent years, LegalAI has drawn increasing attention rapidly from both AI researchers and legal professionals, as LegalAI is beneficial to the legal system for liberating legal professionals from a maze of paperwork. Legal professionals often think about how to solve tasks from rule-based and symbol-based methods, while NLP researchers concentrate more on data-driven and embedding methods. In this paper, we introduce the history, the current state, and the future directions of research in LegalAI. We illustrate the tasks from the perspectives of legal professionals and NLP researchers and show several representative applications in LegalAI. We conduct experiments and provide an in-depth analysis of the advantages and disadvantages of existing works to explore possible future directions. You can find the implementation of our work from https://github.com/thunlp/CLAIM.</font>
<br>
</div>


<hr>
<div id="paper42"> <b>42. OpinionDigest: A Simple Framework for Opinion Summarization</b>  <a href="https://www.aclweb.org/anthology/2020.acl-main.513.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title42" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;ACL 2020. <br>&nbsp;&nbsp;<i>Yoshihiko Suhara, Xiaolan Wang, Stefanos Angelidis, Wang-Chiew Tan</i><br>
<font size="3">
We present OpinionDigest, an abstractive opinion summarization framework, which does not rely on gold-standard summaries for training. The framework uses an Aspect-based Sentiment Analysis model to extract opinion phrases from reviews, and trains a Transformer model to reconstruct the original reviews from these extractions. At summarization time, we merge extractions from multiple reviews and select the most popular ones. The selected opinions are used as input to the trained Transformer model, which verbalizes them into an opinion summary. OpinionDigest can also generate customized summaries, tailored to specific user needs, by filtering the selected opinions according to their aspect and/or sentiment. Automatic evaluation on Yelp data shows that our framework outperforms competitive baselines. Human studies on two corpora verify that OpinionDigest produces informative summaries and shows promising customization capabilities.</font>
<br>
</div>


<hr>
<div id="paper43"> <b>43. Composing Elementary Discourse Units in Abstractive Summarization</b>  <a href="https://www.aclweb.org/anthology/2020.acl-main.551.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title43" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;ACL 2020. <br>&nbsp;&nbsp;<i>Zhenwen Li, Wenhao Wu, Sujian Li</i><br>
<font size="3">
In this paper, we argue that elementary discourse unit (EDU) is a more appropriate textual unit of content selection than the sentence unit in abstractive summarization. To well handle the problem of composing EDUs into an informative and fluent summary, we propose a novel summarization method that first designs an EDU selection model to extract and group informative EDUs and then an EDU fusion model to fuse the EDUs in each group into one sentence. We also design the reinforcement learning mechanism to use EDU fusion results to reward the EDU selection action, boosting the final summarization performance. Experiments on CNN/Daily Mail have demonstrated the effectiveness of our model.</font>
<br>
</div>


<hr>
<div id="paper44"> <b>44. Extractive Summarization as Text Matching</b>  <a href="https://www.aclweb.org/anthology/2020.acl-main.552.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title44" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;ACL 2020. <br>&nbsp;&nbsp;<i>Ming Zhong, Pengfei Liu, Yiran Chen, Danqing Wang, Xipeng Qiu, Xuanjing Huang</i><br>
<font size="3">
This paper creates a paradigm shift with regard to the way we build neural extractive summarization systems. Instead of following the commonly used framework of extracting sentences individually and modeling the relationship between sentences, we formulate the extractive summarization task as a semantic text matching problem, in which a source document and candidate summaries will be (extracted from the original text) matched in a semantic space. Notably, this paradigm shift to semantic matching framework is well-grounded in our comprehensive analysis of the inherent gap between sentence-level and summary-level extractors based on the property of the dataset. Besides, even instantiating the framework with a simple form of a matching model, we have driven the state-of-the-art extractive result on CNN/DailyMail to a new level (44.41 in ROUGE-1). Experiments on the other five datasets also show the effectiveness of the matching framework. We believe the power of this matching-based summarization framework has not been fully exploited. To encourage more instantiations in the future, we have released our codes, processed dataset, as well as generated summaries in https://github.com/maszhongming/MatchSum.</font>
<br>
</div>


<hr>
<div id="paper45"> <b>45. Heterogeneous Graph Neural Networks for Extractive Document Summarization</b>  <a href="https://www.aclweb.org/anthology/2020.acl-main.553.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title45" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;ACL 2020. <br>&nbsp;&nbsp;<i>Danqing Wang, Pengfei Liu, Yining Zheng, Xipeng Qiu, Xuanjing Huang</i><br>
<font size="3">
As a crucial step in extractive document summarization, learning cross-sentence relations has been explored by a plethora of approaches. An intuitive way is to put them in the graph-based neural network, which has a more complex structure for capturing inter-sentence relationships. In this paper, we present a heterogeneous graph-based neural network for extractive summarization (HETERSUMGRAPH), which contains semantic nodes of different granularity levels apart from sentences. These additional nodes act as the intermediary between sentences and enrich the cross-sentence relations. Besides, our graph structure is flexible in natural extension from a single-document setting to multi-document via introducing document nodes. To our knowledge, we are the first one to introduce different types of nodes into graph-based neural networks for extractive document summarization and perform a comprehensive qualitative analysis to investigate their benefits. The code will be released on Github.</font>
<br>
</div>


<hr>
<div id="paper46"> <b>46. Jointly Learning to Align and Summarize for Neural Cross-Lingual Summarization</b>  <a href="https://www.aclweb.org/anthology/2020.acl-main.554.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title46" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;ACL 2020. <br>&nbsp;&nbsp;<i>Yue Cao, Hui Liu, Xiaojun Wan</i><br>
<font size="3">
Cross-lingual summarization is the task of generating a summary in one language given a text in a different language. Previous works on cross-lingual summarization mainly focus on using pipeline methods or training an end-to-end model using the translated parallel data. However, it is a big challenge for the model to directly learn cross-lingual summarization as it requires learning to understand different languages and learning how to summarize at the same time. In this paper, we propose to ease the cross-lingual summarization training by jointly learning to align and summarize. We design relevant loss functions to train this framework and propose several methods to enhance the isomorphism and cross-lingual transfer between languages. Experimental results show that our model can outperform competitive models in most cases. In addition, we show that our model even has the ability to generate cross-lingual summaries without access to any cross-lingual corpus.</font>
<br>
</div>


<hr>
<div id="paper47"> <b>47. Leveraging Graph to Improve Abstractive Multi-Document Summarization</b>  <a href="https://www.aclweb.org/anthology/2020.acl-main.555.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title47" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;ACL 2020. <br>&nbsp;&nbsp;<i>Wei Li, Xinyan Xiao, Jiachen Liu, Hua Wu, Haifeng Wang, Junping Du</i><br>
<font size="3">
Graphs that capture relations between textual units have great benefits for detecting salient information from multiple documents and generating overall coherent summaries. In this paper, we develop a neural abstractive multi-document summarization (MDS) model which can leverage well-known graph representations of documents such as similarity graph and discourse graph, to more effectively process multiple input documents and produce abstractive summaries. Our model utilizes graphs to encode documents in order to capture cross-document relations, which is crucial to summarizing long documents. Our model can also take advantage of graphs to guide the summary generation process, which is beneficial for generating coherent and concise summaries. Furthermore, pre-trained language models can be easily combined with our model, which further improve the summarization performance significantly. Empirical results on the WikiSum and MultiNews dataset show that the proposed architecture brings substantial improvements over several strong baselines.</font>
<br>
</div>


<hr>
<div id="paper48"> <b>48. Multi-Granularity Interaction Network for Extractive and Abstractive Multi-Document Summarization</b>  <a href="https://www.aclweb.org/anthology/2020.acl-main.556.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title48" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;ACL 2020. <br>&nbsp;&nbsp;<i>Hanqi Jin, Tianming Wang, Xiaojun Wan</i><br>
<font size="3">
In this paper, we propose a multi-granularity interaction network for extractive and abstractive multi-document summarization, which jointly learn semantic representations for words, sentences, and documents. The word representations are used to generate an abstractive summary while the sentence representations are used to produce an extractive summary. We employ attention mechanisms to interact between different granularity of semantic representations, which helps to capture multi-granularity key information and improves the performance of both abstractive and extractive summarization. Experiment results show that our proposed model substantially outperforms all strong baseline methods and achieves the best results on the Multi-News dataset.</font>
<br>
</div>


<hr>
<div id="paper49"> <b>49. Understanding Points of Correspondence between Sentences for Abstractive Summarization</b>  <a href="https://www.aclweb.org/anthology/2020.acl-srw.26.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title49" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;ACL 2020. Student Research Workshop<br>&nbsp;&nbsp;<i>Logan Lebanoff, John Muchovej, Franck Dernoncourt, Doo Soon Kim, Lidan Wang, Walter Chang, Fei Liu</i><br>
<font size="3">
Fusing sentences containing disparate content is a remarkable human ability that helps create informative and succinct summaries. Such a simple task for humans has remained challenging for modern abstractive summarizers, substantially restricting their applicability in real-world scenarios. In this paper, we present an investigation into fusing sentences drawn from a document by introducing the notion of points of correspondence, which are cohesive devices that tie any two sentences together into a coherent text. The types of points of correspondence are delineated by text cohesion theory, covering pronominal and nominal referencing, repetition and beyond. We create a dataset containing the documents, source and fusion sentences, and human annotations of points of correspondence between sentences. Our dataset bridges the gap between coreference resolution and summarization. It is publicly shared to serve as a basis for future work to measure the success of sentence fusion systems.</font>
<br>
</div>


<hr>
<div id="paper50"> <b>50. A Deep Reinforced Model for Zero-Shot Cross-Lingual Summarization with Bilingual Semantic Similarity Rewards</b>  <a href="https://www.aclweb.org/anthology/2020.ngt-1.7.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title50" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;ACL 2020. the Fourth Workshop on Neural Generation and Translation<br>&nbsp;&nbsp;<i>Zi-Yi Dou, Sachin Kumar, Yulia Tsvetkov</i><br>
<font size="3">
Cross-lingual text summarization aims at generating a document summary in one language given input in another language. It is a practically important but under-explored task, primarily due to the dearth of available data. Existing methods resort to machine translation to synthesize training data, but such pipeline approaches suffer from error propagation. In this work, we propose an end-to-end cross-lingual text summarization model. The model uses reinforcement learning to directly optimize a bilingual semantic similarity metric between the summaries generated in a target language and gold summaries in a source language. We also introduce techniques to pre-train the model leveraging monolingual summarization and machine translation objectives. Experimental results in both English–Chinese and English–German cross-lingual summarization settings demonstrate the effectiveness of our methods. In addition, we find that reinforcement learning models with bilingual semantic similarity as rewards generate more fluent sentences than strong baselines.</font>
<br>
</div>


<hr>
<div id="paper51"> <b>51. Multi-document Summarization with Maximal Marginal Relevance-guided Reinforcement Learning</b>  <a href="https://www.aclweb.org/anthology/2020.emnlp-main.136.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title51" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Long Paper<br>&nbsp;&nbsp;<i>Yuning Mao, Yanru Qu, Yiqing Xie, Xiang Ren, Jiawei Han</i><br>
<font size="3">
While neural sequence learning methods have made significant progress in single-document summarization (SDS), they produce unsatisfactory results on multi-document summarization (MDS). We observe two major challenges when adapting SDS advances to MDS: (1) MDS involves larger search space and yet more limited training data, setting obstacles for neural methods to learn adequate representations; (2) MDS needs to resolve higher information redundancy among the source documents, which SDS methods are less effective to handle. To close the gap, we present RL-MMR, Maximal Margin Relevance-guided Reinforcement Learning for MDS, which unifies advanced neural SDS methods and statistical measures used in classical MDS. RL-MMR casts MMR guidance on fewer promising candidates, which restrains the search space and thus leads to better representation learning. Additionally, the explicit redundancy measure in MMR helps the neural representation of the summary to better capture redundancy. Extensive experiments demonstrate that RL-MMR achieves state-of-the-art performance on benchmark MDS datasets. In particular, we show the benefits of incorporating MMR into end-to-end learning when adapting SDS to MDS in terms of both learning effectiveness and efficiency.</font>
<br>
</div>


<hr>
<div id="paper52"> <b>52. Q-learning with Language Model for Edit-based Unsupervised Summarization</b>  <a href="https://www.aclweb.org/anthology/2020.emnlp-main.34.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title52" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Long Paper<br>&nbsp;&nbsp;<i>Ryosuke Kohita, Akifumi Wachi, Yang Zhao, Ryuki Tachibana</i><br>
<font size="3">
Unsupervised methods are promising for abstractive textsummarization in that the parallel corpora is not required. However, their performance is still far from being satisfied, therefore research on promising solutions is on-going. In this paper, we propose a new approach based on Q-learning with an edit-based summarization. The method combines two key modules to form an Editorial Agent and Language Model converter (EALM). The agent predicts edit actions (e.t., delete, keep, and replace), and then the LM converter deterministically generates a summary on the basis of the action signals. Q-learning is leveraged to train the agent to produce proper edit actions. Experimental results show that EALM delivered competitive performance compared with the previous encoder-decoder-based methods, even with truly zero paired data (i.e., no validation set). Defining the task as Q-learning enables us not only to develop a competitive method but also to make the latest techniques in reinforcement learning available for unsupervised summarization. We also conduct qualitative analysis, providing insights into future study on unsupervised summarizers.</font>
<br>
</div>


<hr>
<div id="paper53"> <b>53. MLSUM: The Multilingual Summarization Corpus</b>  <a href="https://www.aclweb.org/anthology/2020.emnlp-main.647.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title53" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Long Paper<br>&nbsp;&nbsp;<i>Thomas Scialom, Paul-Alexis Dray, Sylvain Lamprier, Benjamin Piwowarski, Jacopo Staiano</i><br>
<font size="3">
We present MLSUM, the first large-scale MultiLingual SUMmarization dataset. Obtained from online newspapers, it contains 1.5M+ article/summary pairs in five different languages -- namely, French, German, Spanish, Russian, Turkish. Together with English news articles from the popular CNN/Daily mail dataset, the collected data form a large scale multilingual dataset which can enable new research directions for the text summarization community.We report cross-lingual comparative analyses based on state-of-the-art systems. These highlight existing biases which motivate the use of a multi-lingual dataset.</font>
<br>
</div>


<hr>
<div id="paper54"> <b>54. Multistage Fusion with Forget Gate for Multimodal Summarization in Open-Domain Videos</b>  <a href="https://www.aclweb.org/anthology/2020.emnlp-main.144.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title54" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Long Paper<br>&nbsp;&nbsp;<i>Nayu Liu, Xian Sun, Hongfeng Yu, Wenkai Zhang, Guangluan Xu</i><br>
<font size="3">
Multimodal summarization for open-domain videos is an emerging task, aiming to generate a summary from multisource information (video, audio, transcript). Despite the success of recent multiencoder-decoder frameworks on this task, existing methods lack fine-grained multimodality interactions of multisource inputs. Besides, unlike other multimodal tasks, this task has longer multimodal sequences with more redundancy and noise. To address these two issues, we propose a multistage fusion network with the fusion forget gate module, which builds upon this approach by modeling fine-grained interactions between the modalities through a multistep fusion schema and controlling the flow of redundant information between multimodal long sequences via a forgetting module. Experimental results on the How2 dataset show that our proposed model achieves a new state-of-the-art performance. Comprehensive analysis empirically verifies the effectiveness of our fusion schema and forgetting module on multiple encoder-decoder architectures. Specially, when using high noise ASR transcripts (WER>30%), our model still achieves performance close to the ground-truth transcript model, which reduces manual annotation cost.</font>
<br>
</div>


<hr>
<div id="paper55"> <b>55. Multi-View Sequence-to-Sequence Models with Conversational Structure for Abstractive Dialogue Summarization</b>  <a href="https://www.aclweb.org/anthology/2020.emnlp-main.336.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title55" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Long Paper<br>&nbsp;&nbsp;<i>Jiaao Chen, Diyi Yang</i><br>
<font size="3">
Text summarization is one of the most challenging and interesting problems in NLP. Although much attention has been paid to summarizing structured text like news reports or encyclopedia articles, summarizing conversations---an essential part of human-human/machine interaction where most important pieces of information are scattered across various utterances of different speakers---remains relatively under-investigated. This work proposes a multi-view sequence-to-sequence model by first extracting conversational structures of unstructured daily chats from different views to represent conversations and then utilizing a multi-view decoder to incorporate different views to generate dialogue summaries. Experiments on a large-scale dialogue summarization corpus demonstrated that our methods significantly outperformed previous state-of-the-art models via both automatic evaluations and human judgment. We also discussed specific challenges that current approaches faced with this task. We have publicly released our code at https://github.com/GT-SALT/Multi-View-Seq2Seq.</font>
<br>
</div>


<hr>
<div id="paper56"> <b>56. Intrinsic Evaluation of Summarization Datasets</b>  <a href="https://www.aclweb.org/anthology/2020.emnlp-main.649.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title56" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Long Paper<br>&nbsp;&nbsp;<i>Rishi Bommasani, Claire Cardie</i><br>
<font size="3">
High quality data forms the bedrock for building meaningful statistical models in NLP. Consequently, data quality must be evaluated either during dataset construction or *post hoc*. Almost all popular summarization datasets are drawn from natural sources and do not come with inherent quality assurance guarantees. In spite of this, data quality has gone largely unquestioned for many of these recent datasets. We perform the first large-scale evaluation of summarization datasets by introducing 5 intrinsic metrics and applying them to 10 popular datasets. We find that data usage in recent summarization research is sometimes inconsistent with the underlying properties of the data. Further, we discover that our metrics can serve the additional purpose of being inexpensive heuristics for detecting generically low quality examples.</font>
<br>
</div>


<hr>
<div id="paper57"> <b>57. Coarse-to-Fine Query Focused Multi-Document Summarization</b>  <a href="https://www.aclweb.org/anthology/2020.emnlp-main.296.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title57" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Long Paper<br>&nbsp;&nbsp;<i>Yumo Xu, Mirella Lapata</i><br>
<font size="3">
We consider the problem of better modeling query-cluster interactions to facilitate query focused multi-document summarization. Due to the lack of training data, existing work relies heavily on retrieval-style methods for assembling query relevant summaries. We propose a coarse-to-fine modeling framework which employs progressively more accurate modules for estimating whether text segments are relevant, likely to contain an answer, and central. The modules can be independently developed and leverage training data if available. We present an instantiation of this framework with a trained evidence estimator which relies on distant supervision from question answering (where various resources exist) to identify segments which are likely to answer the query and should be included in the summary. Our framework is robust across domains and query types (i.e., long vs short) and outperforms strong comparison systems on benchmark datasets.</font>
<br>
</div>


<hr>
<div id="paper58"> <b>58. VMSMO: Learning to Generate Multimodal Summary for Video-based News Articles</b>  <a href="https://www.aclweb.org/anthology/2020.emnlp-main.752.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title58" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Long Paper<br>&nbsp;&nbsp;<i>Mingzhe Li, Xiuying Chen, Shen Gao, Zhangming Chan, Dongyan Zhao, Rui Yan</i><br>
<font size="3">
A popular multimedia news format nowadays is providing users with a lively video and a corresponding news article, which is employed by influential news media including CNN, BBC, and social media including Twitter and Weibo. In such a case, automatically choosing a proper cover frame of the video and generating an appropriate textual summary of the article can help editors save time, and readers make the decision more effectively. Hence, in this paper, we propose the task of Video-based Multimodal Summarization with Multimodal Output (VMSMO) to tackle such a problem. The main challenge in this task is to jointly model the temporal dependency of video with semantic meaning of article. To this end, we propose a Dual-Interaction-based Multimodal Summarizer (DIMS), consisting of a dual interaction module and multimodal generator. In the dual interaction module, we propose a conditional self-attention mechanism that captures local semantic information within video and a global-attention mechanism that handles the semantic relationship between news text and video from a high level. Extensive experiments conducted on a large-scale real-world VMSMO dataset show that DIMS achieves the state-of-the-art performance in terms of both automatic metrics and human evaluations.</font>
<br>
</div>


<hr>
<div id="paper59"> <b>59. Pre-training for Abstractive Document Summarization by Reinstating Source Text</b>  <a href="https://www.aclweb.org/anthology/2020.emnlp-main.297.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title59" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Long Paper<br>&nbsp;&nbsp;<i>Yanyan Zou, Xingxing Zhang, Wei Lu, Furu Wei, Ming Zhou</i><br>
<font size="3">
Abstractive document summarization is usually modeled as a sequence-to-sequence (SEQ2SEQ) learning problem. Unfortunately, training large SEQ2SEQ based summarization models on limited supervised summarization data is challenging. This paper presents three sequence-to-sequence pre-training (in shorthand, STEP) objectives which allow us to pre-train a SEQ2SEQ based abstractive summarization model on unlabeled text. The main idea is that, given an input text artificially constructed from a document, a model is pre-trained to reinstate the original document. These objectives include sentence reordering, next sentence generation and masked document generation, which have close relations with the abstractive document summarization task. Experiments on two benchmark summarization datasets (i.e., CNN/DailyMail and New York Times) show that all three objectives can improve performance upon baselines. Compared to models pre-trained on large-scale data (larger than 160GB), our method, with only 19GB text for pre-training, achieves comparable results, which demonstrates its effectiveness.</font>
<br>
</div>


<hr>
<div id="paper60"> <b>60. What Have We Achieved on Text Summarization?</b>  <a href="https://www.aclweb.org/anthology/2020.emnlp-main.33.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title60" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Long Paper<br>&nbsp;&nbsp;<i>Dandan Huang, Leyang Cui, Sen Yang, Guangsheng Bao, Kun Wang, Jun Xie, Yue Zhang</i><br>
<font size="3">
Deep learning has led to significant improvement in text summarization with various methods investigated and improved ROUGE scores reported over the years. However, gaps still exist between summaries produced by automatic summarizers and human professionals. Aiming to gain more understanding of summarization systems with respect to their strengths and limits on a fine-grained syntactic and semantic level, we consult the Multidimensional Quality Metric (MQM) and quantify 8 major sources of errors on 10 representative summarization models manually. Primarily, we find that 1) under similar settings, extractive summarizers are in general better than their abstractive counterparts thanks to strength in faithfulness and factual-consistency; 2) milestone techniques such as copy, coverage and hybrid extractive/abstractive methods do bring specific improvements but also demonstrate limitations; 3) pre-training techniques, and in particular sequence-to-sequence pre-training, are highly effective for improving text summarization, with BART giving the best results.</font>
<br>
</div>


<hr>
<div id="paper61"> <b>61. Few-Shot Learning for Opinion Summarization</b>  <a href="https://www.aclweb.org/anthology/2020.emnlp-main.337.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title61" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Long Paper<br>&nbsp;&nbsp;<i>Arthur Bražinskas, Mirella Lapata, Ivan Titov</i><br>
<font size="3">
Opinion summarization is the automatic creation of text reflecting subjective information expressed in multiple documents, such as user reviews of a product. The task is practically important and has attracted a lot of attention. However, due to the high cost of summary production, datasets large enough for training supervised models are lacking. Instead, the task has been traditionally approached with extractive methods that learn to select text fragments in an unsupervised or weakly-supervised way. Recently, it has been shown that abstractive summaries, potentially more fluent and better at reflecting conflicting information, can also be produced in an unsupervised fashion. However, these models, not being exposed to actual summaries, fail to capture their essential properties. In this work, we show that even a handful of summaries is sufficient to bootstrap generation of the summary text with all expected properties, such as writing style, informativeness, fluency, and sentiment preservation. We start by training a conditional Transformer language model to generate a new product review given other available reviews of the product. The model is also conditioned on review properties that are directly related to summaries; the properties are derived from reviews with no manual effort. In the second stage, we fine-tune a plug-in module that learns to predict property values on a handful of summaries. This lets us switch the generator to the summarization mode. We show on Amazon and Yelp datasets that our approach substantially outperforms previous extractive and abstractive methods in automatic and human evaluation.</font>
<br>
</div>


<hr>
<div id="paper62"> <b>62. Multi-hop Inference for Question-driven Summarization</b>  <a href="https://www.aclweb.org/anthology/2020.emnlp-main.547.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title62" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Long Paper<br>&nbsp;&nbsp;<i>Yang Deng, Wenxuan Zhang, Wai Lam</i><br>
<font size="3">
Question-driven summarization has been recently studied as an effective approach to summarizing the source document to produce concise but informative answers for non-factoid questions. In this work, we propose a novel question-driven abstractive summarization method, Multi-hop Selective Generator (MSG), to incorporate multi-hop reasoning into question-driven summarization and, meanwhile, provide justifications for the generated summaries. Specifically, we jointly model the relevance to the question and the interrelation among different sentences via a human-like multi-hop inference module, which captures important sentences for justifying the summarized answer. A gated selective pointer generator network with a multi-view coverage mechanism is designed to integrate diverse information from different perspectives. Experimental results show that the proposed method consistently outperforms state-of-the-art methods on two non-factoid QA datasets, namely WikiHow and PubMedQA.</font>
<br>
</div>


<hr>
<div id="paper63"> <b>63. On Extractive and Abstractive Neural Document Summarization with Transformer Language Models</b>  <a href="https://www.aclweb.org/anthology/2020.emnlp-main.748.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title63" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Long Paper<br>&nbsp;&nbsp;<i>Jonathan Pilault, Raymond Li, Sandeep Subramanian, Chris Pal</i><br>
<font size="3">
We present a method to produce abstractive summaries of long documents that exceed several thousand words via neural abstractive summarization. We perform a simple extractive step before generating a summary, which is then used to condition the transformer language model on relevant information before being tasked with generating a summary. We also show that this approach produces more abstractive summaries compared to prior work that employs a copy mechanism while still achieving higher ROUGE scores. We provide extensive comparisons with strong baseline methods, prior state of the art work as well as multiple variants of our approach including those using only transformers, only extractive techniques and combinations of the two. We examine these models using four different summarization tasks and datasets: arXiv papers, PubMed papers, the Newsroom and BigPatent datasets. We find that transformer based methods produce summaries with fewer n-gram copies, leading to n-gram copying statistics that are more similar to human generated abstracts. We include a human evaluation, finding that transformers are ranked highly for coherence and fluency, but purely extractive methods score higher for informativeness and relevance. We hope that these architectures and experiments may serve as strong points of comparison for future work.Note: The abstract above was collaboratively written by the authors and one of the models presented in this paper based on an earlier draft of this paper.</font>
<br>
</div>


<hr>
<div id="paper64"> <b>64. Multi-Fact Correction in Abstractive Text Summarization</b>  <a href="https://www.aclweb.org/anthology/2020.emnlp-main.749.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title64" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Long Paper<br>&nbsp;&nbsp;<i>Yue Dong, Shuohang Wang, Zhe Gan, Yu Cheng, Jackie Chi Kit Cheung, Jingjing Liu</i><br>
<font size="3">
Pre-trained neural abstractive summarization systems have dominated extractive strategies on news summarization performance, at least in terms of ROUGE. However, system-generated abstractive summaries often face the pitfall of factual inconsistency: generating incorrect facts with respect to the source text. To address this challenge, we propose Span-Fact, a suite of two factual correction models that leverages knowledge learned from question answering models to make corrections in system-generated summaries via span selection. Our models employ single or multi-masking strategies to either iteratively or auto-regressively replace entities in order to ensure semantic consistency w.r.t. the source text, while retaining the syntactic structure of summaries generated by abstractive summarization models. Experiments show that our models significantly boost the factual consistency of system-generated summaries without sacrificing summary quality in terms of both automatic metrics and human evaluation.</font>
<br>
</div>


<hr>
<div id="paper65"> <b>65. Compressive Summarization with Plausibility and Salience Modeling</b>  <a href="https://www.aclweb.org/anthology/2020.emnlp-main.507.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title65" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Long Paper<br>&nbsp;&nbsp;<i>Shrey Desai, Jiacheng Xu, Greg Durrett</i><br>
<font size="3">
Compressive summarization systems typically rely on a seed set of syntactic rules to determine under what circumstances deleting a span is permissible, then learn which compressions to actually apply by optimizing for ROUGE. In this work, we propose to relax these explicit syntactic constraints on candidate spans, and instead leave the decision about what to delete to two data-driven criteria: plausibility and salience. Deleting a span is plausible if removing it maintains the grammaticality and factuality of a sentence, and it is salient if it removes important information from the summary. Each of these is judged by a pre-trained Transformer model, and only deletions that are both plausible and not salient can be applied. When integrated into a simple extraction-compression pipeline, our method achieves strong in-domain results on benchmark datasets, and human evaluation shows that the plausibility model generally selects for grammatical and factual deletions. Furthermore, the flexibility of our approach allows it to generalize cross-domain, and we show that our system fine-tuned on only 500 samples from a new domain can match or exceed a strong in-domain extractive model.</font>
<br>
</div>


<hr>
<div id="paper66"> <b>66. Evaluating the Factual Consistency of Abstractive Text Summarization</b>  <a href="https://www.aclweb.org/anthology/2020.emnlp-main.750.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title66" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Long Paper<br>&nbsp;&nbsp;<i>Wojciech Kryscinski, Bryan McCann, Caiming Xiong, Richard Socher</i><br>
<font size="3">
The most common metrics for assessing summarization algorithms do not account for whether summaries are factually consistent with source documents. We propose a weakly-supervised, model-based approach for verifying factual consistency and identifying conflicts between source documents and generated summaries. Training data is generated by applying a series of rule-based transformations to the sentences of source documents.The factual consistency model is then trained jointly for three tasks: 1) predict whether each summary sentence is factually consistent or not, 2) in either case, extract a span in the source document to support this consistency prediction, 3) for each summary sentence that is deemed inconsistent, extract the inconsistent span from it. Transferring this model to summaries generated by several neural models reveals that this highly scalable approach outperforms previous models, including those trained with strong supervision using datasets from related domains, such as natural language inference and fact checking. Additionally, human evaluation shows that the auxiliary span extraction tasks provide useful assistance in the process of verifying factual consistency. We also release a manually annotated dataset for factual consistency verification, code for training data generation, and trained model weights at https://github.com/salesforce/factCC.</font>
<br>
</div>


<hr>
<div id="paper67"> <b>67. Quantitative Argument Summarization and beyond: Cross-Domain Key Point Analysis</b>  <a href="https://www.aclweb.org/anthology/2020.emnlp-main.3.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title67" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Long Paper<br>&nbsp;&nbsp;<i>Roy Bar-Haim, Yoav Kantor, Lilach Eden, Roni Friedman, Dan Lahav, Noam Slonim</i><br>
<font size="3">
When summarizing a collection of views, arguments or opinions on some topic, it is often desirable not only to extract the most salient points, but also to quantify their prevalence. Work on multi-document summarization has traditionally focused on creating textual summaries, which lack this quantitative aspect. Recent work has proposed to summarize arguments by mapping them to a small set of expert-generated key points, where the salience of each key point corresponds to the number of its matching arguments. The current work advances key point analysis in two important respects: first, we develop a method for automatic extraction of key points, which enables fully automatic analysis, and is shown to achieve performance comparable to a human expert. Second, we demonstrate that the applicability of key point analysis goes well beyond argumentation data. Using models trained on publicly available argumentation datasets, we achieve promising results in two additional domains: municipal surveys and user reviews. An additional contribution is an in-depth evaluation of argument-to-key point matching models, where we substantially outperform previous results.</font>
<br>
</div>


<hr>
<div id="paper68"> <b>68. TESA: A Task in Entity Semantic Aggregation for Abstractive Summarization</b>  <a href="https://www.aclweb.org/anthology/2020.emnlp-main.646.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title68" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Long Paper<br>&nbsp;&nbsp;<i>Clément Jumel, Annie Louis, Jackie Chi Kit Cheung</i><br>
<font size="3">
Human-written texts contain frequent generalizations and semantic aggregation of content. In a document, they may refer to a pair of named entities such as 'London' and 'Paris' with different expressions: "the major cities'', "the capital cities'' and "two European cities''. Yet generation, especially, abstractive summarization systems have so far focused heavily on paraphrasing and simplifying the source content, to the exclusion of such semantic abstraction capabilities. In this paper, we present a new dataset and task aimed at the semantic aggregation of entities. TESA contains a dataset of 5.3K crowd-sourced entity aggregations of Person, Organization, and Location named entities. The aggregations are document-appropriate, meaning that they are produced by annotators to match the situational context of a given news article from the New York Times. We then build baseline models for generating aggregations given a tuple of entities and document context. We finetune on TESA an encoder-decoder language model and compare it with simpler classification methods based on linguistically informed features. Our quantitative and qualitative evaluations show reasonable performance in making a choice from a given list of expressions, but free-form expressions are understandably harder to generate and evaluate.</font>
<br>
</div>


<hr>
<div id="paper69"> <b>69. A Spectral Method for Unsupervised Multi-Document Summarization</b>  <a href="https://www.aclweb.org/anthology/2020.emnlp-main.32.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title69" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Long Paper<br>&nbsp;&nbsp;<i>Kexiang Wang, Baobao Chang, Zhifang Sui</i><br>
<font size="3">
Multi-document summarization (MDS) aims at producing a good-quality summary for several related documents. In this paper, we propose a spectral-based hypothesis, which states that the goodness of summary candidate is closely linked to its so-called spectral impact. Here spectral impact considers the perturbation to the dominant eigenvalue of affinity matrix when dropping the summary candidate from the document cluster. The hypothesis is validated by three theoretical perspectives: semantic scaling, propagation dynamics and matrix perturbation. According to the hypothesis, we formulate the MDS task as the combinatorial optimization of spectral impact and propose an accelerated greedy solution based on a surrogate of spectral impact. The evaluation results on various datasets demonstrate: (1) The performance of the summary candidate is positively correlated with its spectral impact, which accords with our hypothesis; (2) Our spectral-based method has a competitive result as compared to state-of-the-art MDS systems.</font>
<br>
</div>


<hr>
<div id="paper70"> <b>70. Unsupervised Reference-Free Summary Quality Evaluation via Contrastive Learning</b>  <a href="https://www.aclweb.org/anthology/2020.emnlp-main.294.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title70" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Long Paper<br>&nbsp;&nbsp;<i>Hanlu Wu, Tengfei Ma, Lingfei Wu, Tariro Manyumwa, Shouling Ji</i><br>
<font size="3">
Evaluation of a document summarization system has been a critical factor to impact the success of the summarization task. Previous approaches, such as ROUGE, mainly consider the informativeness of the assessed summary and require human-generated references for each test summary. In this work, we propose to evaluate the summary qualities without reference summaries by unsupervised contrastive learning. Specifically, we design a new metric which covers both linguistic qualities and semantic informativeness based on BERT. To learn the metric, for each summary, we construct different types of negative samples with respect to different aspects of the summary qualities, and train our model with a ranking loss. Experiments on Newsroom and CNN/Daily Mail demonstrate that our new evaluation method outperforms other metrics even without reference summaries. Furthermore, we show that our method is general and transferable across datasets.</font>
<br>
</div>


<hr>
<div id="paper71"> <b>71. Friendly Topic Assistant for Transformer Based Abstractive Summarization</b>  <a href="https://www.aclweb.org/anthology/2020.emnlp-main.35.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title71" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Long Paper<br>&nbsp;&nbsp;<i>Zhengjue Wang, Zhibin Duan, Hao Zhang, chaojie wang, long tian, Bo Chen, Mingyuan Zhou</i><br>
<font size="3">
Abstractive document summarization is a comprehensive task including document understanding and summary generation, in which area Transformer-based models have achieved the state-of-the-art performance. Compared with Transformers, topic models are better at learning explicit document semantics, and hence could be integrated into Transformers to further boost their performance. To this end, we rearrange and explore the semantics learned by a topic model, and then propose a topic assistant (TA) including three modules. TA is compatible with various Transformer-based models and user-friendly since i) TA is a plug-and-play model that does not break any structure of the original Transformer network, making users easily fine-tune Transformer+TA based on a well pre-trained model; ii) TA only introduces a small number of extra parameters. Experimental results on three datasets demonstrate that TA is able to improve the performance of several Transformer-based models.</font>
<br>
</div>


<hr>
<div id="paper72"> <b>72. Better Highlighting: Creating Sub-Sentence Summary Highlights</b>  <a href="https://www.aclweb.org/anthology/2020.emnlp-main.509.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title72" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Long Paper<br>&nbsp;&nbsp;<i>Sangwoo Cho, Kaiqiang Song, Chen Li, Dong Yu, Hassan Foroosh, Fei Liu</i><br>
<font size="3">
Amongst the best means to summarize is highlighting. In this paper, we aim to generate summary highlights to be overlaid on the original documents to make it easier for readers to sift through a large amount of texts. The method allows summaries to be understood in context to prevent any summarizer from distorting the original meaning, of which abstractive summarization can fall short. In particular, we present a new method to produce self-contained highlights that are understandable on their own to avoid any confusion. Our method combines determinantal point processes and deep contextualized representations to identify an optimal set of sub-sentence segments that are both important and non-redundant to form summary highlights. To show the flexibility and modeling power of our method, we conduct extensive experiments on summarization datasets. Our analysis provides further evidence that highlighting is a promising avenue of research toward future summarization.</font>
<br>
</div>


<hr>
<div id="paper73"> <b>73. Stepwise Extractive Summarization and Planning with Structured Transformers</b>  <a href="https://www.aclweb.org/anthology/2020.emnlp-main.339.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title73" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Long Paper<br>&nbsp;&nbsp;<i>Shashi Narayan, Joshua Maynez, Jakub Adamek, Daniele Pighin, Blaz Bratanic, Ryan McDonald</i><br>
<font size="3">
We propose encoder-centric stepwise models for extractive summarization using structured transformers -- HiBERT and Extended Transformers. We enable stepwise summarization by injecting the previously generated summary into the structured transformer as an auxiliary sub-structure. Our models are not only efficient in modeling the structure of long inputs, but they also do not rely on task-specific redundancy-aware modeling, making them a general purpose extractive content planner for different tasks.When evaluated on CNN/DailyMail extractive summarization, stepwise models achieve state-of-the-art performance in terms of Rouge without any redundancy aware modeling or sentence filtering. This also holds true for Rotowire table-to-text generation, where our models surpass previously reported metrics for content selection, planning and ordering, highlighting the strength of stepwise modeling. Amongst the two structured transformers we test, stepwise Extended Transformers provides the best performance across both datasets and sets a new standard for these challenges.</font>
<br>
</div>


<hr>
<div id="paper74"> <b>74. Neural Extractive Summarization with Hierarchical Attentive Heterogeneous Graph Network</b>  <a href="https://www.aclweb.org/anthology/2020.emnlp-main.295.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title74" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Long Paper<br>&nbsp;&nbsp;<i>Ruipeng Jia, Yanan Cao, Hengzhu Tang, Fang Fang, Cong Cao, Shi Wang</i><br>
<font size="3">
Sentence-level extractive text summarization is substantially a node classification task of network mining, adhering to the informative components and concise representations. There are lots of redundant phrases between extracted sentences, but it is difficult to model them exactly by the general supervised methods. Previous sentence encoders, especially BERT, specialize in modeling the relationship between source sentences. While, they have no ability to consider the overlaps of the target selected summary, and there are inherent dependencies among target labels of sentences. In this paper, we propose HAHSum (as shorthand for Hierarchical Attentive Heterogeneous Graph for Text Summarization), which well models different levels of information, including words and sentences, and spotlights redundancy dependencies between sentences. Our approach iteratively refines the sentence representations with redundancy-aware graph and delivers the label dependencies by message passing. Experiments on large scale benchmark corpus (CNN/DM, NYT, and NEWSROOM) demonstrate that HAHSum yields ground-breaking performance and outperforms previous extractive summarizers.</font>
<br>
</div>


<hr>
<div id="paper75"> <b>75. Re-evaluating Evaluation in Text Summarization</b>  <a href="https://www.aclweb.org/anthology/2020.emnlp-main.751.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title75" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Long Paper<br>&nbsp;&nbsp;<i>Manik Bhandari, Pranav Narayan Gour, Atabak Ashfaq, Pengfei Liu, Graham Neubig</i><br>
<font size="3">
Automated evaluation metrics as a stand-in for manual evaluation are an essential part of the development of text-generation tasks such as text summarization. However, while the field has progressed, our standard metrics have not -- for nearly 20 years ROUGE has been the standard evaluation in most summarization papers. In this paper, we make an attempt to re-evaluate the evaluation method for text summarization: assessing the reliability of automatic metrics using top-scoring system outputs, both abstractive and extractive, on recently popular datasets for both system-level and summary-level evaluation settings. We find that conclusions about evaluation metrics on older datasets do not necessarily hold on modern datasets and systems. We release a dataset of human judgments that are collected from 25 top-scoring neural summarization systems (14 abstractive and 11 extractive).</font>
<br>
</div>


<hr>
<div id="paper76"> <b>76. Multi-XScience: A Large-scale Dataset for Extreme Multi-document Summarization of Scientific Articles</b>  <a href="https://www.aclweb.org/anthology/2020.emnlp-main.648.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title76" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Short Paper<br>&nbsp;&nbsp;<i>Yao Lu, Yue Dong, Laurent Charlin</i><br>
<font size="3">
Multi-document summarization is a challenging task for which there exists little large-scale datasets. We propose Multi-XScience, a large-scale multi-document summarization dataset created from scientific articles. Multi-XScience introduces a challenging multi-document summarization task: writing the related-work section of a paper based on its abstract and the articles it references. Our work is inspired by extreme summarization, a dataset construction protocol that favours abstractive modeling approaches. Descriptive statistics and empirical results---using several state-of-the-art models trained on the Multi-XScience dataset---reveal that Multi-XScience is well suited for abstractive models.</font>
<br>
</div>


<hr>
<div id="paper77"> <b>77. Modeling Content Importance for Summarization with Pre-trained Language Models</b>  <a href="https://www.aclweb.org/anthology/2020.emnlp-main.293.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title77" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Short Paper<br>&nbsp;&nbsp;<i>Liqiang Xiao, Lu Wang, Hao He, Yaohui Jin</i><br>
<font size="3">
Modeling content importance is an essential yet challenging task for summarization. Previous work is mostly based on statistical methods that estimate word-level salience, which does not consider semantics and larger context when quantifying importance. It is thus hard for these methods to generalize to semantic units of longer text spans. In this work, we apply information theory on top of pre-trained language models and define the concept of importance from the perspective of information amount. It considers both the semantics and context when evaluating the importance of each semantic unit. With the help of pre-trained language models, it can easily generalize to different kinds of semantic units n-grams or sentences. Experiments on CNN/Daily Mail and New York Times datasets demonstrate that our method can better model the importance of content than prior work based on F1 and ROUGE scores.</font>
<br>
</div>


<hr>
<div id="paper78"> <b>78. Factual Error Correction for Abstractive Summarization Models</b>  <a href="https://www.aclweb.org/anthology/2020.emnlp-main.506.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title78" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Short Paper<br>&nbsp;&nbsp;<i>Meng Cao, Yue Dong, Jiapeng Wu, Jackie Chi Kit Cheung</i><br>
<font size="3">
Neural abstractive summarization systems have achieved promising progress, thanks to the availability of large-scale datasets and models pre-trained with self-supervised methods. However, ensuring the factual consistency of the generated summaries for abstractive summarization systems is a challenge. We propose a post-editing corrector module to address this issue by identifying and correcting factual errors in generated summaries. The neural corrector model is pre-trained on artificial examples that are created by applying a series of heuristic transformations on reference summaries. These transformations are inspired by the error analysis of state-of-the-art summarization model outputs. Experimental results show that our model is able to correct factual errors in summaries generated by other neural summarization models and outperforms previous models on factual consistency evaluation on the CNN/DailyMail dataset. We also find that transferring from artificial error correction to downstream settings is still very challenging.</font>
<br>
</div>


<hr>
<div id="paper79"> <b>79. Understanding Neural Abstractive Summarization Models via Uncertainty</b>  <a href="https://www.aclweb.org/anthology/2020.emnlp-main.508.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title79" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Short Paper<br>&nbsp;&nbsp;<i>Jiacheng Xu, Shrey Desai, Greg Durrett</i><br>
<font size="3">
An advantage of seq2seq abstractive summarization models is that they generate text in a free-form manner, but this flexibility makes it difficult to interpret model behavior. In this work, we analyze summarization decoders in both blackbox and whitebox ways by studying on the entropy, or uncertainty, of the model's token-level predictions. For two strong pre-trained models, PEGASUS and BART on two summarization datasets, we find a strong correlation between low prediction entropy and where the model copies tokens rather than generating novel text. The decoder's uncertainty also connects to factors like sentence position and syntactic distance between adjacent pairs of tokens, giving a sense of what factors make a context particularly selective for the model's next output token. Finally, we study the relationship of decoder uncertainty and attention behavior to understand how attention gives rise to these observed effects in the model. We show that uncertainty is a useful perspective for analyzing summarization and text generation models more broadly.</font>
<br>
</div>


<hr>
<div id="paper80"> <b>80. Learning to Fuse Sentences with Transformers for Summarization</b>  <a href="https://www.aclweb.org/anthology/2020.emnlp-main.338.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title80" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Short Paper<br>&nbsp;&nbsp;<i>Logan Lebanoff, Franck Dernoncourt, Doo Soon Kim, Lidan Wang, Walter Chang, Fei Liu</i><br>
<font size="3">
The ability to fuse sentences is highly attractive for summarization systems because it is an essential step to produce succinct abstracts. However, to date, summarizers can fail on fusing sentences. They tend to produce few summary sentences by fusion or generate incorrect fusions that lead the summary to fail to retain the original meaning. In this paper, we explore the ability of Transformers to fuse sentences and propose novel algorithms to enhance their ability to perform sentence fusion by leveraging the knowledge of points of correspondence between sentences. Through extensive experiments, we investigate the effects of different design choices on Transformer's performance. Our findings highlight the importance of modeling points of correspondence between sentences for effective sentence fusion.</font>
<br>
</div>


<hr>
<div id="paper81"> <b>81. Summarizing Text on Any Aspects: A Knowledge-Informed Weakly-Supervised Approach</b>  <a href="https://www.aclweb.org/anthology/2020.emnlp-main.510.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title81" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Short Paper<br>&nbsp;&nbsp;<i>Bowen Tan, Lianhui Qin, Eric Xing, Zhiting Hu</i><br>
<font size="3">
Given a document and a target aspect (e.g., a topic of interest), aspect-based abstractive summarization attempts to generate a summary with respect to the aspect. Previous studies usually assume a small pre-defined set of aspects and fall short of summarizing on other diverse topics. In this work, we study summarizing on \empharbitrary aspects relevant to the document, which significantly expands the application of the task in practice. Due to the lack of supervision data, we develop a new weak supervision construction method and an aspect modeling scheme, both of which integrate rich external knowledge sources such as ConceptNet and Wikipedia. Experiments show our approach achieves performance boosts on summarizing both real and synthetic documents given pre-defined or arbitrary aspects.</font>
<br>
</div>


<hr>
<div id="paper82"> <b>82. Summarizing Chinese Medical Answer with Graph Convolution Networks and Question-focused Dual Attention</b>  <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.2.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title82" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Findings Short Paper<br>&nbsp;&nbsp;<i>Ningyu Zhang, Shumin Deng, Juan Li, Xi Chen, Wei Zhang, Huajun Chen</i><br>
<font size="3">
Online search engines are a popular source of medical information for users, where users can enter questions and obtain relevant answers. It is desirable to generate answer summaries for online search engines, particularly summaries that can reveal direct answers to questions. Moreover, answer summaries are expected to reveal the most relevant information in response to questions; hence, the summaries should be generated with a focus on the question, which is a challenging topic-focused summarization task. In this paper, we propose an approach that utilizes graph convolution networks and question-focused dual attention for Chinese medical answer summarization. We first organize the original long answer text into a medical concept graph with graph convolution networks to better understand the internal structure of the text and the correlation between medical concepts. Then, we introduce a question-focused dual attention mechanism to generate summaries relevant to questions. Experimental results demonstrate that the proposed model can generate more coherent and informative summaries compared with baseline models.</font>
<br>
</div>


<hr>
<div id="paper83"> <b>83. A Hierarchical Network for Abstractive Meeting Summarization with Cross-Domain Pretraining</b>  <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.19.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title83" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Findings Short Paper<br>&nbsp;&nbsp;<i>Chenguang Zhu, Ruochen Xu, Michael Zeng, Xuedong Huang</i><br>
<font size="3">
With the abundance of automatic meeting transcripts, meeting summarization is of great interest to both participants and other parties. Traditional methods of summarizing meetings depend on complex multi-step pipelines that make joint optimization intractable. Meanwhile, there are a handful of deep neural models for text summarization and dialogue systems. However, the semantic structure and styles of meeting transcripts are quite different from articles and conversations. In this paper, we propose a novel abstractive summary network that adapts to the meeting scenario. We design a hierarchical structure to accommodate long meeting transcripts and a role vector to depict the difference among speakers. Furthermore, due to the inadequacy of meeting summary data, we pretrain the model on large-scale news summary data. Empirical results show that our model outperforms previous approaches in both automatic metrics and human evaluation. For example, on ICSI dataset, the ROUGE-1 score increases from 34.66% to 46.28%.</font>
<br>
</div>


<hr>
<div id="paper84"> <b>84. ZEST: Zero-shot Learning from Text Descriptions using Textual Similarity and Visual Summarization</b>  <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.50.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title84" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Findings Short Paper<br>&nbsp;&nbsp;<i>Tzuf Paz-Argaman, Reut Tsarfaty, Gal Chechik, Yuval Atzmon</i><br>
<font size="3">
We study the problem of recognizing visual entities from the textual descriptions of their classes. Specifically, given birds’ images with free-text descriptions of their species, we learn to classify images of previously-unseen species based on specie descriptions. This setup has been studied in the vision community under the name zero-shot learning from text, focusing on learning to transfer knowledge about visual aspects of birds from seen classes to previously-unseen ones. Here, we suggest focusing on the textual description and distilling from the description the most relevant information to effectively match visual features to the parts of the text that discuss them. Specifically, (1) we propose to leverage the similarity between species, reflected in the similarity between text descriptions of the species. (2) we derive visual summaries of the texts, i.e., extractive summaries that focus on the visual features that tend to be reflected in images. We propose a simple attention-based model augmented with the similarity and visual summaries components. Our empirical results consistently and significantly outperform the state-of-the-art on the largest benchmarks for text-based zero-shot learning, illustrating the critical importance of texts for zero-shot image-recognition.</font>
<br>
</div>


<hr>
<div id="paper85"> <b>85. Conditional Neural Generation using Sub-Aspect Functions for Extractive News Summarization</b>  <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.131.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title85" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Findings Short Paper<br>&nbsp;&nbsp;<i>Zhengyuan Liu, Ke Shi, Nancy Chen</i><br>
<font size="3">
Much progress has been made in text summarization, fueled by neural architectures using large-scale training corpora. However, in the news domain, neural models easily overfit by leveraging position-related features due to the prevalence of the inverted pyramid writing style. In addition, there is an unmet need to generate a variety of summaries for different users. In this paper, we propose a neural framework that can flexibly control summary generation by introducing a set of sub-aspect functions (i.e. importance, diversity, position). These sub-aspect functions are regulated by a set of control codes to decide which sub-aspect to focus on during summary generation. We demonstrate that extracted summaries with minimal position bias is comparable with those generated by standard models that take advantage of position preference. We also show that news summaries generated with a focus on diversity can be more preferred by human raters. These results suggest that a more flexible neural summarization framework providing more control options could be desirable in tailoring to different user preferences, which is useful since it is often impractical to articulate such preferences for different applications a priori.</font>
<br>
</div>


<hr>
<div id="paper86"> <b>86. Unsupervised Extractive Summarization by Pre-training Hierarchical Transformers</b>  <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.161.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title86" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Findings Short Paper<br>&nbsp;&nbsp;<i>Shusheng Xu, Xingxing Zhang, Yi Wu, Furu Wei, Ming Zhou</i><br>
<font size="3">
Unsupervised extractive document summarization aims to select important sentences from a document without using labeled summaries during training. Existing methods are mostly graph-based with sentences as nodes and edge weights measured by sentence similarities. In this work, we find that transformer attentions can be used to rank sentences for unsupervised extractive summarization. Specifically, we first pre-train a hierarchical transformer model using unlabeled documents only. Then we propose a method to rank sentences using sentence-level self-attentions and pre-training objectives. Experiments on CNN/DailyMail and New York Times datasets show our model achieves state-of-the-art performance on unsupervised summarization. We also find in experiments that our model is less dependent on sentence positions. When using a linear combination of our model and a recent unsupervised model explicitly modeling sentence positions, we obtain even better results.</font>
<br>
</div>


<hr>
<div id="paper87"> <b>87. TED: A Pretrained Unsupervised Summarization Model with Theme Modeling and Denoising</b>  <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.168.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title87" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Findings Short Paper<br>&nbsp;&nbsp;<i>Ziyi Yang, Chenguang Zhu, Robert Gmyr, Michael Zeng, Xuedong Huang, Eric Darve</i><br>
<font size="3">
Text summarization aims to extract essential information from a piece of text and transform the text into a concise version. Existing unsupervised abstractive summarization models leverage recurrent neural networks framework while the recently proposed transformer exhibits much more capability. Moreover, most of previous summarization models ignore abundant unlabeled corpora resources available for pretraining. In order to address these issues, we propose TED, a transformer-based unsupervised abstractive summarization system with pretraining on large-scale data. We first leverage the lead bias in news articles to pretrain the model on millions of unlabeled corpora. Next, we finetune TED on target domains through theme modeling and a denoising autoencoder to enhance the quality of generated summaries. Notably, TED outperforms all unsupervised abstractive baselines on NYT, CNN/DM and English Gigaword datasets with various document styles. Further analysis shows that the summaries generated by TED are highly abstractive, and each component in the objective function of TED is highly effective.</font>
<br>
</div>


<hr>
<div id="paper88"> <b>88. KLearn: Background Knowledge Inference from Summarization Data</b>  <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.188.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title88" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Findings Short Paper<br>&nbsp;&nbsp;<i>Maxime Peyrard, Robert West</i><br>
<font size="3">
The goal of text summarization is to compress documents to the relevant information while excluding background information already known to the receiver. So far, summarization researchers have given considerably more attention to relevance than to background knowledge. In contrast, this work puts background knowledge in the foreground. Building on the realization that the choices made by human summarizers and annotators contain implicit information about their background knowledge, we develop and compare techniques for inferring background knowledge from summarization data. Based on this framework, we define summary scoring functions that explicitly model background knowledge, and show that these scoring functions fit human judgments significantly better than baselines. We illustrate some of the many potential applications of our framework. First, we provide insights into human information importance priors. Second, we demonstrate that averaging the background knowledge of multiple, potentially biased annotators or corpora greatly improves summaryscoring performance. Finally, we discuss potential applications of our framework beyond summarization.</font>
<br>
</div>


<hr>
<div id="paper89"> <b>89. Reducing the Frequency of Hallucinated Quantities in Abstractive Summaries</b>  <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.203.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title89" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Findings Short Paper<br>&nbsp;&nbsp;<i>Zheng Zhao, Shay B. Cohen, Bonnie Webber</i><br>
<font size="3">
It is well-known that abstractive summaries are subject to hallucination—including material that is not supported by the original text. While summaries can be made hallucination-free by limiting them to general phrases, such summaries would fail to be very informative. Alternatively, one can try to avoid hallucinations by verifying that any specific entities in the summary appear in the original text in a similar context. This is the approach taken by our system, Herman. The system learns to recognize and verify quantity entities (dates, numbers, sums of money, etc.) in a beam-worth of abstractive summaries produced by state-of-the-art models, in order to up-rank those summaries whose quantity terms are supported by the original text. Experimental results demonstrate that the ROUGE scores of such up-ranked summaries have a higher Precision than summaries that have not been up-ranked, without a comparable loss in Recall, resulting in higher F1. Preliminary human evaluation of up-ranked vs. original summaries shows people’s preference for the former.</font>
<br>
</div>


<hr>
<div id="paper90"> <b>90. Abstractive Multi-Document Summarization via Joint Learning with Single-Document Summarization</b>  <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.231.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title90" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Findings Short Paper<br>&nbsp;&nbsp;<i>Hanqi Jin, Xiaojun Wan</i><br>
<font size="3">
Single-document and multi-document summarizations are very closely related in both task definition and solution method. In this work, we propose to improve neural abstractive multi-document summarization by jointly learning an abstractive single-document summarizer. We build a unified model for single-document and multi-document summarizations by fully sharing the encoder and decoder and utilizing a decoding controller to aggregate the decoder’s outputs for multiple input documents. We evaluate our model on two multi-document summarization datasets: Multi-News and DUC-04. Experimental results show the efficacy of our approach, and it can substantially outperform several strong baselines. We also verify the helpfulness of single-document summarization to abstractive multi-document summarization task.</font>
<br>
</div>


<hr>
<div id="paper91"> <b>91. Corpora Evaluation and System Bias detection in Multi Document Summarization</b>  <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.254.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title91" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Findings Short Paper<br>&nbsp;&nbsp;<i>Alvin Dey, Tanya Chowdhury, Yash Kumar, Tanmoy Chakraborty</i><br>
<font size="3">
Multi-document summarization (MDS) is the task of reflecting key points from any set of documents into a concise text paragraph. In the past, it has been used to aggregate news, tweets, product reviews, etc. from various sources. Owing to no standard definition of the task, we encounter a plethora of datasets with varying levels of overlap and conflict between participating documents. There is also no standard regarding what constitutes summary information in MDS. Adding to the challenge is the fact that new systems report results on a set of chosen datasets, which might not correlate with their performance on the other datasets. In this paper, we study this heterogeneous task with the help of a few widely used MDS corpora and a suite of state-of-theart models. We make an attempt to quantify the quality of summarization corpus and prescribe a list of points to consider while proposing a new MDS corpus. Next, we analyze the reason behind the absence of an MDS system which achieves superior performance across all corpora. We then observe the extent to which system metrics are influenced, and bias is propagated due to corpus properties. The scripts to reproduce the experiments in this work are available at https://github.com/LCS2-IIITD/summarization_bias.git</font>
<br>
</div>


<hr>
<div id="paper92"> <b>92. Towards Zero Shot Conditional Summarization with Adaptive Multi-task Fine-Tuning</b>  <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.289.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title92" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Findings Short Paper<br>&nbsp;&nbsp;<i>Travis Goodwin, Max Savery, Dina Demner-Fushman</i><br>
<font size="3">
Automatic summarization research has traditionally focused on providing high quality general-purpose summaries of documents. However, there are many applications which require more specific summaries, such as supporting question answering or topic-based literature discovery. In this paper we study the problem of conditional summarization in which content selection and surface realization are explicitly conditioned on an ad-hoc natural language question or topic description. Because of the difficulty in obtaining sufficient reference summaries to support arbitrary conditional summarization, we explore the use of multi-task fine-tuning (MTFT) on twenty-one natural language tasks to enable zero-shot conditional summarization on five tasks. We present four new summarization datasets, two novel “online” or adaptive task-mixing strategies, and report zero-shot performance using T5 and BART, demonstrating that MTFT can improve zero-shot summarization quality.</font>
<br>
</div>


<hr>
<div id="paper93"> <b>93. Document Reranking for Precision Medicine with Neural Matching and Faceted Summarization</b>  <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.304.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title93" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Findings Short Paper<br>&nbsp;&nbsp;<i>Jiho Noh, Ramakanth Kavuluru</i><br>
<font size="3">
Information retrieval (IR) for precision medicine (PM) often involves looking for multiple pieces of evidence that characterize a patient case. This typically includes at least the name of a condition and a genetic variation that applies to the patient. Other factors such as demographic attributes, comorbidities, and social determinants may also be pertinent. As such, the retrieval problem is often formulated as ad hoc search but with multiple facets (e.g., disease, mutation) that may need to be incorporated. In this paper, we present a document reranking approach that combines neural query-document matching and text summarization toward such retrieval scenarios. Our architecture builds on the basic BERT model with three specific components for reranking: (a). document-query matching (b). keyword extraction and (c). facet-conditioned abstractive summarization. The outcomes of (b) and (c) are used to essentially transform a candidate document into a concise summary that can be compared with the query at hand to compute a relevance score. Component (a) directly generates a matching score of a candidate document for a query. The full architecture benefits from the complementary potential of document-query matching and the novel document transformation approach based on summarization along PM facets. Evaluations using NIST’s TREC-PM track datasets (2017–2019) show that our model achieves state-of-the-art performance. To foster reproducibility, our code is made available here: https://github.com/bionlproc/text-summ-for-doc-retrieval.</font>
<br>
</div>


<hr>
<div id="paper94"> <b>94. An Empirical Study of Cross-Dataset Evaluation for Neural Summarization Systems</b>  <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.329.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title94" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Findings Short Paper<br>&nbsp;&nbsp;<i>Yiran Chen, Pengfei Liu, Ming Zhong, Zi-Yi Dou, Danqing Wang, Xipeng Qiu, Xuanjing Huang</i><br>
<font size="3">
Neural network-based models augmented with unsupervised pre-trained knowledge have achieved impressive performance on text summarization. However, most existing evaluation methods are limited to an in-domain setting, where summarizers are trained and evaluated on the same dataset. We argue that this approach can narrow our understanding of the generalization ability for different summarization systems. In this paper, we perform an in-depth analysis of characteristics of different datasets and investigate the performance of different summarization models under a cross-dataset setting, in which a summarizer trained on one corpus will be evaluated on a range of out-of-domain corpora. A comprehensive study of 11 representative summarization systems on 5 datasets from different domains reveals the effect of model architectures and generation ways (i.e. abstractive and extractive) on model generalization ability. Further, experimental results shed light on the limitations of existing summarizers. Brief introduction and supplementary code can be found in https://github.com/zide05/CDEvalSumm.</font>
<br>
</div>


<hr>
<div id="paper95"> <b>95. Dr. Summarize: Global Summarization of Medical Dialogue by Exploiting Local Structures</b>  <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.335.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title95" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Findings Short Paper<br>&nbsp;&nbsp;<i>Anirudh Joshi, Namit Katariya, Xavier Amatriain, Anitha Kannan</i><br>
<font size="3">
Understanding a medical conversation between a patient and a physician poses unique natural language understanding challenge since it combines elements of standard open-ended conversation with very domain-specific elements that require expertise and medical knowledge. Summarization of medical conversations is a particularly important aspect of medical conversation understanding since it addresses a very real need in medical practice: capturing the most important aspects of a medical encounter so that they can be used for medical decision making and subsequent follow ups. In this paper we present a novel approach to medical conversation summarization that leverages the unique and independent local structures created when gathering a patient’s medical history. Our approach is a variation of the pointer generator network where we introduce a penalty on the generator distribution, and we explicitly model negations. The model also captures important properties of medical conversations such as medical knowledge coming from standardized medical ontologies better than when those concepts are introduced explicitly. Through evaluation by doctors, we show that our approach is preferred on twice the number of summaries to the baseline pointer generator model and captures most or all of the information in 80% of the conversations making it a realistic alternative to costly manual summarization by medical experts.</font>
<br>
</div>


<hr>
<div id="paper96"> <b>96. WikiLingua: A New Benchmark Dataset for Multilingual Abstractive Summarization</b>  <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.360.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title96" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Findings Short Paper<br>&nbsp;&nbsp;<i>Faisal Ladhak, Esin Durmus, Claire Cardie, Kathleen McKeown</i><br>
<font size="3">
We introduce WikiLingua, a large-scale, multilingual dataset for the evaluation of cross-lingual abstractive summarization systems. We extract article and summary pairs in 18 languages from WikiHow, a high quality, collaborative resource of how-to guides on a diverse set of topics written by human authors. We create gold-standard article-summary alignments across languages by aligning the images that are used to describe each how-to step in an article. As a set of baselines for further studies, we evaluate the performance of existing cross-lingual abstractive summarization methods on our dataset. We further propose a method for direct cross-lingual summarization (i.e., without requiring translation at inference time) by leveraging synthetic data and Neural Machine Translation as a pre-training step. Our method significantly outperforms the baseline approaches, while being more cost efficient during inference.</font>
<br>
</div>


<hr>
<div id="paper97"> <b>97. SupMMD: A Sentence Importance Model for Extractive Summarisation using Maximum Mean Discrepancy</b>  <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.367.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title97" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Findings Short Paper<br>&nbsp;&nbsp;<i>Umanga Bista, Alexander Mathews, Aditya Menon, Lexing Xie</i><br>
<font size="3">
Most work on multi-document summarization has focused on generic summarization of information present in each individual document set. However, the under-explored setting of update summarization, where the goal is to identify the new information present in each set, is of equal practical interest (e.g., presenting readers with updates on an evolving news topic). In this work, we present SupMMD, a novel technique for generic and update summarization based on the maximum mean discrepancy from kernel two-sample testing. SupMMD combines both supervised learning for salience and unsupervised learning for coverage and diversity. Further, we adapt multiple kernel learning to make use of similarity across multiple information sources (e.g., text features and knowledge based concepts). We show the efficacy of SupMMD in both generic and update summarization tasks by meeting or exceeding the current state-of-the-art on the DUC-2004 and TAC-2009 datasets.</font>
<br>
</div>


<hr>
<div id="paper98"> <b>98. TLDR: Extreme Summarization of Scientific Documents</b>  <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.428.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title98" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;EMNLP 2020. Findings Short Paper<br>&nbsp;&nbsp;<i>Isabel Cachola, Kyle Lo, Arman Cohan, Daniel Weld</i><br>
<font size="3">
We introduce TLDR generation, a new form of extreme summarization, for scientific papers. TLDR generation involves high source compression and requires expert background knowledge and understanding of complex domain-specific language. To facilitate study on this task, we introduce SCITLDR, a new multi-target dataset of 5.4K TLDRs over 3.2K papers. SCITLDR contains both author-written and expert-derived TLDRs, where the latter are collected using a novel annotation protocol that produces high-quality summaries while minimizing annotation burden. We propose CATTS, a simple yet effective learning strategy for generating TLDRs that exploits titles as an auxiliary training signal. CATTS improves upon strong baselines under both automated metrics and human evaluations. Data and code are publicly available at https://github.com/allenai/scitldr.</font>
<br>
</div>


<hr>
<div id="paper99"> <b>99. FSNet: Compression of Deep Convolutional Neural Networks by Filter Summary</b>  <a href="https://openreview.net/pdf?id=S1xtORNFwH" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title99" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;ICLR 2020. <br>&nbsp;&nbsp;<i>Yingzhen Yang, Jiahui Yu, Nebojsa Jojic, Jun Huan, Thomas S. Huang</i><br>
<font size="3">
We present a novel method of compression of deep Convolutional Neural Networks (CNNs) by weight sharing through a new representation of convolutional filters. The proposed method reduces the number of parameters of each convolutional layer by learning a $1$D vector termed Filter Summary (FS). The convolutional filters are located in FS as overlapping $1$D segments, and nearby filters in FS share weights in their overlapping regions in a natural way. The resultant neural network based on such weight sharing scheme, termed Filter Summary CNNs or FSNet, has a FS in each convolution layer instead of a set of independent filters in the conventional convolution layer. FSNet has the same architecture as that of the baseline CNN to be compressed, and each convolution layer of FSNet has the same number of filters from FS as that of the basline CNN in the forward process. With compelling computational acceleration ratio, the parameter space of FSNet is much smaller than that of the baseline CNN. In addition, FSNet is quantization friendly. FSNet with weight quantization leads to even higher compression ratio without noticeable performance loss. We further propose Differentiable FSNet where the way filters share weights is learned in a differentiable and end-to-end manner. Experiments demonstrate the effectiveness of FSNet in compression of CNNs for computer vision tasks including image classification and object detection, and the effectiveness of DFSNet is evidenced by the task of Neural Architecture Search.</font>
<br>
</div>


<hr>
<div id="paper100"> <b>100. k-SDPP: Fixed-Size Video Summarization via Sequential Determinantal Point Processes</b>  <a href="https://www.ijcai.org/proceedings/2020/0108.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title100" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;IJCAI 2020. <br>&nbsp;&nbsp;<i>Jiping Zheng, Ganfeng Lu</i><br>
<font size="3">
With the explosive growth of video data, video summarization which converts long-time videos to key frame sequences has become an important task in information retrieval and machine learning. Determinantal point processes (DPPs) which are elegant probabilistic models have been successfully applied to video summarization. However, existing DPP-based video summarization methods suffer from poor efficiency of outputting a specified size summary or neglecting inherent sequential nature of videos. In this paper, we propose a new model in the DPP lineage named k-SDPP in vein of sequential determinantal point processes but with fixed user specified size k. Our k-SDPP partitions sampled frames of a video into segments where each segment is with constant number of video frames. Moreover, an efficient branch and bound method (BB) considering sequential nature of the frames is provided to optimally select k frames delegating the summary from the divided segments. Experimental results show that our proposed BB method outperforms not only k-DPP and sequential DPP (seqDPP) but also the partition and Markovian assumption based methods.</font>
<br>
</div>


<hr>
<div id="paper101"> <b>101. Neural Entity Summarization with Joint Encoding and Weak Supervision</b>  <a href="https://www.ijcai.org/proceedings/2020/0228.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title101" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;IJCAI 2020. <br>&nbsp;&nbsp;<i>Junyou Li, Gong Cheng, Qingxia Liu, Wen Zhang, Evgeny Kharlamov, Kalpa Gunaratna, Huajun Chen</i><br>
<font size="3">
In a large-scale knowledge graph (KG), an entity is often described by a large number of triple-structured facts. Many applications require abridged versions of entity descriptions, called entity summaries. Existing solutions to entity summarization are mainly unsupervised. In this paper, we present a supervised approach NEST that is based on our novel neural model to jointly encode graph structure and text in KGs and generate high-quality diversified summaries. Since it is costly to obtain manually labeled summaries for training, our supervision is weak as we train with programmatically labeled data which may contain noise but is free of manual work. Evaluation results show that our approach significantly outperforms the state of the art on two public benchmarks.</font>
<br>
</div>


<hr>
<div id="paper102"> <b>102. Neural Abstractive Summarization with Structural Attention</b>  <a href="https://www.ijcai.org/proceedings/2020/0514.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title102" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;IJCAI 2020. <br>&nbsp;&nbsp;<i>Tanya Chowdhury, Sachin Kumar, Tanmoy Chakraborty</i><br>
<font size="3">
Attentional, RNN-based encoder-decoder architectures have obtained impressive performance on abstractive summarization of news articles. However, these methods fail to account for long term dependencies within the sentences of a document. This problem is exacerbated in multi-document summarization tasks such as summarizing the popular opinion in threads present in community question answering (CQA) websites such as Yahoo! Answers and Quora. These threads contain answers which often overlap or contradict each other. In this work, we present  a hierarchical encoder based on structural attention to model such inter-sentence and inter-document dependencies. We set the popular pointer-generator architecture and some of the architectures derived from it as our baselines and show that they fail to generate good summaries in a multi-document setting. We further illustrate that our proposed model achieves significant improvement  over the baseline in both single and multi-document summarization settings -- in the former setting, it beats the  baseline by 1.31 and 7.8 ROUGE-1 points on CNN and CQA datasets, respectively; in the latter setting, the performance is further improved by   1.6 ROUGE-1 points on the CQA dataset.</font>
<br>
</div>


<hr>
<div id="paper103"> <b>103. A Unified Model for Financial Event Classification, Detection and Summarization</b>  <a href="https://www.ijcai.org/proceedings/2020/0644.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title103" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;IJCAI 2020. <br>&nbsp;&nbsp;<i>Quanzhi Li, Qiong Zhang</i><br>
<font size="3">
There is massive amount of news on financial events every day.  In this paper, we present a unified model for detecting, classifying and summarizing financial events.  This model exploits a multi-task learning approach, in which a pre-trained BERT model is used to encode the news articles, and the encoded information are shared by event type classification, detection and summarization tasks. For event summarization, we use a Transformer structure as the decoder. In addition to the input document encoded by BERT, the decoder also utilizes the predicted event type and cluster information, so that it can focus on the specific aspects of the event when generating summary. Our experiments show that our approach outperforms other methods.</font>
<br>
</div>


<hr>
<div id="paper104"> <b>104. From Standard Summarization to New Tasks and Beyond: Summarization with Manifold Information</b>  <a href="https://www.ijcai.org/proceedings/2020/0676.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title104" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;IJCAI 2020. <br>&nbsp;&nbsp;<i>Shen Gao, Xiuying Chen, Zhaochun Ren, Dongyan Zhao, Rui Yan</i><br>
<font size="3">
Text summarization is the research area aiming at creating a short and condensed version of the original document, which conveys the main idea of the document in a few words.This research topic has started to attract the attention of a large community of researchers, and it is nowadays counted as one of the most promising research areas.In general, text summarization algorithms aim at using a plain text document as input and then output a summary.However, in real-world applications, most of the data is not in a plain text format.Instead, there is much manifold information to be summarized, such as the summary for a web page based on a query in the search engine, extreme long document (e.g. academic paper), dialog history and so on.In this paper, we focus on the survey of these new summarization tasks and approaches in the real-world application.</font>
<br>
</div>


<hr>
<div id="paper105"> <b>105. Point at the Triple: Generation of Text Summaries from Knowledge Base Triples (Extended Abstract)</b>  <a href="https://www.ijcai.org/proceedings/2020/0711.pdf" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title105" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;IJCAI 2020. <br>&nbsp;&nbsp;<i>Pavlos Vougiouklis, Eddy Maddalena, Jonathon S. Hare, Elena Simperl</i><br>
<font size="3">
We investigate the problem of generating natural language summaries from knowledge base triples. Our approach is based on a pointer-generator network, which, in addition to generating regular words from a fixed target vocabulary, is able to verbalise triples in several ways. We undertake an automatic and a human evaluation on single and open-domain summaries generation tasks. Both show that our approach significantly outperforms other data-driven baselines.</font>
<br>
</div>


<hr>
<p><font style="color:red;">注：论文列表使用<a href="https://zhuanlan.zhihu.com/p/282844968" target="_blank" rel="noopener">AC论文搜索器</a>整理！</font></p>

    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>PROCJX
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://procjx.github.io/2020/12/09/%E3%80%90NLP%E3%80%91%202020%20Summarization%20%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/" title="【NLP】 2020 Summarization 相关论文整理">https://procjx.github.io/2020/12/09/%E3%80%90NLP%E3%80%91%202020%20Summarization%20%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-CN" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">

        
        

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
                <a href="/2020/12/09/%E3%80%90NLP%E3%80%91%202014-2020%20Information%20Extraction%20%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/" rel="next" title="【NLP】 2014-2020 Information Extraction 信息抽取相关论文整理">
                  <i class="fa fa-chevron-left"></i> 【NLP】 2014-2020 Information Extraction 信息抽取相关论文整理
                </a>
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
                <a href="/2020/12/09/%E3%80%90NLP%E3%80%91%202020%20Neural%20Machine%20Translation%20%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/" rel="prev" title="【NLP】 2020 Neural Machine Translation 机器翻译相关论文整理">
                  【NLP】 2020 Neural Machine Translation 机器翻译相关论文整理 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>

        
        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- procjx-wenzhang -->
<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-1179774715076800"
     data-ad-slot="9197824246"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>


      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    <div class="comments" id="gitalk-container"></div>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#目录"><span class="nav-number">1.</span> <span class="nav-text">目录</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#摘要"><span class="nav-number">2.</span> <span class="nav-text">摘要</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <img class="site-author-image" itemprop="image" alt="PROCJX"
    src="/images/procjx.png">
  <p class="site-author-name" itemprop="name">PROCJX</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">426</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">15</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">71</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/procjx" title="GitHub &amp;rarr; https:&#x2F;&#x2F;github.com&#x2F;procjx" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:procjx@gmail.com" title="E-Mail &amp;rarr; mailto:procjx@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
  </div>



      </div>


<!--
      
        <script type="text/javascript" charset="utf-8" src="/js/tagcloud.js"></script>
        <script type="text/javascript" charset="utf-8" src="/js/tagcanvas.js"></script>
        <div class="widget-wrap">
            <h3 class="widget-title">标签云</h3>
            <div id="myCanvasContainer" class="widget tagcloud">
                <canvas width="250" height="250" id="resCanvas" style="width=100%">
                    <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/AAAI/" rel="tag">AAAI</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ACL/" rel="tag">ACL</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Accepted-Papers/" rel="tag">Accepted Papers</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ArXiv/" rel="tag">ArXiv</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/BERT/" rel="tag">BERT</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CS20SI/" rel="tag">CS20SI</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CS224d/" rel="tag">CS224d</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CS231n/" rel="tag">CS231n</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CVPR/" rel="tag">CVPR</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Context/" rel="tag">Context</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Cross-Lingual/" rel="tag">Cross Lingual</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Dialog-System/" rel="tag">Dialog System</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Discourse/" rel="tag">Discourse</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Discourse-Ranking/" rel="tag">Discourse Ranking</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Discourse-Structure/" rel="tag">Discourse Structure</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Document-NMT/" rel="tag">Document NMT</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/EMNLP/" rel="tag">EMNLP</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Extractive/" rel="tag">Extractive</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ICLR/" rel="tag">ICLR</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ICML/" rel="tag">ICML</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/IJCAI/" rel="tag">IJCAI</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Inter-Sentence/" rel="tag">Inter-Sentence</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Keyphrase-Generation/" rel="tag">Keyphrase Generation</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NAACL/" rel="tag">NAACL</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NIPS/" rel="tag">NIPS</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NMT/" rel="tag">NMT</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Neural-Relation-Extraction/" rel="tag">Neural Relation Extraction</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RST/" rel="tag">RST</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Relation-Constraints/" rel="tag">Relation Constraints</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Summarization/" rel="tag">Summarization</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Translation/" rel="tag">Translation</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Word-Translation/" rel="tag">Word Translation</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/alias/" rel="tag">alias</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/git/" rel="tag">git</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pip/" rel="tag">pip</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/" rel="tag">python</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/screen/" rel="tag">screen</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/shell/" rel="tag">shell</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tgz/" rel="tag">tgz</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tts/" rel="tag">tts</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%86%92%E6%B3%A1/" rel="tag">冒泡</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F/" rel="tag">冒泡排序</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%86%99%E4%BD%9C%E5%8A%A9%E6%89%8B/" rel="tag">写作助手</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8E%8B%E7%BC%A9/" rel="tag">压缩</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6/" rel="tag">发送邮件</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%90%88%E5%B9%B6%E6%8E%92%E5%BA%8F/" rel="tag">合并排序</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%90%8E%E5%8F%B0/" rel="tag">后台</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9F%BA%E6%95%B0%E6%8E%92%E5%BA%8F/" rel="tag">基数排序</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F/" rel="tag">希尔排序</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BD%92%E5%B9%B6/" rel="tag">归并</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/" rel="tag">归并排序</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/" rel="tag">快速排序</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%89%B9%E9%87%8F/" rel="tag">批量</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%89%B9%E9%87%8F%E5%88%A0%E9%99%A4/" rel="tag">批量删除</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8E%92%E5%BA%8F/" rel="tag">排序</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8F%92%E5%85%A5/" rel="tag">插入</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F/" rel="tag">插入排序</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%99%E7%A8%8B/" rel="tag">教程</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%96%90%E6%B3%A2%E9%82%A3%E5%A5%91%E6%95%B0%E5%88%97/" rel="tag">斐波那契数列</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9D%80%E6%AD%BB%E8%BF%9B%E7%A8%8B/" rel="tag">杀死进程</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B1%89%E8%AF%BA%E5%A1%94/" rel="tag">汉诺塔</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%AE%97%E6%B3%95/" rel="tag">算法</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%A7%A3%E5%8E%8B/" rel="tag">解压</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%B0%B7%E6%AD%8C%E7%BF%BB%E8%AF%91/" rel="tag">谷歌翻译</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%BF%AD%E4%BB%A3%E5%9B%9E%E7%BF%BB/" rel="tag">迭代回翻</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%80%89%E6%8B%A9/" rel="tag">选择</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F/" rel="tag">选择排序</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%99%84%E4%BB%B6/" rel="tag">附件</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%9D%9E%E7%9B%91%E7%9D%A3/" rel="tag">非监督</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%A2%86%E5%9F%9F%E9%80%82%E5%BA%94/" rel="tag">领域适应</a><span class="tag-list-count">1</span></li></ul>
                </canvas>
            </div>
        </div>
        
-->
        
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- procjx-hengfu -->
<!--
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-1179774715076800"
     data-ad-slot="9879871597"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
-->

<!-- procjx-chuizhi -->
<!--
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-1179774715076800"
     data-ad-slot="1662238719"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
-->

<!-- procjx-zhengfangxing -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-1179774715076800"
     data-ad-slot="6699421902"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">PROCJX</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.0.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.4.2
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>












        
      </div>
    </footer>
  </div>

  
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/pisces.js"></script>
<script src="/js/next-boot.js"></script>



  
  <script>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>




  <script src="/js/local-search.js"></script>













  

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID: '2286ab64f5194d9d79ce',
      clientSecret: 'f912492bec2391664b40478f50f2f943376768d6',
      repo: 'procjx.github.io',
      owner: 'procjx',
      admin: ['procjx'],
      id: '1f76896f054953d36a7cdb6fbf078099',
        language: 'zh-CN',
      distractionFreeMode: 'true'
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>
</html>
