<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/procjx.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/procjxfavicon32x32.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/procjxfavicon16x16.ico">
  <link rel="mask-icon" href="/images/procjx.png" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '7.4.2',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":true,"show_result":true,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    },
    sidebarPadding: 40
  };
</script>

<!-- Google Adsense -->
<!--
<script async src="//pagead2.googlesyndication.com/
pagead/js/adsbygoogle.js"></script>
<script>
(adsbygoogle = window.adsbygoogle || []).push({
google_ad_client: "pub-1179774715076800",
enable_page_level_ads: true
});
</script>
-->

<script data-ad-client="ca-pub-1179774715076800" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>


<meta name="google-site-verification" content="cEiGwg0T8Rj5msmuEcGYZTh5nnf05EhCXy0gp2Ml5BI" />
<meta name="baidu-site-verification" content="noSKHe8MJs" />

  <meta name="description" content="目录  1. Hybrid Generative-Retrieval Transformers for Dialogue Domain Adaptation [PDF] 摘要  2. Improving Uyghur ASR systems with decoders using morpheme-based language  models [PDF] 摘要  3. Multi-Task Lea">
<meta property="og:type" content="article">
<meta property="og:title" content="【arxiv论文】 Computation and Language 2020-03-04">
<meta property="og:url" content="https:&#x2F;&#x2F;procjx.github.io&#x2F;2020&#x2F;03&#x2F;04&#x2F;%E3%80%90arxiv%E8%AE%BA%E6%96%87%E3%80%91%20Computation%20and%20Language%202020-03-04&#x2F;index.html">
<meta property="og:site_name" content="PROCJX&#39;s BLOGS">
<meta property="og:description" content="目录  1. Hybrid Generative-Retrieval Transformers for Dialogue Domain Adaptation [PDF] 摘要  2. Improving Uyghur ASR systems with decoders using morpheme-based language  models [PDF] 摘要  3. Multi-Task Lea">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2020-03-04T17:06:48.528Z">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://procjx.github.io/2020/03/04/%E3%80%90arxiv%E8%AE%BA%E6%96%87%E3%80%91%20Computation%20and%20Language%202020-03-04/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>【arxiv论文】 Computation and Language 2020-03-04 | PROCJX's BLOGS</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">PROCJX's BLOGS</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <h1 class="site-subtitle" itemprop="description">WITH LOVE OF WORLD</h1>
      
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
        <li class="menu-item menu-item-resources">

    <a href="/resources/" rel="section"><i class="fa fa-fw fa-download"></i>资源</a>

  </li>
        <li class="menu-item menu-item-arxiv">

    <a href="/arxiv/" rel="section"><i class="fa fa-fw fa-file-pdf-o"></i>arxiv论文</a>

  </li>
        <li class="menu-item menu-item-deadline">

    <a href="/deadline/" rel="section"><i class="fa fa-fw fa-calendar"></i>会议截稿</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="搜索..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://procjx.github.io/2020/03/04/%E3%80%90arxiv%E8%AE%BA%E6%96%87%E3%80%91%20Computation%20and%20Language%202020-03-04/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/procjx.png">
      <meta itemprop="name" content="PROCJX">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PROCJX's BLOGS">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          【arxiv论文】 Computation and Language 2020-03-04
        </h2>

        <div class="post-meta">
        
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-03-04 11:29:35" itemprop="dateCreated datePublished" datetime="2020-03-04T11:29:35+08:00">2020-03-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-05 01:06:48" itemprop="dateModified" datetime="2020-03-05T01:06:48+08:00">2020-03-05</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/arxiv/" itemprop="url" rel="index">
                    <span itemprop="name">arxiv</span>
                  </a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/arxiv/CL/" itemprop="url" rel="index">
                    <span itemprop="name">CL</span>
                  </a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
              <span>20k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
              <span>33 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a><div style="color:red;">目录</div></h1><font size="4">
<div id="title1">
<b>1.</b> Hybrid Generative-Retrieval Transformers for Dialogue Domain Adaptation <a href="https://arxiv.org/pdf/2003.01680" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper1" style="color:#0000EE;">摘要</a><br></div>
<div id="title2">
<b>2.</b> Improving Uyghur ASR systems with decoders using morpheme-based language  models <a href="https://arxiv.org/pdf/2003.01509" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper2" style="color:#0000EE;">摘要</a><br></div>
<div id="title3">
<b>3.</b> Multi-Task Learning Network for Emotion Recognition in Conversation <a href="https://arxiv.org/pdf/2003.01478" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper3" style="color:#0000EE;">摘要</a><br></div>
<div id="title4">
<b>4.</b> XGPT: Cross-modal Generative Pre-Training for Image Captioning <a href="https://arxiv.org/pdf/2003.01473" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper4" style="color:#0000EE;">摘要</a><br></div>
<div id="title5">
<b>5.</b> Seshat: A tool for managing and verifying annotation campaigns of audio  data <a href="https://arxiv.org/pdf/2003.01472" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper5" style="color:#0000EE;">摘要</a><br></div>
<div id="title6">
<b>6.</b> Meta-Embeddings Based On Self-Attention <a href="https://arxiv.org/pdf/2003.01371" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper6" style="color:#0000EE;">摘要</a><br></div>
<div id="title7">
<b>7.</b> CLUECorpus2020: A Large-scale Chinese Corpus for Pre-trainingLanguage  Model <a href="https://arxiv.org/pdf/2003.01355" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper7" style="color:#0000EE;">摘要</a><br></div>
<div id="title8">
<b>8.</b> Improving Candidate Generation for Low-resource Cross-lingual Entity  Linking <a href="https://arxiv.org/pdf/2003.01343" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper8" style="color:#0000EE;">摘要</a><br></div>
<div id="title9">
<b>9.</b> Controllable Time-Delay Transformer for Real-Time Punctuation Prediction  and Disfluency Detection <a href="https://arxiv.org/pdf/2003.01309" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper9" style="color:#0000EE;">摘要</a><br></div>
<div id="title10">
<b>10.</b> Transfer Learning for Context-Aware Spoken Language Understanding <a href="https://arxiv.org/pdf/2003.01305" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper10" style="color:#0000EE;">摘要</a><br></div>
<div id="title11">
<b>11.</b> Med7: a transferable clinical natural language processing model for  electronic health records <a href="https://arxiv.org/pdf/2003.01271" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper11" style="color:#0000EE;">摘要</a><br></div>
<div id="title12">
<b>12.</b> Understanding the Prediction Mechanism of Sentiments by XAI  Visualization <a href="https://arxiv.org/pdf/2003.01425" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper12" style="color:#0000EE;">摘要</a><br></div>
<div id="title13">
<b>13.</b> Hierarchical Context Enhanced Multi-Domain Dialogue System for  Multi-domain Task Completion <a href="https://arxiv.org/pdf/2003.01338" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a> <a href="#paper13" style="color:#0000EE;">摘要</a><br></div>
</font><a id="more"></a>


<hr>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><!-- procjx-wenzhang2 --> <ins class="adsbygoogle" style="display:block; text-align:center;" data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-1179774715076800" data-ad-slot="5367332398"></ins> <script>      (adsbygoogle = window.adsbygoogle || []).push({}); </script>



<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><div style="color:red;">摘要</div></h1><div id="paper1"> <b>1. Hybrid Generative-Retrieval Transformers for Dialogue Domain Adaptation</b>  <a href="https://arxiv.org/pdf/2003.01680" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title1" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Shalyminov%2C+I" target="_blank" rel="noopener" style="color:#0000EE;">Igor Shalyminov</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Sordoni%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Alessandro Sordoni</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Atkinson%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Adam Atkinson</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Schulz%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hannes Schulz</a><br>
<font size="3">
Abstract: Domain adaptation has recently become a key problem in dialogue systems research. Deep learning, while being the preferred technique for modeling such systems, works best given massive training data. However, in the real-world scenario, such resources aren't available for every new domain, so the ability to train with a few dialogue examples can be considered essential. Pre-training on large data sources and adapting to the target data has become the standard method for few-shot problems within the deep learning framework. In this paper, we present the winning entry at the fast domain adaptation task of DSTC8, a hybrid generative-retrieval model based on GPT-2 fine-tuned to the multi-domain MetaLWOz dataset. Robust and diverse in response generation, our model uses retrieval logic as a fallback, being SoTA on MetaLWOz in human evaluation (>4% improvement over the 2nd place system) and attaining competitive generalization performance in adaptation to the unseen MultiWOZ dataset. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：域名适应最近已成为对话系统研究的关键问题。深度学习，而被用于模拟这样的系统的首选技术，最适合给大量的训练数据。然而，在实际情况中，这种资源是不可用于每一个新的领域，因此有能力与列车的几个对话的例子可以被认为是必不可少的。在大型数据源和适应目标数据前培训已成为深学习框架内为数不多的射门问题的标准方法。在本文中，我们提出在DSTC8，基于GPT-2微调到多域MetaLWOz数据集混合生成检索模型的快速领域适应性任务的获奖作品。健壮和在响应生成多样化的，我们的模型使用检索逻辑作为备用，上MetaLWOz人评价为Sota株（>在第2个地方系统4％的改善）和实现在适应看不见MultiWOZ数据集竞争性泛化性能。</font>
</div>


<hr>
<div id="paper2"> <b>2. Improving Uyghur ASR systems with decoders using morpheme-based language  models</b>  <a href="https://arxiv.org/pdf/2003.01509" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title2" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Qiu%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Zicheng Qiu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Jiang%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Wei Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Mamut%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Turghunjan Mamut</a><br>
<font size="3">
Abstract: Uyghur is a minority language, and its resources for Automatic Speech Recognition (ASR) research are always insufficient. THUYG-20 is currently the only open-sourced dataset of Uyghur speeches. State-of-the-art results of its clean and noiseless speech test task haven't been updated since the first release, which shows a big gap in the development of ASR between mainstream languages and this http URL this paper, we try to bridge the gap by ultimately optimizing the ASR systems, and by developing a morpheme-based decoder, MLDG-Decoder (Morpheme Lattice Dynamically Generating Decoder for Uyghur DNN-HMM systems), which has long been missing. We have open-sourced the decoder. The MLDG-Decoder employs an algorithm, named as "on-the-fly composition with FEBABOS", to allow the back-off states and transitions to play the role of a relay station in on-the-fly composition. The algorithm empowers the dynamically generated graph to constrain the morpheme sequences in the lattices as effectively as the static and fully composed graph does when a 4-Gram morpheme-based Language Model (LM) is used. We have trained deeper and wider neural network acoustic models, and experimented with three kinds of decoding schemes. The experimental results show that the decoding based on the static and fully composed graph reduces state-of-the-art Word Error Rate (WER) on the clean and noiseless speech test task in THUYG-20 to 14.24%. The MLDG-Decoder reduces the WER to 14.54% while keeping the memory consumption reasonable. Based on the open-sourced MLDG-Decoder, readers can easily reproduce the experimental results in this paper. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：维吾尔语是一种少数民族语言，它的资源自动语音识别（ASR）的研究始终是不够的。 THUYG-20是目前维吾尔语演讲的唯一开源数据集。国家的最先进的清洁和无声的语音测试任务的结果尚未以来的第一个版本更新，这显示了ASR的主流语言的发展有很大的差距，这HTTP URL本文中，我们尝试桥该间隙由最终优化ASR系统，并且通过开发基于词素解码器，MLDG  - 解码器（语素格子动态地生成解码维吾尔族DNN-HMM系统），它一直被丢失。我们已经开源的解码器。该MLDG  - 解码器采用的算法，命名为“上即时组合物与FEBABOS”，允许回退状态和转换在即时成分发挥中继站的角色。该算法授权时使用基于词素-4- gram语言模型（LM）做动态生成图形，以限制在晶格语素序列尽可能有效的静态和完全构成图。我们已经培训了更深，更广的神经网络声学模型，并具有三种解码方案的实验。实验结果表明，基于静态和完全由曲线图中的解码降低状态的最先进的在THUYG-20至14.24％的清洁和无噪声语音测试任务字差错率（WER）。所述MLDG  - 解码器减少到WER 14.54％，同时保持存储器消耗合理。基于开源MLDG  - 解码器，读者可以很容易地复制在本文的实验结果。</font>
</div>


<hr>
<div id="paper3"> <b>3. Multi-Task Learning Network for Emotion Recognition in Conversation</b>  <a href="https://arxiv.org/pdf/2003.01478" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title3" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jingye Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhang%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Meishan Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ji%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Donghong Ji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Liu%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yijiang Liu</a><br>
<font size="3">
Abstract: Conversational emotion recognition (CER) has attracted increasing interests in the natural language processing (NLP) community. Different from the vanilla emotion recognition, effective speaker-sensitive utterance representation is one major challenge for CER. In this paper, we exploit speaker identification (SI) as an auxiliary task to enhance the utterance representation in conversations. By this method, we can learn better speaker-aware contextual representations from the additional SI corpus. Experiments on two benchmark datasets demonstrate that the proposed architecture is highly effective for CER, obtaining new state-of-the-art results on two datasets. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：会话情感识别（CER）已经吸引了自然语言处理（NLP）的社区越来越浓厚的兴趣。从香草情感识别不同的，有效的扬声器敏感的话语表示是CER一个重大的挑战。在本文中，我们利用说话人识别（SI）作为辅助任务，以提高对话的话语表示。通过这种方法，我们可以从另外的SI语料更好的演讲者感知上下文表示。两个基准数据集的实验表明，该架构是CER高效，对两个数据集获得国家的最先进的新成果。</font>
</div>


<hr>
<div id="paper4"> <b>4. XGPT: Cross-modal Generative Pre-Training for Image Captioning</b>  <a href="https://arxiv.org/pdf/2003.01473" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title4" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Xia%2C+Q" target="_blank" rel="noopener" style="color:#0000EE;">Qiaolin Xia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Huang%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Haoyang Huang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Duan%2C+N" target="_blank" rel="noopener" style="color:#0000EE;">Nan Duan</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhang%2C+D" target="_blank" rel="noopener" style="color:#0000EE;">Dongdong Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Ji%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Lei Ji</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Sui%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Zhifang Sui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Cui%2C+E" target="_blank" rel="noopener" style="color:#0000EE;">Edward Cui</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bharti%2C+T" target="_blank" rel="noopener" style="color:#0000EE;">Taroon Bharti</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhou%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Ming Zhou</a><br>
<font size="3">
Abstract: While many BERT-based cross-modal pre-trained models produce excellent results on downstream understanding tasks like image-text retrieval and VQA, they cannot be applied to generation tasks directly. In this paper, we propose XGPT, a new method of Cross-modal Generative Pre-Training for Image Captioning that is designed to pre-train text-to-image caption generators through three novel generation tasks, including Image-conditioned Masked Language Modeling (IMLM), Image-conditioned Denoising Autoencoding (IDA), and Text-conditioned Image Feature Generation (TIFG). As a result, the pre-trained XGPT can be fine-tuned without any task-specific architecture modifications to create state-of-the-art models for image captioning. Experiments show that XGPT obtains new state-of-the-art results on the benchmark datasets, including COCO Captions and Flickr30k Captions. We also use XGPT to generate new image captions as data augmentation for the image retrieval task and achieve significant improvement on all recall metrics. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：虽然许多基于BERT，跨模式预先训练模型产生像图像，文本检索和VQA下游理解任务优异的成绩，他们不能直接应用于生成任务。在本文中，我们提出XGPT，跨模态剖成前的训练中的图像字幕的新方法，旨在通过三种新的生成任务，包括图像的空调蒙面语言模型预列车文字到图片标题发生器（ IMLM），图像空调去噪Autoencoding（IDA），和文本条件的图像特征生成（TIFG）。其结果是，预先训练XGPT可以进行微调而没有任何特定任务的架构修改以用于图像字幕创建状态的最先进的模型。实验表明，XGPT获得国家的最先进的新的基准数据集，包括COCO字幕和字幕Flickr30k结果。我们还使用XGPT产生新的图片说明为图像检索任务数据增强，实现对所有召回的指标显著改善。</font>
</div>


<hr>
<div id="paper5"> <b>5. Seshat: A tool for managing and verifying annotation campaigns of audio  data</b>  <a href="https://arxiv.org/pdf/2003.01472" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title5" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Titeux%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Hadrien Titeux</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Riad%2C+R" target="_blank" rel="noopener" style="color:#0000EE;">Rachid Riad</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Cao%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xuan-Nga Cao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Hamilakis%2C+N" target="_blank" rel="noopener" style="color:#0000EE;">Nicolas Hamilakis</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Madden%2C+K" target="_blank" rel="noopener" style="color:#0000EE;">Kris Madden</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Cristia%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Alejandrina Cristia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Bachoud-L%C3%A9vi%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Anne-Catherine Bachoud-Lévi</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Dupoux%2C+E" target="_blank" rel="noopener" style="color:#0000EE;">Emmanuel Dupoux</a><br>
<font size="3">
Abstract: We introduce Seshat, a new, simple and open-source software to efficiently manage annotations of speech corpora. The Seshat software allows users to easily customise and manage annotations of large audio corpora while ensuring compliance with the formatting and naming conventions of the annotated output files. In addition, it includes procedures for checking the content of annotations following specific rules are implemented in personalised parsers. Finally, we propose a double-annotation mode, for which Seshat computes automatically an associated inter-annotator agreement with the $\gamma$ measure taking into account the categorisation and segmentation discrepancies. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：介绍塞莎特，一个新的，简单的和开源软件来有效地管理语音语料库的注释。该塞莎特软件允许用户轻松定制并同时确保遵守注释的输出文件的格式和命名规范管理大型音语料库的注释。此外，它还包括用于检查下列特定规则在个性化的解析器实现注释的内容程序。最后，我们提出了一个双注释模式，为此塞莎特自动计算与$ \ $伽玛衡量考虑到分类和分割的差异关联，注释间协议。</font>
</div>


<hr>
<div id="paper6"> <b>6. Meta-Embeddings Based On Self-Attention</b>  <a href="https://arxiv.org/pdf/2003.01371" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title6" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+Q" target="_blank" rel="noopener" style="color:#0000EE;">Qichen Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Jiang%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xiaoke Jiang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Xia%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jun Xia</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jian Li</a><br>
<font size="3">
Abstract: Creating meta-embeddings for better performance in language modelling has received attention lately, and methods based on concatenation or merely calculating the arithmetic mean of more than one separately trained embeddings to perform meta-embeddings have shown to be beneficial. In this paper, we devise a new meta-embedding model based on the self-attention mechanism, namely the Duo. With less than 0.4M parameters, the Duo mechanism achieves state-of-the-art accuracy in text classification tasks such as 20NG. Additionally, we propose a new meta-embedding sequece-to-sequence model for machine translation, which to the best of our knowledge, is the first machine translation model based on more than one word-embedding. Furthermore, it has turned out that our model outperform the Transformer not only in terms of achieving a better result, but also a faster convergence on recognized benchmarks, such as the WMT 2014 English-to-French translation task. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：创建元的嵌入在语言模型更好的性能受到了关注最近和方法，基于级联或仅仅计算一个以上的单独训练的嵌入物进行荟萃的嵌入的算术平均值已经证明是有益的。在本文中，我们设计基础上，自注意机制，即双核新的元嵌入模型。少于0.4M参数，二重奏机构达到的状态的最先进的精度在文本分类任务，如20ng的。此外，我们提出了一个新的元嵌入sequece到序列模型机器翻译，这在我们所知的，是基于超过一个字嵌入第一机器翻译模型。此外，它已经证明，我们的模型跑赢变压器不仅实现了较好的效果方面，也对认可的基准，如WMT 2014英语对法语翻译任务较快的收敛。</font>
</div>


<hr>
<div id="paper7"> <b>7. CLUECorpus2020: A Large-scale Chinese Corpus for Pre-trainingLanguage  Model</b>  <a href="https://arxiv.org/pdf/2003.01355" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title7" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Xu%2C+L" target="_blank" rel="noopener" style="color:#0000EE;">Liang Xu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhang%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xuanwei Zhang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Dong%2C+Q" target="_blank" rel="noopener" style="color:#0000EE;">Qianqian Dong</a><br>
<font size="3">
Abstract: In this paper, we introduce the Chinese corpus from CLUE organization, CLUECorpus2020, a large-scale corpus that can be used directly for self-supervised learning such as pre-training of a language model, or language generation. It has 100G raw corpus with 35 billion Chinese characters, which is retrieved from Common Crawl. To better understand this corpus, we conduct language understanding experiments on both small and large scale, and results show that the models trained on this corpus can achieve excellent performance on Chinese. We release a new Chinese vocabulary with a size of 8K, which is only one-third of the vocabulary size used in Chinese Bert released by Google. It saves computational cost and memory while works as good as original vocabulary. We also release both large and tiny versions of the pre-trained model on this corpus. The former achieves the state-of-the-art result, and the latter retains most precision while accelerating training and prediction speed for eight times compared to Bert-base. To facilitate future work on self-supervised learning on Chinese, we release our dataset, new vocabulary, codes, and pre-trained models on Github. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：在本文中，我们将介绍从CLUE组织，CLUECorpus2020，可直接用于大规模语料库的中国语料库自我监督学习，如语言模型前培训或语言的产生。它拥有100G 35个十亿中国字，这是从常见的爬行检索生语料库。为了更好地理解这个语料库，我们在两个小规模和大规模开展语言理解实验，结果表明，经过训练这个语料库的车型可以实现在中国的出色表现。我们发布了新的中国的词汇，大小为8K，这是只有三分之一由谷歌发布了中国伯特使用的词汇量的大小的。它节省了计算成本和内存，而作品不如原来的词汇。我们还发布关于这个语料库大型和微型版本的预先训练模式。前者达到国家的最先进的结果，后者则保留了大部分精度，同时加速训练和预测速度的八倍相比伯特基。为了便于对中国自我监督学习今后的工作中，我们发布的数据集，新的词汇，代码和预先训练Github上的模型。</font>
</div>


<hr>
<div id="paper8"> <b>8. Improving Candidate Generation for Low-resource Cross-lingual Entity  Linking</b>  <a href="https://arxiv.org/pdf/2003.01343" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title8" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhou%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Shuyan Zhou</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Rijhawani%2C+S" target="_blank" rel="noopener" style="color:#0000EE;">Shruti Rijhawani</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wieting%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">John Wieting</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Carbonell%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jaime Carbonell</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Neubig%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Graham Neubig</a><br>
<font size="3">
Abstract: Cross-lingual entity linking (XEL) is the task of finding referents in a target-language knowledge base (KB) for mentions extracted from source-language texts. The first step of (X)EL is candidate generation, which retrieves a list of plausible candidate entities from the target-language KB for each mention. Approaches based on resources from Wikipedia have proven successful in the realm of relatively high-resource languages (HRL), but these do not extend well to low-resource languages (LRL) with few, if any, Wikipedia pages. Recently, transfer learning methods have been shown to reduce the demand for resources in the LRL by utilizing resources in closely-related languages, but the performance still lags far behind their high-resource counterparts. In this paper, we first assess the problems faced by current entity candidate generation methods for low-resource XEL, then propose three improvements that (1) reduce the disconnect between entity mentions and KB entries, and (2) improve the robustness of the model to low-resource scenarios. The methods are simple, but effective: we experiment with our approach on seven XEL datasets and find that they yield an average gain of 16.9% in Top-30 gold candidate recall, compared to state-of-the-art baselines. Our improved model also yields an average gain of 7.9% in in-KB accuracy of end-to-end XEL. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：跨语种实体链接（XEL）是在目标语言知识基础提到从源语言文本中提取找到参照物（KB）的任务。 （X）EL的第一步是候选生成，它检索来自目标语言KB对每个提似是而非候选实体的列表。但是基于维基百科资源相对较高的资源语言（HRL）的领域证明是成功的，但这些并没有很好地低资源语言（LRL）很少，如果有的话，维基百科页面扩展。近日，传递学习方法已被证明在密切相关的语言运用资源，以减少LRL对资源的需求，但性能仍远远落后于他们的高资源同行。在本文中，我们首先评估低资源XEL面临当前实体候选生成方法存在的问题，则提出了三种改善：（1）降低断开之间实体提到和KB条目，和（2）提高了模型的鲁棒性以低资源场景。方法很简单，但有效的：我们尝试与我们的七个XEL数据集的方法，并发现它们产生了16.9％的前30金的候选人召回的平均收益，相较于国家的最先进的基线。我们的改进的模型也产生的7.9％在-KB的端至端XEL的精度的平均增益。</font>
</div>


<hr>
<div id="paper9"> <b>9. Controllable Time-Delay Transformer for Real-Time Punctuation Prediction  and Disfluency Detection</b>  <a href="https://arxiv.org/pdf/2003.01309" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title9" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Chen%2C+Q" target="_blank" rel="noopener" style="color:#0000EE;">Qian Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Chen%2C+M" target="_blank" rel="noopener" style="color:#0000EE;">Mengzhe Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+B" target="_blank" rel="noopener" style="color:#0000EE;">Bo Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Wen Wang</a><br>
<font size="3">
Abstract: With the increased applications of automatic speech recognition (ASR) in recent years, it is essential to automatically insert punctuation marks and remove disfluencies in transcripts, to improve the readability of the transcripts as well as the performance of subsequent applications, such as machine translation, dialogue systems, and so forth. In this paper, we propose a Controllable Time-delay Transformer (CT-Transformer) model that jointly completes the punctuation prediction and disfluency detection tasks in real time. The CT-Transformer model facilitates freezing partial outputs with controllable time delay to fulfill the real-time constraints in partial decoding required by subsequent applications. We further propose a fast decoding strategy to minimize latency while maintaining competitive performance. Experimental results on the IWSLT2011 benchmark dataset and an in-house Chinese annotated dataset demonstrate that the proposed approach outperforms the previous state-of-the-art models on F-scores and achieves a competitive inference speed. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：近年来，随着自动语音识别（ASR）的申请越来越多，这是至关重要的自动插入标点符号和成绩单删除不流利，以提高转录本的可读性，以及随后的应用程序，如机器的性能翻译，对话系统，等等。在本文中，我们提出了共同完成实时标点符号预测和不流利的检测任务的可控延时互感器（CT变压器）模型。的CT-Transformer模型有利于冷冻可控时间延迟部分输出到履行由后续应用所需部分解码的实时约束。我们进一步提出了一个快速解码策略，以减少等待时间，同时保持具有竞争力的表现。在IWSLT2011基准数据集和内部注解中国数据集表明，该方法比对F-分数以前的状态的最先进的车型，并实现了有竞争力的推理速度实验结果。</font>
</div>


<hr>
<div id="paper10"> <b>10. Transfer Learning for Context-Aware Spoken Language Understanding</b>  <a href="https://arxiv.org/pdf/2003.01305" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title10" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Chen%2C+Q" target="_blank" rel="noopener" style="color:#0000EE;">Qian Chen</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhuo%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Zhu Zhuo</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Wen Wang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Xu%2C+Q" target="_blank" rel="noopener" style="color:#0000EE;">Qiuyun Xu</a><br>
<font size="3">
Abstract: Spoken language understanding (SLU) is a key component of task-oriented dialogue systems. SLU parses natural language user utterances into semantic frames. Previous work has shown that incorporating context information significantly improves SLU performance for multi-turn dialogues. However, collecting a large-scale human-labeled multi-turn dialogue corpus for the target domains is complex and costly. To reduce dependency on the collection and annotation effort, we propose a Context Encoding Language Transformer (CELT) model facilitating exploiting various context information for SLU. We explore different transfer learning approaches to reduce dependency on data collection and annotation. In addition to unsupervised pre-training using large-scale general purpose unlabeled corpora, such as Wikipedia, we explore unsupervised and supervised adaptive training approaches for transfer learning to benefit from other in-domain and out-of-domain dialogue corpora. Experimental results demonstrate that the proposed model with the proposed transfer learning approaches achieves significant improvement on the SLU performance over state-of-the-art models on two large-scale single-turn dialogue benchmarks and one large-scale multi-turn dialogue benchmark. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：口语理解（SLU）是面向任务的对话系统的关键组成部分。 SLU解析自然语言的用户话语到语义框架。以前的研究表明，结合上下文信息显著提高了多圈的对话SLU性能。然而，收集大规模人标记的多匝对话语料库用于目标域是复杂和昂贵的。为了减少对收集和注释工作的依赖性，我们提出了一个上下文编语言变压器（CELT）模型有利于开发用于SLU各种上下文信息。我们在探索不同的传输学习方法，以减少对数据收集和注解的依赖。除了使用大型通用语料库未标注，如维基百科监督的训练前，我们探索无监督和监督适应性训练转移学习其它域内和外的域对话语料库方法中受益。实验结果表明，该模型所提出的迁移学习方法实现了对两个大型单圈对话基准和一个大型多转对话标杆SLU表现在国家的最先进的车型显著的改善。</font>
</div>


<hr>
<div id="paper11"> <b>11. Med7: a transferable clinical natural language processing model for  electronic health records</b>  <a href="https://arxiv.org/pdf/2003.01271" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title11" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Kormilitzin%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Andrey Kormilitzin</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Vaci%2C+N" target="_blank" rel="noopener" style="color:#0000EE;">Nemanja Vaci</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Liu%2C+Q" target="_blank" rel="noopener" style="color:#0000EE;">Qiang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Nevado-Holgado%2C+A" target="_blank" rel="noopener" style="color:#0000EE;">Alejo Nevado-Holgado</a><br>
<font size="3">
Abstract: The field of clinical natural language processing has been advanced significantly since the introduction of deep learning models. The self-supervised representation learning and the transfer learning paradigm became the methods of choice in many natural language processing application, in particular in the settings with the dearth of high quality manually annotated data. Electronic health record systems are ubiquitous and the majority of patients' data are now being collected electronically and in particular in the form of free text. Identification of medical concepts and information extraction is a challenging task, yet important ingredient for parsing unstructured data into structured and tabulated format for downstream analytical tasks. In this work we introduced a named-entity recognition model for clinical natural language processing. The model is trained to recognise seven categories: drug names, route, frequency, dosage, strength, form, duration. The model was first self-supervisedly pre-trained by predicting the next word, using a collection of 2 million free-text patients' records from MIMIC-III corpora and then fine-tuned on the named-entity recognition task. The model achieved a lenient (strict) micro-averaged F1 score of 0.957 (0.893) across all seven categories. Additionally, we evaluated the transferability of the developed model using the data from the Intensive Care Unit in the US to secondary care mental health records (CRIS) in the UK. A direct application of the trained NER model to CRIS data resulted in reduced performance of F1=0.762, however after fine-tuning on a small sample from CRIS, the model achieved a reasonable performance of F1=0.944. This demonstrated that despite a close similarity between the data sets and the NER tasks, it is essential to fine-tune on the target domain data in order to achieve more accurate results. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：临床自然语言处理领域一直以来引进深学习模式的显著进展。自我监督表示学习和转移学习模式成为首选的方法在许多自然语言处理的应用，特别是在高品质的手工标注的数据缺乏的设置。电子病历系统是普遍存在的，大多数病人的数据，目前正在收集电子，特别是在自由文本形式。医学概念和信息提取鉴定是一项艰巨的任务，用于分析非结构化数据转换成结构和表格形式进行下游分析任务而重要的组成部分。在这项工作中，我们介绍了临床自然语言处理命名实体识别模型。该模型被训练识别七类：药品名称，路径，频率，用量，强度，形式，时间。该模型是第一个自supervisedly通过预测下一个字，用200万自由文本病人从MIMIC-III语料库记录，然后在命名实体识别任务微调集合预先训练。该模型在所有七个类别取得了宽松（严格）的微平均F1的0.957（0.893）得分。此外，我们评估使用从重症监护病房，在美国的数据在英国的二级医疗机构的心理健康记录（CRIS）开发的模型的转移性。经训练的模型NER到CRIS数据的直接应用导致F1 = 0.762的性能下降，但之后从CRIS一个小样本的微调，模型取得的F1 = 0.944一个合理的性能。这表明，尽管该数据集和NER任务之间有密切的相似性，它是在目标域数据微调必要的，以便实现更精确的结果。</font>
</div>


<hr>
<div id="paper12"> <b>12. Understanding the Prediction Mechanism of Sentiments by XAI  Visualization</b>  <a href="https://arxiv.org/pdf/2003.01425" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title12" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=So%2C+C" target="_blank" rel="noopener" style="color:#0000EE;">Chaehan So</a><br>
<font size="3">
Abstract: People often rely on online reviews to make purchase decisions. The present work aimed to gain an understanding of a machine learning model's prediction mechanism by visualizing the effect of sentiments extracted from online hotel reviews with explainable AI (XAI) methodology. Study 1 used the extracted sentiments as features to predict the review ratings by five machine learning algorithms (knn, CART decision trees, support vector machines, random forests, gradient boosting machines) and identified random forests as best algorithm. Study 2 analyzed the random forests model by feature importance and revealed the sentiments joy, disgust, positive and negative as the most predictive features. Furthermore, the visualization of additive variable attributions and their prediction distribution showed correct prediction in direction and effect size for the 5-star rating but partially wrong direction and insufficient effect size for the 1-star rating. These prediction details were corroborated by a what-if analysis for the four top features. In conclusion, the prediction mechanism of a machine learning model can be uncovered by visualization of particular observations. Comparing instances of contrasting ground truth values can draw a differential picture of the prediction mechanism and inform decisions for model improvement. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：人们通常依赖于网上评论做出购买决定。目前的工作的目的是通过从可视化的在线酒店评论与解释的AI（XAI）方法提取情绪的效果，以获得一个机器学习模型的预测机制的理解。研究1使用提取的情感为特征五个机器学习算法（KNN，CART决策树，支持向量机，随机森林，助推梯度机器），并确定随机森林是最好的算法预测评价评分。研究2分析了功能重要性的随机森林模型，揭示了感情的喜悦，厌恶，积极和消极作为最有预测功能。此外，添加剂可变归因和它们的预测分布的可视化显示，在方向和效果大小正确预测对5-星级，而是部分错误的方向和作用大小不足1星评级。这些预测资料由一个假设分析的四大功能确证。最后，机器学习模型的预测机构可以通过特定的观察可视化被发现。比较对比地面真值的情况下，可以得出预测机制的差分图像，并告知决策模型的改进。</font>
</div>


<hr>
<div id="paper13"> <b>13. Hierarchical Context Enhanced Multi-Domain Dialogue System for  Multi-domain Task Completion</b>  <a href="https://arxiv.org/pdf/2003.01338" target="_blank" rel="noopener" style="color:#0000EE;">[PDF]</a>  <a href="#title13" style="color:#0000EE;">返回目录</a>
 <br>&nbsp;&nbsp;<a href="https://arxiv.org/search/cs?searchtype=author&query=Yang%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jingyuan Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Liu%2C+G" target="_blank" rel="noopener" style="color:#0000EE;">Guang Liu</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Mao%2C+Y" target="_blank" rel="noopener" style="color:#0000EE;">Yuzhao Mao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Zhao%2C+Z" target="_blank" rel="noopener" style="color:#0000EE;">Zhiwei Zhao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Gao%2C+W" target="_blank" rel="noopener" style="color:#0000EE;">Weiguo Gao</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Li%2C+X" target="_blank" rel="noopener" style="color:#0000EE;">Xuan Li</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Yang%2C+H" target="_blank" rel="noopener" style="color:#0000EE;">Haiqin Yang</a>, 
<a href="https://arxiv.org/search/cs?searchtype=author&query=Shen%2C+J" target="_blank" rel="noopener" style="color:#0000EE;">Jianping Shen</a><br>
<font size="3">
Abstract: Task 1 of the DSTC8-track1 challenge aims to develop an end-to-end multi-domain dialogue system to accomplish complex users' goals under tourist information desk settings. This paper describes our submitted solution, Hierarchical Context Enhanced Dialogue System (HCEDS), for this task. The main motivation of our system is to comprehensively explore the potential of hierarchical context for sufficiently understanding complex dialogues. More specifically, we apply BERT to capture token-level information and employ the attention mechanism to capture sentence-level information. The results listed in the leaderboard show that our system achieves first place in automatic evaluation and the second place in human evaluation. </font>
<br>
<font size="2" style="line-height:30px;">
摘要：DSTC8-TRACK1挑战目标的任务1，开发一个终端到终端的多领域对话系统来完成在旅游信息服务台设置复杂的用户的目标。本文介绍了我们的解决方案提出，阶层上下文加强对话系统（HCEDS），这个任务。我们的系统的主要动机是为全面探索分层上下文的潜力充分理解复杂的对话。更具体地讲，我们应用BERT捕捉标记级别信息和使用注意机制，捕捉句子级别的信息。结果在排行榜显示，我们的系统实现了自动评估和人工评估的第二位第一位上市。</font>
</div>


<hr>
<p><font style="color:red;">注：中文为机器翻译结果！</font></p>

    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>PROCJX
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://procjx.github.io/2020/03/04/%E3%80%90arxiv%E8%AE%BA%E6%96%87%E3%80%91%20Computation%20and%20Language%202020-03-04/" title="【arxiv论文】 Computation and Language 2020-03-04">https://procjx.github.io/2020/03/04/%E3%80%90arxiv%E8%AE%BA%E6%96%87%E3%80%91%20Computation%20and%20Language%202020-03-04/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-CN" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">

        
        

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
                <a href="/2020/03/03/%E3%80%90arxiv%E8%AE%BA%E6%96%87%E3%80%91%20Computer%20Vision%20and%20Pattern%20Recognition%202020-03-03/" rel="next" title="【arxiv论文】 Computer Vision and Pattern Recognition 2020-03-03">
                  <i class="fa fa-chevron-left"></i> 【arxiv论文】 Computer Vision and Pattern Recognition 2020-03-03
                </a>
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
                <a href="/2020/03/04/%E3%80%90arxiv%E8%AE%BA%E6%96%87%E3%80%91%20Computer%20Vision%20and%20Pattern%20Recognition%202020-03-04/" rel="prev" title="【arxiv论文】 Computer Vision and Pattern Recognition 2020-03-04">
                  【arxiv论文】 Computer Vision and Pattern Recognition 2020-03-04 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>

        
        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- procjx-wenzhang -->
<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-1179774715076800"
     data-ad-slot="9197824246"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>


      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    <div class="comments" id="gitalk-container"></div>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#目录"><span class="nav-number">1.</span> <span class="nav-text">目录</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#摘要"><span class="nav-number">2.</span> <span class="nav-text">摘要</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <img class="site-author-image" itemprop="image" alt="PROCJX"
    src="/images/procjx.png">
  <p class="site-author-name" itemprop="name">PROCJX</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">84</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">53</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/procjx" title="GitHub &amp;rarr; https:&#x2F;&#x2F;github.com&#x2F;procjx" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:procjx@gmail.com" title="E-Mail &amp;rarr; mailto:procjx@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
  </div>



      </div>


<!--
      
        <script type="text/javascript" charset="utf-8" src="/js/tagcloud.js"></script>
        <script type="text/javascript" charset="utf-8" src="/js/tagcanvas.js"></script>
        <div class="widget-wrap">
            <h3 class="widget-title">标签云</h3>
            <div id="myCanvasContainer" class="widget tagcloud">
                <canvas width="250" height="250" id="resCanvas" style="width=100%">
                    <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/AAAI/" rel="tag">AAAI</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ACL/" rel="tag">ACL</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Accepted-Papers/" rel="tag">Accepted Papers</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ArXiv/" rel="tag">ArXiv</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/BERT/" rel="tag">BERT</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CS20SI/" rel="tag">CS20SI</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CS224d/" rel="tag">CS224d</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CS231n/" rel="tag">CS231n</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CVPR/" rel="tag">CVPR</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Context/" rel="tag">Context</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Cross-Lingual/" rel="tag">Cross Lingual</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Dialog-System/" rel="tag">Dialog System</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Discourse/" rel="tag">Discourse</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Discourse-Ranking/" rel="tag">Discourse Ranking</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Discourse-Structure/" rel="tag">Discourse Structure</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Document-NMT/" rel="tag">Document NMT</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/EMNLP/" rel="tag">EMNLP</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Extractive/" rel="tag">Extractive</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ICLR/" rel="tag">ICLR</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ICML/" rel="tag">ICML</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/IJCAI/" rel="tag">IJCAI</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Inter-Sentence/" rel="tag">Inter-Sentence</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Keyphrase-Generation/" rel="tag">Keyphrase Generation</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NAACL/" rel="tag">NAACL</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NIPS/" rel="tag">NIPS</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NMT/" rel="tag">NMT</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Neural-Relation-Extraction/" rel="tag">Neural Relation Extraction</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RST/" rel="tag">RST</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Relation-Constraints/" rel="tag">Relation Constraints</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Summarization/" rel="tag">Summarization</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/alias/" rel="tag">alias</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/git/" rel="tag">git</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pip/" rel="tag">pip</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/" rel="tag">python</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/screen/" rel="tag">screen</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/shell/" rel="tag">shell</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tgz/" rel="tag">tgz</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tts/" rel="tag">tts</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%86%99%E4%BD%9C%E5%8A%A9%E6%89%8B/" rel="tag">写作助手</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8E%8B%E7%BC%A9/" rel="tag">压缩</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6/" rel="tag">发送邮件</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%90%8E%E5%8F%B0/" rel="tag">后台</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%89%B9%E9%87%8F/" rel="tag">批量</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%89%B9%E9%87%8F%E5%88%A0%E9%99%A4/" rel="tag">批量删除</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%99%E7%A8%8B/" rel="tag">教程</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9D%80%E6%AD%BB%E8%BF%9B%E7%A8%8B/" rel="tag">杀死进程</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%A7%A3%E5%8E%8B/" rel="tag">解压</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%B0%B7%E6%AD%8C%E7%BF%BB%E8%AF%91/" rel="tag">谷歌翻译</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%BF%AD%E4%BB%A3%E5%9B%9E%E7%BF%BB/" rel="tag">迭代回翻</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%99%84%E4%BB%B6/" rel="tag">附件</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%9D%9E%E7%9B%91%E7%9D%A3/" rel="tag">非监督</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%A2%86%E5%9F%9F%E9%80%82%E5%BA%94/" rel="tag">领域适应</a><span class="tag-list-count">1</span></li></ul>
                </canvas>
            </div>
        </div>
        
-->
        
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- procjx-hengfu -->
<!--
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-1179774715076800"
     data-ad-slot="9879871597"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
-->

<!-- procjx-chuizhi -->
<!--
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-1179774715076800"
     data-ad-slot="1662238719"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
-->

<!-- procjx-zhengfangxing -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-1179774715076800"
     data-ad-slot="6699421902"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">PROCJX</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.0.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.4.2
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>












        
      </div>
    </footer>
  </div>

  
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/pisces.js"></script>
<script src="/js/next-boot.js"></script>



  
  <script>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>




  <script src="/js/local-search.js"></script>













  

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID: '2286ab64f5194d9d79ce',
      clientSecret: 'f912492bec2391664b40478f50f2f943376768d6',
      repo: 'procjx.github.io',
      owner: 'procjx',
      admin: ['procjx'],
      id: 'bfa7d254915299e80adc05dbc7227702',
        language: 'zh-CN',
      distractionFreeMode: 'true'
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>
</html>
